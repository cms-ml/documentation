<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Documentation of the CMS Machine Learning Group"><meta name=author content="CMS Machine Learning Group"><link rel=canonical href=https://cms-ml.github.io/documentation/tutorials/nn_in_cms.html><link rel=prev href=../resources/gpu_resources/cms_resources/ml_cern_ch.html><link rel=next href=../software_envs/lcg_environments.html><link rel=icon href=../images/favicon.png><meta name=generator content="mkdocs-1.6.0, mkdocs-material-9.5.23"><title>NN in CMS - CMS Machine Learning Documentation</title><link rel=stylesheet href=../assets/stylesheets/main.6543a935.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../termynal.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=orange> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#introduction class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../index.html title="CMS Machine Learning Documentation" class="md-header__button md-logo" aria-label="CMS Machine Learning Documentation" data-md-component=logo> <img src=../images/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> CMS Machine Learning Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> NN in CMS </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=orange aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=orange aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/cms-ml/documentation title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../index.html title="CMS Machine Learning Documentation" class="md-nav__button md-logo" aria-label="CMS Machine Learning Documentation" data-md-component=logo> <img src=../images/logo.png alt=logo> </a> CMS Machine Learning Documentation </label> <div class=md-nav__source> <a href=https://github.com/cms-ml/documentation title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../index.html class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../newsletter/newsletters.html class=md-nav__link> <span class=md-ellipsis> Newsletters </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Innovation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Innovation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../innovation/journal_club.html class=md-nav__link> <span class=md-ellipsis> ML Journal Club </span> </a> </li> <li class=md-nav__item> <a href=../innovation/hackathons.html class=md-nav__link> <span class=md-ellipsis> ML Hackathons </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../resources/cloud_resources/index.html class=md-nav__link> <span class=md-ellipsis> Cloud Resources </span> </a> </li> <li class=md-nav__item> <a href=../resources/dataset_resources/index.html class=md-nav__link> <span class=md-ellipsis> Dataset Resources </span> </a> </li> <li class=md-nav__item> <a href=../resources/fpga_resources/index.html class=md-nav__link> <span class=md-ellipsis> FPGA Resource </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_4> <label class=md-nav__link for=__nav_4_4 id=__nav_4_4_label tabindex=0> <span class=md-ellipsis> GPU Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> GPU Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/lxplus_gpu.html class=md-nav__link> <span class=md-ellipsis> lxplus-gpu </span> </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/lxplus_htcondor.html class=md-nav__link> <span class=md-ellipsis> CERN HTCondor </span> </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/swan.html class=md-nav__link> <span class=md-ellipsis> SWAN </span> </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/ml_cern_ch.html class=md-nav__link> <span class=md-ellipsis> ml.cern.ch </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> NN in CMS </span> <span class="md-nav__icon md-icon"></span> </label> <a href=nn_in_cms.html class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> NN in CMS </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#the-basics-of-a-nn class=md-nav__link> <span class=md-ellipsis> The basics of a NN </span> </a> <nav class=md-nav aria-label="The basics of a NN"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#loss-functions-binary-multi-class class=md-nav__link> <span class=md-ellipsis> Loss functions: binary &amp; multi-class </span> </a> </li> <li class=md-nav__item> <a href=#architecture-weights class=md-nav__link> <span class=md-ellipsis> Architecture &amp; weights </span> </a> </li> <li class=md-nav__item> <a href=#learningtraining-of-a-nn class=md-nav__link> <span class=md-ellipsis> Learning/Training of a NN </span> </a> <nav class=md-nav aria-label="Learning/Training of a NN"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gradient-descent class=md-nav__link> <span class=md-ellipsis> Gradient descent </span> </a> </li> <li class=md-nav__item> <a href=#adam class=md-nav__link> <span class=md-ellipsis> Adam </span> </a> </li> <li class=md-nav__item> <a href=#regularization class=md-nav__link> <span class=md-ellipsis> Regularization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#activation-functions class=md-nav__link> <span class=md-ellipsis> Activation functions </span> </a> </li> <li class=md-nav__item> <a href=#number-of-epochs-batch-size class=md-nav__link> <span class=md-ellipsis> Number of epochs, batch size </span> </a> </li> <li class=md-nav__item> <a href=#code-snippets class=md-nav__link> <span class=md-ellipsis> Code snippets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sample-treatment class=md-nav__link> <span class=md-ellipsis> Sample treatment </span> </a> <nav class=md-nav aria-label="Sample treatment"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#splitting-training-validation-and-testing-samples class=md-nav__link> <span class=md-ellipsis> Splitting: training, validation, and testing samples </span> </a> </li> <li class=md-nav__item> <a href=#event-normalization class=md-nav__link> <span class=md-ellipsis> Event normalization </span> </a> </li> <li class=md-nav__item> <a href=#shuffling-seeding class=md-nav__link> <span class=md-ellipsis> Shuffling, seeding </span> </a> </li> <li class=md-nav__item> <a href=#event-weighting-balancing class=md-nav__link> <span class=md-ellipsis> Event weighting &amp; balancing </span> </a> </li> <li class=md-nav__item> <a href=#code-snippets_1 class=md-nav__link> <span class=md-ellipsis> Code snippets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#metrics class=md-nav__link> <span class=md-ellipsis> Metrics </span> </a> <nav class=md-nav aria-label=Metrics> <ul class=md-nav__list> <li class=md-nav__item> <a href=#training-validation-losses-versus-epoch class=md-nav__link> <span class=md-ellipsis> Training &amp; Validation losses versus epoch </span> </a> </li> <li class=md-nav__item> <a href=#truefalse-positivenegative class=md-nav__link> <span class=md-ellipsis> True/False positive/negative </span> </a> </li> <li class=md-nav__item> <a href=#accuracy-versus-epoch class=md-nav__link> <span class=md-ellipsis> Accuracy versus epoch </span> </a> </li> <li class=md-nav__item> <a href=#multi-class-nn-confusion-matrix class=md-nav__link> <span class=md-ellipsis> Multi-class NN: confusion matrix </span> </a> </li> <li class=md-nav__item> <a href=#over-training class=md-nav__link> <span class=md-ellipsis> Over-training </span> </a> </li> <li class=md-nav__item> <a href=#assess-performance-of-classification-in-analysis class=md-nav__link> <span class=md-ellipsis> Assess performance of classification in analysis </span> </a> </li> <li class=md-nav__item> <a href=#code-snippets_2 class=md-nav__link> <span class=md-ellipsis> Code snippets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#full-codes class=md-nav__link> <span class=md-ellipsis> Full codes </span> </a> <nav class=md-nav aria-label="Full codes"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#binary class=md-nav__link> <span class=md-ellipsis> Binary </span> </a> </li> <li class=md-nav__item> <a href=#multiclass class=md-nav__link> <span class=md-ellipsis> Multiclass </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#how-to-train-on-a-gpu class=md-nav__link> <span class=md-ellipsis> How to train on a GPU </span> </a> </li> <li class=md-nav__item> <a href=#reading-suggestions-references class=md-nav__link> <span class=md-ellipsis> Reading suggestions &amp; references </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex> <span class=md-ellipsis> Guides </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_1> <label class=md-nav__link for=__nav_6_1 id=__nav_6_1_label tabindex=0> <span class=md-ellipsis> Software environments </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_1_label aria-expanded=false> <label class=md-nav__title for=__nav_6_1> <span class="md-nav__icon md-icon"></span> Software environments </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../software_envs/lcg_environments.html class=md-nav__link> <span class=md-ellipsis> LCG environments </span> </a> </li> <li class=md-nav__item> <a href=../software_envs/containers.html class=md-nav__link> <span class=md-ellipsis> Using containers </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_2> <label class=md-nav__link for=__nav_6_2 id=__nav_6_2_label tabindex=0> <span class=md-ellipsis> Optimization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2> <span class="md-nav__icon md-icon"></span> Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../optimization/model_optimization.html class=md-nav__link> <span class=md-ellipsis> Model optimization </span> </a> </li> <li class=md-nav__item> <a href=../optimization/importance.html class=md-nav__link> <span class=md-ellipsis> Feature importance </span> </a> </li> <li class=md-nav__item> <a href=../optimization/data_augmentation.html class=md-nav__link> <span class=md-ellipsis> Data augmentation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3> <label class=md-nav__link for=__nav_6_3 id=__nav_6_3_label tabindex=0> <span class=md-ellipsis> General Advice </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3> <span class="md-nav__icon md-icon"></span> General Advice </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/intro.html class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3_2> <label class=md-nav__link for=__nav_6_3_2 id=__nav_6_3_2_label tabindex=0> <span class=md-ellipsis> Before training </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3_2> <span class="md-nav__icon md-icon"></span> Before training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/before/domains.html class=md-nav__link> <span class=md-ellipsis> Domains </span> </a> </li> <li class=md-nav__item> <a href=../general_advice/before/features.html class=md-nav__link> <span class=md-ellipsis> Features </span> </a> </li> <li class=md-nav__item> <a href=../general_advice/before/inputs.html class=md-nav__link> <span class=md-ellipsis> Inputs </span> </a> </li> <li class=md-nav__item> <a href=../general_advice/before/model.html class=md-nav__link> <span class=md-ellipsis> Model </span> </a> </li> <li class=md-nav__item> <a href=../general_advice/before/metrics.html class=md-nav__link> <span class=md-ellipsis> Metrics & Losses </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3_3> <label class=md-nav__link for=__nav_6_3_3 id=__nav_6_3_3_label tabindex=0> <span class=md-ellipsis> During training </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3_3> <span class="md-nav__icon md-icon"></span> During training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/during/overfitting.html class=md-nav__link> <span class=md-ellipsis> Overfitting </span> </a> </li> <li class=md-nav__item> <a href=../general_advice/during/xvalidation.html class=md-nav__link> <span class=md-ellipsis> Cross-validation </span> </a> </li> <li class=md-nav__item> <a href=../general_advice/during/opt.html class=md-nav__link> <span class=md-ellipsis> Optimisation problems </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../general_advice/after/after.html class=md-nav__link> <span class=md-ellipsis> After training </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4> <label class=md-nav__link for=__nav_6_4 id=__nav_6_4_label tabindex=0> <span class=md-ellipsis> Inference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_4_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4> <span class="md-nav__icon md-icon"></span> Inference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4_1> <label class=md-nav__link for=__nav_6_4_1 id=__nav_6_4_1_label tabindex=0> <span class=md-ellipsis> Direct inference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4_1> <span class="md-nav__icon md-icon"></span> Direct inference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../inference/tensorflow2.html class=md-nav__link> <span class=md-ellipsis> TensorFlow 2 </span> </a> </li> <li class=md-nav__item> <a href=../inference/tensorflow_aot.html class=md-nav__link> <span class=md-ellipsis> TensorFlow AOT </span> </a> </li> <li class=md-nav__item> <a href=../inference/pytorch.html class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../inference/pyg.html class=md-nav__link> <span class=md-ellipsis> PyTorch Geometric </span> </a> </li> <li class=md-nav__item> <a href=../inference/onnx.html class=md-nav__link> <span class=md-ellipsis> ONNX </span> </a> </li> <li class=md-nav__item> <a href=../inference/qonnx.html class=md-nav__link> <span class=md-ellipsis> QONNX </span> </a> </li> <li class=md-nav__item> <a href=../inference/xgboost.html class=md-nav__link> <span class=md-ellipsis> XGBoost </span> </a> </li> <li class=md-nav__item> <a href=../inference/hls4ml.html class=md-nav__link> <span class=md-ellipsis> hls4ml </span> </a> </li> <li class=md-nav__item> <a href=../inference/conifer.html class=md-nav__link> <span class=md-ellipsis> conifer </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4_2> <label class=md-nav__link for=__nav_6_4_2 id=__nav_6_4_2_label tabindex=0> <span class=md-ellipsis> Inference as a service </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4_2> <span class="md-nav__icon md-icon"></span> Inference as a service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../inference/sonic_triton.html class=md-nav__link> <span class=md-ellipsis> Sonic/Triton </span> </a> </li> <li class=md-nav__item> <a href=../inference/tfaas.html class=md-nav__link> <span class=md-ellipsis> TFaaS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4_3> <label class=md-nav__link for=__nav_6_4_3 id=__nav_6_4_3_label tabindex=0> <span class=md-ellipsis> Non-standard workflows </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4_3> <span class="md-nav__icon md-icon"></span> Non-standard workflows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../inference/standalone.html class=md-nav__link> <span class=md-ellipsis> Standalone framework </span> </a> </li> <li class=md-nav__item> <a href=../inference/swan_aws.html class=md-nav__link> <span class=md-ellipsis> SWAN + AWS </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../inference/checklist.html class=md-nav__link> <span class=md-ellipsis> Integration checklist </span> </a> </li> <li class=md-nav__item> <a href=../inference/performance.html class=md-nav__link> <span class=md-ellipsis> Performance </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4_6> <label class=md-nav__link for=__nav_6_4_6 id=__nav_6_4_6_label tabindex=0> <span class=md-ellipsis> Successful integrations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_4_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4_6> <span class="md-nav__icon md-icon"></span> Successful integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../inference/particlenet.html class=md-nav__link> <span class=md-ellipsis> ParticleNet </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_5> <label class=md-nav__link for=__nav_6_5 id=__nav_6_5_label tabindex=0> <span class=md-ellipsis> Training </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_5_label aria-expanded=false> <label class=md-nav__title for=__nav_6_5> <span class="md-nav__icon md-icon"></span> Training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/BayesianNN.html class=md-nav__link> <span class=md-ellipsis> Bayesian Neural Network </span> </a> </li> <li class=md-nav__item> <a href=../training/Decorrelation.html class=md-nav__link> <span class=md-ellipsis> Decorrelation </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_5_3> <label class=md-nav__link for=__nav_6_5_3 id=__nav_6_5_3_label tabindex=0> <span class=md-ellipsis> Training as a Service </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_5_3> <span class="md-nav__icon md-icon"></span> Training as a Service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/MLaaS4HEP.html class=md-nav__link> <span class=md-ellipsis> MLaaS4HEP </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../training/autoencoders.html class=md-nav__link> <span class=md-ellipsis> Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=../training/HGQ.html class=md-nav__link> <span class=md-ellipsis> HGQ </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#the-basics-of-a-nn class=md-nav__link> <span class=md-ellipsis> The basics of a NN </span> </a> <nav class=md-nav aria-label="The basics of a NN"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#loss-functions-binary-multi-class class=md-nav__link> <span class=md-ellipsis> Loss functions: binary &amp; multi-class </span> </a> </li> <li class=md-nav__item> <a href=#architecture-weights class=md-nav__link> <span class=md-ellipsis> Architecture &amp; weights </span> </a> </li> <li class=md-nav__item> <a href=#learningtraining-of-a-nn class=md-nav__link> <span class=md-ellipsis> Learning/Training of a NN </span> </a> <nav class=md-nav aria-label="Learning/Training of a NN"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gradient-descent class=md-nav__link> <span class=md-ellipsis> Gradient descent </span> </a> </li> <li class=md-nav__item> <a href=#adam class=md-nav__link> <span class=md-ellipsis> Adam </span> </a> </li> <li class=md-nav__item> <a href=#regularization class=md-nav__link> <span class=md-ellipsis> Regularization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#activation-functions class=md-nav__link> <span class=md-ellipsis> Activation functions </span> </a> </li> <li class=md-nav__item> <a href=#number-of-epochs-batch-size class=md-nav__link> <span class=md-ellipsis> Number of epochs, batch size </span> </a> </li> <li class=md-nav__item> <a href=#code-snippets class=md-nav__link> <span class=md-ellipsis> Code snippets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sample-treatment class=md-nav__link> <span class=md-ellipsis> Sample treatment </span> </a> <nav class=md-nav aria-label="Sample treatment"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#splitting-training-validation-and-testing-samples class=md-nav__link> <span class=md-ellipsis> Splitting: training, validation, and testing samples </span> </a> </li> <li class=md-nav__item> <a href=#event-normalization class=md-nav__link> <span class=md-ellipsis> Event normalization </span> </a> </li> <li class=md-nav__item> <a href=#shuffling-seeding class=md-nav__link> <span class=md-ellipsis> Shuffling, seeding </span> </a> </li> <li class=md-nav__item> <a href=#event-weighting-balancing class=md-nav__link> <span class=md-ellipsis> Event weighting &amp; balancing </span> </a> </li> <li class=md-nav__item> <a href=#code-snippets_1 class=md-nav__link> <span class=md-ellipsis> Code snippets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#metrics class=md-nav__link> <span class=md-ellipsis> Metrics </span> </a> <nav class=md-nav aria-label=Metrics> <ul class=md-nav__list> <li class=md-nav__item> <a href=#training-validation-losses-versus-epoch class=md-nav__link> <span class=md-ellipsis> Training &amp; Validation losses versus epoch </span> </a> </li> <li class=md-nav__item> <a href=#truefalse-positivenegative class=md-nav__link> <span class=md-ellipsis> True/False positive/negative </span> </a> </li> <li class=md-nav__item> <a href=#accuracy-versus-epoch class=md-nav__link> <span class=md-ellipsis> Accuracy versus epoch </span> </a> </li> <li class=md-nav__item> <a href=#multi-class-nn-confusion-matrix class=md-nav__link> <span class=md-ellipsis> Multi-class NN: confusion matrix </span> </a> </li> <li class=md-nav__item> <a href=#over-training class=md-nav__link> <span class=md-ellipsis> Over-training </span> </a> </li> <li class=md-nav__item> <a href=#assess-performance-of-classification-in-analysis class=md-nav__link> <span class=md-ellipsis> Assess performance of classification in analysis </span> </a> </li> <li class=md-nav__item> <a href=#code-snippets_2 class=md-nav__link> <span class=md-ellipsis> Code snippets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#full-codes class=md-nav__link> <span class=md-ellipsis> Full codes </span> </a> <nav class=md-nav aria-label="Full codes"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#binary class=md-nav__link> <span class=md-ellipsis> Binary </span> </a> </li> <li class=md-nav__item> <a href=#multiclass class=md-nav__link> <span class=md-ellipsis> Multiclass </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#how-to-train-on-a-gpu class=md-nav__link> <span class=md-ellipsis> How to train on a GPU </span> </a> </li> <li class=md-nav__item> <a href=#reading-suggestions-references class=md-nav__link> <span class=md-ellipsis> Reading suggestions &amp; references </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/cms-ml/documentation/blob/master/content/tutorials/nn_in_cms.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg> </a> <a href=https://github.com/cms-ml/documentation/raw/master/content/tutorials/nn_in_cms.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg> </a> <h1>NN in CMS</h1> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">&para;</a></h2> <p>The very basic idea of any multivariate analysis or supervised machine learning (ML) tool for classification is to make a more optimal use of a set of discriminating variables xi than each of these variables, either individually or two-by-two or three-by-three, which is the highest dimension a human can geometrically represent. An ML can at least make a more optimal chain of decisions via 1-dimensional (1D) cuts (like Boosted Decision Trees - BDTs) than human based 1D or 2D decisions. This is exactly what BDTs do, where each tree applies an ensemble of 1D cuts, and where the forest of trees effectively applies cuts of higher dimensions. It can also exploit the differences of correlation among the input variables xi for S and B events (like Deep Neural Networks - NNs).</p> <p>In this tutorial, we will first go through the basic ideas of a NN, then cover its different metrics, and then cover how events/samples should be treated. In each section, we will provide code snippets as to illustrate the practice of each covered point. To not overload the flow of the tutorial, these pieces of code will be just snippets, and full example codes will be provided in the last section.</p> <hr> <h2 id=the-basics-of-a-nn>The basics of a NN<a class=headerlink href=#the-basics-of-a-nn title="Permanent link">&para;</a></h2> <p>In this section, we will cover the basic concepts of a Neural Network (NN) classifier. First, we will cover the quantity which is minimized and is guiding the training of a NN, quantity which can also be used by other classifiers. Then we will cover the specifics of a NN classifier, namely its architecture and how one builds its output discriminator as function of the input variables. We will then cover how a NN is trained, and go over the activation functions of a NN. Finally, we will provide code snippets illustrating the mentioned functionalities.</p> <h3 id=loss-functions-binary-multi-class>Loss functions: binary &amp; multi-class<a class=headerlink href=#loss-functions-binary-multi-class title="Permanent link">&para;</a></h3> <p>When <b>classifying</b> events, we need to optimize a quantity which quantifies our classification; this quantity can be a loss function. If we are dealing with a binary classification of Signal (S) versus Background (B), we need a measure of how much we have classified signal events as S, and background events as B. The binary cross-entropy, which is one such quantity, is one of the loss functions used for binary studies, and is averaged over N events:</p> <div class=arithmatex>\[\begin{align} L = - \frac{1}{N} \times \Sigma_{i=1}^{N} [ z(i) \times ln(y(i)) + (1 - z(i)) \times ln(1 - y(i)) ] &amp; (1), \end{align}\]</div> <p>where:</p> <ul> <li><span class=arithmatex>\(z(i)\)</span> is the true classification: it is 1 for S, and 0 for B; this can be viewed as the <b>tag</b> of the event, ie. the prior knowledge that we provide to the classifier for this latter to know which event is S or B.</li> <li><span class=arithmatex>\(y(i)\)</span> is the classifier's output, with its value between 0 and 1, ie. its <b>prediction</b> for whether an event is S(1) or B(0).</li> </ul> <p><span class=arithmatex>\(L\)</span> is reflective of the morphology of the classifier: the measure of the classification, itself a function of the separation achieved by the classifier. In equation (1), the first and second terms are "signal" and "background" term respectively. Indeed:</p> <ul> <li><span class=arithmatex>\(L = - \frac{1}{N} \times \Sigma_{i=1}^{N} ln(y(i))\)</span>. If the prediction is S: <span class=arithmatex>\(y(i) \rightarrow 1\)</span>, then we have <span class=arithmatex>\(L \rightarrow 0\)</span>.</li> <li><span class=arithmatex>\(L = - \frac{1}{N} \times \Sigma_{i=1}^{N} ln(1 - y(i))\)</span>. If the prediction is B: <span class=arithmatex>\(y(i) \rightarrow 0\)</span>, then we have <span class=arithmatex>\(L \rightarrow 0\)</span>.</li> </ul> <p>The general, ie. multi-class, cross-entropy is given by:</p> <div class=arithmatex>\[\begin{align} L = - \frac{1}{N} \times \Sigma_{i=1}^{N} [ \Sigma_{j=1}^{m} z_j(i) \times ln(y_j(i)) ] &amp; (1'), \end{align}\]</div> <p>where <span class=arithmatex>\(j\)</span> is the index of <span class=arithmatex>\(m\)</span> different classes. Eq. (1) is easily obtained by considering <span class=arithmatex>\(m=2\)</span>, and considering that for each event <span class=arithmatex>\(i\)</span>, we have <span class=arithmatex>\(z_1 + z_2 = 1\)</span> and <span class=arithmatex>\(y_1 + y_2 = 1\)</span>.</p> <p>It has to be noted that Keras, an open-source library in Python for artificial neural networks, minimizes a slightly different loss function. For example, for binary classification, the cross-entropy that Keras minimizes is given by:</p> <div class=arithmatex>\[\begin{align} L_K = - \frac{1}{N} \times \Sigma_{i=1}^{N} w_i \times [ z(i) \times ln(y(i)) + (1 - z(i)) \times ln(1 - y(i)) ] &amp; (2), \end{align}\]</div> <p>where <span class=arithmatex>\(w_i\)</span> is the event weight, reflecting the number of events in the sample, cross section, etc; it takes into account the (signal and background) samples, both in their shape (through bins of a distribution) and normalization. Therefore, to have a numerically balanced problem to solve, the weights should be made to be comparable:</p> <div class=arithmatex>\[\begin{align} \Sigma_{i=1}^{N} w_i^S = \Sigma_{i=1}^{M} w_i^B &amp; (3). \end{align}\]</div> <p>We will cover more this latest aspect in the subsection "Event balancing". Finally, it should be noted that for NNs performing tasks other than classification, loss functions different from cross-entropy are minimized. For example, for the case of a NN performing a regression, the minimized loss function is often the Mean Squared Error.</p> <h3 id=architecture-weights>Architecture &amp; weights<a class=headerlink href=#architecture-weights title="Permanent link">&para;</a></h3> <p>In a NN, the information of the <span class=arithmatex>\(n\)</span> input variables <span class=arithmatex>\(x_i\)</span> is propagated to different nodes as illustrated in figure 1, where we represent a NN with one hidden layer of <span class=arithmatex>\(m\)</span> nodes. The information is propagated from the input nodes to the output node(s) via the hidden layer(s), representing the foward propagation of the NN. In this example, there is only output node. In the case of a multi-class NN, there is as much nodes as classes for classification.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/NNarch-forw.png alt style="width: 500px;"> <figcaption>Figure 1</p> </blockquote> <p>Here, each input node <span class=arithmatex>\(i\)</span> sends the same input variable <span class=arithmatex>\(x_i\)</span> to all nodes of the hidden layer. Overall, the NN is fully connected, meaning that each node of a given layer has a connection with all nodes of the subsequent layer. The lines, ie. the numerical connections, between the nodes are the weights <span class=arithmatex>\(w\)</span>, all different from one another, and are updated during the training of the NN (see section on learning). Higher/Lower weights indicate a stronger/weaker influence of one neuron on another. The hidden layers of the NN can be viewed as functions of the variables/nodes of the previous layer.</p> <p>In the case of a NN with one hidden layer, the output discriminant <span class=arithmatex>\(y\)</span> of a NN at the output layer is given as a function of input variables <span class=arithmatex>\(x_i\)</span>:</p> <div class=arithmatex>\[\begin{align} y = \Sigma_j^{N_{nodes}} [ g(\Sigma_i^{N_{inputs}} w_{ij} \times x_i) \times w_j ] + O &amp; (4), \end{align}\]</div> <p>where <span class=arithmatex>\(w_{ij}\)</span> is the weight between node <span class=arithmatex>\(i\)</span> of a layer and node <span class=arithmatex>\(j\)</span> of another layer, <span class=arithmatex>\(w_j\)</span> is the weight between node <span class=arithmatex>\(j\)</span> of penultimate layer and the output. <span class=arithmatex>\(g\)</span> is the activation function (see section on activation functions) operating at each node <span class=arithmatex>\(h_j\)</span> of the hidden layer. As such, y retains the information about the input variables plus a set of weights optimized to minimize the cross-entropy loss.</p> <h3 id=learningtraining-of-a-nn>Learning/Training of a NN<a class=headerlink href=#learningtraining-of-a-nn title="Permanent link">&para;</a></h3> <p>The NN is trained iteratively on the (training) data to adjust the weights, aiming to find their optimal values that minimize the loss, ie. minimize the difference between its predictions and the true values. This is done in the backward propagation step of the training, as illustrated in the figure below. The full iteration of a forward- &amp; backward-propagation is called an epoch, ie. <b>epoch</b> in the training of the NN.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/NNarch-forwbck.png alt style="width: 500px;"> <figcaption>Figure 2</p> </blockquote> <p>The prediction of the NN for an event <span class=arithmatex>\(y_p\)</span> is compared with the true value <span class=arithmatex>\(y_t\)</span>, comparison upon which the loss value is calculated. This latter value is in turn fed to the optimizer, which updates the weights, injecting them back in the forward propagation part of the training. We cover the two most known optimizers in the two subsections below.</p> <h4 id=gradient-descent>Gradient descent<a class=headerlink href=#gradient-descent title="Permanent link">&para;</a></h4> <p>The equation giving the evolution of the weights <span class=arithmatex>\(w_{tij}\)</span> at epoch <span class=arithmatex>\(t\)</span>, is:</p> <div class=arithmatex>\[\begin{align} w^{t+1}_{ij} = w^t_{ij} − [R \times e^{−D t} \times \Delta w^t_{ij} ] &amp; (5), \end{align}\]</div> <p>where <span class=arithmatex>\(R\)</span> and <span class=arithmatex>\(D\)</span> are the learning and decay rates, respectively. <span class=arithmatex>\(R\)</span> is usually tested in the <span class=arithmatex>\([10^{-5},10^{-2}]\)</span> interval. <span class=arithmatex>\(\Delta w^t_{ij}\)</span> is the partial derivative (versus <span class=arithmatex>\(w\)</span>) of the back-propagation between two epochs:</p> <div class=arithmatex>\[\begin{align} \Delta w^t_{ij} = \frac{\delta L_K}{\delta w} &amp; (6). \end{align}\]</div> <p>This gradient gives the direction of the steepest increase of the loss function, and the learning rate <span class=arithmatex>\(R\)</span> controls the step size taken during an update in that direction. By moving in the opposite direction of the gradient, the algorithm iteratively adjusts the weights to reduce the error and improve the NN's performance. Let us explain this latter point more explicitly. The derivative of Eq. (6), within Eq. (5), points in the direction where the loss function <span class=arithmatex>\(L_K\)</span> decreases the most:</p> <ul> <li>If <span class=arithmatex>\(\frac{\delta L_K}{\delta w} \geq 0\)</span>: <span class=arithmatex>\(L_K\)</span> is increasing, then <span class=arithmatex>\(w_{ij}^{t+1} \leq w_{ij}^t\)</span>, thus weights will decrease and one can only have <span class=arithmatex>\(\frac{\delta L_K}{\delta w} \sim 0\)</span>.</li> <li>If <span class=arithmatex>\(\frac{\delta L_K}{\delta w} \leq 0\)</span>: <span class=arithmatex>\(L_K\)</span> is decreasing, meaning that there is less cross-entropy, thus <span class=arithmatex>\(L_K \rightarrow 0\)</span>, thus: <span class=arithmatex>\(\frac{\delta L_K}{\delta w} \sim 0\)</span>.</li> </ul> <p>Let us now consider a numerical case. Let's consider a case where the weights <span class=arithmatex>\(w_i\)</span> of Eq. (2) are too small, eg. O(<span class=arithmatex>\(10^{−7}\)</span>), while the weights <span class=arithmatex>\(w_{ij}\)</span> are O(<span class=arithmatex>\(1\)</span>). In such a case, <span class=arithmatex>\(L_K\)</span> (see Eq. (2)), thus <span class=arithmatex>\(\Delta w^t_{ij}\)</span> (see Eq.(6)), will also be too small. In such a case, one can see from Eq. (5) that the NN learns almost nothing. This is one illustration of the fact that in a classification problem, the weights should be properly balanced; we will address this point in the section "Event balancing".</p> <h4 id=adam>Adam<a class=headerlink href=#adam title="Permanent link">&para;</a></h4> <p>Equations (7) to (10) summarize the Adam algorithm [1]. <span class=arithmatex>\(g_t\)</span> gives the gradient of the function <span class=arithmatex>\(f(\theta)\)</span> to minimize, which can be a loss function, and which is a stochastic scalar function that is differentiable versus parameters <span class=arithmatex>\(\theta\)</span>:</p> <div class=arithmatex>\[\begin{align} g_t = \nabla \theta f_t (\theta_{t−1}) &amp; (7). \end{align}\]</div> <p><span class=arithmatex>\(g_t\)</span> can be viewed as the equivalent of the gradient of Eq. (6), where the function <span class=arithmatex>\(f(\theta)\)</span> can be identified with the loss function <span class=arithmatex>\(L_K\)</span>, and parameters <span class=arithmatex>\(\theta\)</span> with the weights <span class=arithmatex>\(w\)</span> to be optimized. The algorithm updates exponential moving averages of the gradient (<span class=arithmatex>\(m_t\)</span>) and of the squared gradient (<span class=arithmatex>\(v_t\)</span>) as follow:</p> <div class=arithmatex>\[\begin{align} m_t = e^{−\beta_1t} \times m_{t-1} + (1 - e^{−\beta_1t}) \times g_t &amp; , &amp; v_t = e^{−\beta_2t} \times v_{t-1} + (1 - e^{−\beta_2t}) \times g_t &amp; (8), \end{align}\]</div> <p>where <span class=arithmatex>\(\beta_{1,2} \in [0, 1[\)</span> control the exponential decay rates of these moving averages. The moving averages themselves are estimates of the first moment (the mean) and the second raw moment (the uncentered variance) of the gradient. They are initialized as (vectors of) <span class=arithmatex>\(\theta\)</span>’s. It should be noted that at <span class=arithmatex>\(t=0\)</span>, we have: <span class=arithmatex>\(m_t = m_{t−1}\)</span>, so the gradient descent doesn’t play a role for the first iteration. On the other hand, for <span class=arithmatex>\(t = +Inf\)</span>. we have: <span class=arithmatex>\(m_t= \nabla \theta f_t(\theta_{t−1})\)</span>, where only the gradient of the function plays a role. The estimate of these moments are given by:</p> <div class=arithmatex>\[\begin{align} \hat{m}_t = \frac{m_t }{(1 − \beta_1^t)} &amp; , &amp; \hat{v}_t= \frac{v_t }{(1 − \beta_2^t)} &amp; (9), \end{align}\]</div> <p>where <span class=arithmatex>\(\beta^t\)</span> is <span class=arithmatex>\(\beta\)</span> to the power <span class=arithmatex>\(t\)</span>. Then, the updated parameters <span class=arithmatex>\(\theta\)</span> (equivalent of the weights of a NN) from an epoch to another can be written as function of the estimates of these two moments:</p> <div class=arithmatex>\[\begin{align} \theta_t = \theta_{t−1} − \frac{\alpha \times \hat{m}_t }{( \hat{v}_t + \epsilon)} &amp; (10). \end{align}\]</div> <p>It is interesting to note that an optimization based on Adam has an adaptive learning rate, which is deduced from the first (mean) and second (variance) moments of gradients: in Eq. (10), the effective step, proportional to a learning rate, is given by: <span class=arithmatex>\(\alpha \frac{\hat{m}_t} {\sqrt{\hat{v}_t}}\)</span>, which is <span class=arithmatex>\(t\)</span>-dependent and thus adaptive. For most of cases, it has <span class=arithmatex>\(\alpha\)</span> as upper bound. Generally, the Adam optimization is helpful when the objective function (eg. a loss or cost function) is stochastic: when it is composed of a sum of sub-functions evaluated at different sub-samples of data.</p> <h4 id=regularization>Regularization<a class=headerlink href=#regularization title="Permanent link">&para;</a></h4> <p>If one <span class=arithmatex>\(w\)</span> i is too large, a given node will dominate others. Consequently, the NN, as ensemble of nodes, will stop to learn because a few nodes will dominate the whole process while not allowing the learning through a large enough number of nodes. Therefore, one can introduce weight regularization in the loss function to penalize too large weights <span class=arithmatex>\(w\)</span>:</p> <div class=arithmatex>\[\begin{align} L_1 = L + \alpha \times \Sigma_{i,j} |w_{ij}| &amp; , &amp; L_2 = L + \alpha \times \Sigma_{i,j} |w_{ij}|^2 &amp; (11). \end{align}\]</div> <p>Practically, it is penalizing, possibly suppressing, the link between nodes <span class=arithmatex>\(i\)</span> and <span class=arithmatex>\(j\)</span>. Regularization can stop the training when eg. the <span class=arithmatex>\(L_2\)</span> norm of the difference of weights between two epochs is smaller than <span class=arithmatex>\(\epsilon\)</span>: <span class=arithmatex>\(||w_t − w_{t−k}||^2 &lt; \epsilon\)</span>; it reduces over-training.</p> <h3 id=activation-functions>Activation functions<a class=headerlink href=#activation-functions title="Permanent link">&para;</a></h3> <p>Forword: In this section <span class=arithmatex>\(x\)</span> or <span class=arithmatex>\(z\)</span> is generally the product of weights <span class=arithmatex>\(w_{ij}\)</span> and input values <span class=arithmatex>\(x_i\)</span>.</p> <p>Various activation functions are used for different nodes of a NN, their analytical properties matching the varying needs of different nodes and/or serving computational purposes. For some of activation functions, one can have <span class=arithmatex>\(\frac{\delta L}{\delta w} \sim 0\)</span> for extreme values of <span class=arithmatex>\(x\)</span>. This has the inconvience of leading to a non-learning NN.</p> <p>Let us consider the case where <span class=arithmatex>\(g(x)=x\)</span> which, through a simplified version of the NN, illustrates one of its basic capability. In this case, the outputs <span class=arithmatex>\(y_j\)</span> of the NN (see Eq. (4)) are completely linear, and provided there are enough nodes in the hidden layers versus the number of input variables, the NN would, via a linear combination of the input variables <span class=arithmatex>\(x_i\)</span>, numerically diagonalise them. If the data is such that correlations among discriminating variables are only linear, this aspect of the NN would decorrelate them. If correlations among variables/features are of higher order, the user can decorrelate them before feeding them to the NN.</p> <p>The purpose of the activation function is to introduce a non-linear functionality in the NN.</p> <ul> <li>For the first and hidden layers, the most common activation function used is the Rectified Linear Units (ReLU) function (see figure below). For positive values of <span class=arithmatex>\(x\)</span>, ReLU function is simply <span class=arithmatex>\(x\)</span>. This function avoids the <span class=arithmatex>\(\frac{\delta L}{\delta w} \sim 0\)</span> problem at positive, but not at negative values of <span class=arithmatex>\(x\)</span>. It has another advantage, which is computational: since it doesn’t contain any exponential term, it results in a training time 6 times shorter than with either sigmoid or Tanh.</li> <li>The Tanh function (see figure below) has a zero-centered output which leads to an easier learning of weights which are a mixture of positive and negative weights; however, it has also the problem <span class=arithmatex>\(\frac{\delta L}{\delta w} \sim 0\)</span> for extreme values of <span class=arithmatex>\(x\)</span>.</li> <li>The sigmoid function (see figure below) is useful for the output layer of the NN where we want a response in the <span class=arithmatex>\([0,1]\)</span> interval. For hidden layers, this function has the <span class=arithmatex>\(\frac{\delta L}{\delta w} \sim 0\)</span> problem. Furthermore, it is not zero-centered. It is usually used for the output layer of binary NN’s. If the tag of events is as defined for Eq. (1), ie. <span class=arithmatex>\(z=0/1\)</span> for B/S events, the sigmoid function allows to classify/predict S events for <span class=arithmatex>\(y&gt;0.5\)</span> and B events for <span class=arithmatex>\(y&lt;0.5\)</span>, this at a single node of the output layer, thus allowing to avoid the use of two nodes at the output layer for a binary NN.</li> <li>The Softmax activation function is typically used in the output layer of multi-class NN’s. It first amplifies the raw output scores of the nodes of the previous layer with an exponential function and then converts them into a probability distribution across multiple classes, ensuring that the probabilities for all classes sum up to 1. For example, for a NN with two nodes <span class=arithmatex>\((y_1,y_2)\)</span> at its output layer, and where each <span class=arithmatex>\(y\)</span> is an output like in Eq. (4), the outcome of the first output node is: <span class=arithmatex>\(\frac{e^{y_1}}{(e^{y_1}+e^{y_2})}\)</span>, while the one of the second output node is: <span class=arithmatex>\(\frac{e^{y_2}}{(e^{y_1}+e^{y_2})}\)</span>.</li> </ul> <blockquote> <p><img src=../images/tutorials/nn_in_cms/ActivationFunctions.png alt style="width: 500px;"> <figcaption>Figure 3</p> </blockquote> <p>Finally, we should mention the initializer, which is a notion often associated with the activation functions. An initializer is a method for initializing the weights of a NN. Its goal is to avoid different nodes learning identical mappings (like Eq. (4)) within the network. This is achieved by taking the initial weights <span class=arithmatex>\(w_{ij}\)</span> as random numbers from a uniform interval <span class=arithmatex>\([-w,+w]\)</span> or from a gaussian distribution with mean value 0 and standard deviation <span class=arithmatex>\(\sigma\)</span>. One of the most famous initializers is the Glorot method, which draws samples from a uniform distribution with limits determined by the number of input and output units in the layer. The He Normal initializer is similar to the Glorot method while being specifically designed for ReLU activation function.</p> <h3 id=number-of-epochs-batch-size>Number of epochs, batch size<a class=headerlink href=#number-of-epochs-batch-size title="Permanent link">&para;</a></h3> <p>An epoch, as referred to in the subsection "Learning/Training of a NN" is simply an iteration where the full forward- &amp; backward propagation take place, going through all training events once. The batch size <span class=arithmatex>\(b\)</span> is the number of events taken to update the weights. If <span class=arithmatex>\(N\)</span> is the number of events to be trained upon, then in 1 epoch, there are <span class=arithmatex>\(N/b\)</span> updates of the weights. Frequently, batch sizes are chosen as <span class=arithmatex>\(2^m\)</span>. The update through several batches allows multiple parameter updates per epoch. Furthermore, in the case where the partial derivative of Eq. (6) is evaluated as expectation value over a limited number of events as in the batches, the partial derivative can have a larger variance, thus sometimes helping to escape from local minima.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/Batch.png alt style="width: 500px;"> <figcaption>Figure 4</p> </blockquote> <p><b>Advice &amp; Possible pitfalls:</b> It is generally a good practice to make b large as to include enough statistics for the training within an update. This can contribute to have a training/validation curve which is more stable, ie. with less fluctuations. On the other hand, if <span class=arithmatex>\(b\)</span> is so large as to match the size of the training sample <span class=arithmatex>\(N\)</span>, there will be only one update in the training, as all data will be used to train the NN at once: this can be time consuming, and quite inefficient.</p> <h3 id=code-snippets>Code snippets<a class=headerlink href=#code-snippets title="Permanent link">&para;</a></h3> <p>We should first define the basic parameters of the NN: learning- &amp; decay-rate, architecture, and important functions (activation and initialization). In the same shot, we can also set the number of epochs and the size of the batches. NB: please note that in <a href=https://keras.io/api/optimizers/adam/ >Keras 3</a> decay has changed to <a href=https://keras.io/api/optimizers/learning_rate_schedules/ >learning rate schedules</a>.</p> <div class=highlight><pre><span></span><code><span class=n>activ</span> <span class=o>=</span> <span class=s2>&quot;relu&quot;</span>
<span class=n>LearningRate</span> <span class=o>=</span> <span class=mf>1.e-5</span>
<span class=n>DecayRate</span> <span class=o>=</span> <span class=mf>1.e-2</span>
<span class=n>NodeLayer</span> <span class=o>=</span> <span class=s2>&quot;50 50&quot;</span>
<span class=n>architecture</span><span class=o>=</span><span class=n>NodeLayer</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
<span class=n>ini</span> <span class=o>=</span> <span class=s2>&quot;he_normal&quot;</span>
<span class=n>n_epochs</span> <span class=o>=</span> <span class=mi>2000</span>
<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>10000</span>
</code></pre></div> <p>We can then pass these parameters to the optimizer, meanwhile defining other parameters of the NN such as the number of epochs and batch size. Please note that we will cover the two latter notions in the next section. Model's compilation arguments, training parameters and optimizer:</p> <div class=highlight><pre><span></span><code><span class=n>trainParams</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;epochs&#39;</span><span class=p>:</span> <span class=n>n_epochs</span><span class=p>,</span> <span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=n>batch_size</span><span class=p>,</span> <span class=s1>&#39;verbose&#39;</span><span class=p>:</span> <span class=n>verbose</span><span class=p>}</span>
<span class=n>compileArgs</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;loss&#39;</span><span class=p>:</span> <span class=s1>&#39;binary_crossentropy&#39;</span><span class=p>,</span> <span class=s1>&#39;optimizer&#39;</span><span class=p>:</span> <span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;accuracy&quot;</span><span class=p>]}</span>
<span class=n>myOpt</span> <span class=o>=</span> <span class=n>Adam</span><span class=p>(</span><span class=n>learning_rate</span><span class=o>=</span><span class=n>LearningRate</span><span class=p>,</span> <span class=n>decay</span><span class=o>=</span><span class=n>DecayRate</span><span class=p>)</span>
<span class=n>compileArgs</span><span class=p>[</span><span class=s1>&#39;optimizer&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>myOpt</span>
</code></pre></div> <p>Finally, we build the model, also compiling the arguments provided above. In the example below, we first build the first layer where there are 12 input variables, then the hidden layers which have as many layers/nodes as specified in the argument <span class=arithmatex>\(architecture\)</span>. For both initial and hidden layers, we use ReLU as activation function and he normal as initializer. We finally define the output layer with 1 single node with a sigmoid activation function.</p> <div class=highlight><pre><span></span><code><span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>()</span>
<span class=c1># 1st hidden layer: it has as many nodes as provided by architecture[0]</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>architecture</span><span class=p>[</span><span class=mi>0</span><span class=p>]),</span> <span class=n>input_dim</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activ</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>ini</span><span class=p>))</span>
<span class=n>i</span><span class=o>=</span><span class=mi>1</span>
<span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>architecture</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>architecture</span><span class=p>[</span><span class=n>i</span><span class=p>]),</span> <span class=n>activation</span><span class=o>=</span><span class=n>activ</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>ini</span><span class=p>))</span>
    <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>))</span> <span class=c1># Output layer: 1 node, with sigmoid</span>
<span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=o>**</span><span class=n>compileArgs</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
</code></pre></div> <p>Once the model is defined, we train the model:</p> <div class=highlight><pre><span></span><code><span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>xTrn</span><span class=p>,</span> <span class=n>yTrn</span><span class=p>,</span> <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>xVal</span><span class=p>,</span><span class=n>yVal</span><span class=p>,</span><span class=n>weightVal</span><span class=p>),</span> <span class=n>sample_weight</span><span class=o>=</span><span class=n>weightTrn</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>checkpoint</span><span class=p>],</span> <span class=o>**</span><span class=n>trainParams</span><span class=p>)</span>
</code></pre></div> <p>When defining the model as we did above, we provided the criterion for saving the best epoch as the one where the weights are such that the validation loss is at its minimum. The method below (called <span class=arithmatex>\(checkpoint\)</span>), which uses the <span class=arithmatex>\(callbacks\)</span> function, saves such weights, and the it is used in the line above for training:</p> <div class=highlight><pre><span></span><code><span class=n>checkpoint</span> <span class=o>=</span> <span class=n>callbacks</span><span class=o>.</span><span class=n>ModelCheckpoint</span><span class=p>(</span>
    <span class=n>filepath</span><span class=o>=</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;best_weights.h5&quot;</span><span class=p>,</span>
    <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
    <span class=n>save_weights_only</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>monitor</span><span class=o>=</span><span class=s2>&quot;val_loss&quot;</span><span class=p>,</span>
    <span class=n>mode</span><span class=o>=</span><span class=s2>&quot;min&quot;</span><span class=p>,</span>
    <span class=n>save_best_only</span><span class=o>=</span><span class=kc>True</span>
<span class=p>)</span>
</code></pre></div> <hr> <h2 id=sample-treatment>Sample treatment<a class=headerlink href=#sample-treatment title="Permanent link">&para;</a></h2> <p>A NN is a numerical machine, and numbers that it grinds need to be controlled, often balanced. In this section, we will cover the most common aspects of sample treatment for a NN. Apart from the first which deals with the splitting of the samples, all other subsections can be considered as data pre-processing.</p> <h3 id=splitting-training-validation-and-testing-samples>Splitting: training, validation, and testing samples<a class=headerlink href=#splitting-training-validation-and-testing-samples title="Permanent link">&para;</a></h3> <p>We need 3 samples: one to train the NN, another to validate the training, and another where we run the analysis and get results. The main purpose of the validation sample is to see how well the NN classifies the same type of events as either S or B, this, once exposed to events which were not included in the training; we will cover more this aspect below. Therefore, <b>the training and validation samples should be exactly similar</b>: the fraction of the total number of events that they each represent, the composition of the samples, etc. For example: (1) If the training is performed over 25% of the signal sample, then the validation sample has to include a different still 25% of the signal sample as well; the same for the background sample. (2) If the background sample is made of 75% of Wjets and 25% of ttbar events for training, one needs to keep the same percentages for the background validation sample.</p> <h3 id=event-normalization>Event normalization<a class=headerlink href=#event-normalization title="Permanent link">&para;</a></h3> <p>In the case where the values of the input variables vary by several orders of magnitude and/or are different for the various input variables, the adjusting of the NN parameters might be difficult, typically because the same weights will have to cover the possibly wildly different values. It is therefore better to render these values comparable, while they should naturally retain their discriminating power.</p> <ul> <li>One possibility is to decrease the order of magnitude of an input variable <span class=arithmatex>\(x_i\)</span> while taking into account its mean value <span class=arithmatex>\(&lt;x_i&gt;\)</span> and standard deviation <span class=arithmatex>\(\sigma_i\)</span>: <span class=arithmatex>\(x'_i = \frac{(x_i - &lt;x_i&gt;)}{\sigma_i}\)</span>.</li> <li>Another possibility is to normalize the input variables to the <span class=arithmatex>\([-1,+1]\)</span> interval. This has the property of being simple, zero-centered (which can be interesting in some cases), and will be illustrated in among the snippets below.</li> </ul> <h3 id=shuffling-seeding>Shuffling, seeding<a class=headerlink href=#shuffling-seeding title="Permanent link">&para;</a></h3> <p>It is important to randomly mix, ie. shuffle, S and B events in a given (training and/or validation) sample. This allows to not expose the training first or last to an event of a specific kind, which would bias the training. Having a data sample with eg. S events which come first can easily be the case when putting together, ie. concatenating, S and B events in a given (training or validation) sample.</p> <p>The seeding of a NN is random if left unspecified. The specification of the seeding can be useful in the case one needs an exact reproduction of results.</p> <h3 id=event-weighting-balancing>Event weighting &amp; balancing<a class=headerlink href=#event-weighting-balancing title="Permanent link">&para;</a></h3> <p>Each event i in the training should be weighted by appropriate weight wi which reflects some physics aspect(s) and the sample specificity. Namely:</p> <ul> <li>B weights should be like : <span class=arithmatex>\(w_i(B) = \frac{\sigma}{N_{tot}} \times \Pi_i SF(i) \times w(i)\)</span>, where <span class=arithmatex>\(\sigma\)</span> is the cross-section of the event under consideration, <span class=arithmatex>\(SF(i)\)</span> is the scale factor, and <span class=arithmatex>\(N_{tot}\)</span> is the total number of events. This is because the NN has to:<ul> <li>Be exposed to processes proportionally to their production rate <span class=arithmatex>\(\sigma\)</span> in SM. It has to be noted that the cross section <span class=arithmatex>\(\sigma\)</span> has to be taken into account when the B sample includes various background processes; in the case of a single background process per sample, this can be omitted and be taken as 1.</li> <li>"Be free" of number of generated events per sample.</li> <li>Be trained with simulated events resembling as much as possible to a Data event via the appropriate scale factor(s).</li> </ul> </li> <li>S weights should be like: <span class=arithmatex>\(w_i(S) = \frac{1}{N_{tot}} \times \Pi_i SF(i) \times w(i)\)</span>.</li> </ul> <p>Now these S &amp; B weights, given their definition, can be very different and lead to numerical problems in the training of the NN: for example, the validation loss can reach O(<span class=arithmatex>\(10^{-6,-7}\)</span>) very early on, and lead to weird behaviors and/or under-performance. We should therefore put events on equal footing by properly balancing each event for the training. <b>In the case of binary classification</b>, we should have something like:</p> <ul> <li>B weights should be: <span class=arithmatex>\(w_i(B) \times (\frac{N_{evt}(B)}{\Sigma_i w_i(B)})\)</span>.</li> <li>S weights should be: <span class=arithmatex>\(w_i(S) \times (\frac{N_{evt}(B)}{\Sigma_i w_i(S)})\)</span>.</li> </ul> <p>Here, both B and S weights contain the same total number of eg. B events <span class=arithmatex>\(N_{evt}(B)\)</span> as to render the respective weights numerically comparable, while naturally preserving their event-by-event differences through <span class=arithmatex>\(w_i(B,S)\)</span>.</p> <h3 id=code-snippets_1>Code snippets<a class=headerlink href=#code-snippets_1 title="Permanent link">&para;</a></h3> <p><b>Event normalization</b></p> <p>For normalizing the values of the input variables to the <span class=arithmatex>\([-1,+1]\)</span> interval, we can do the following in a loop over the full, eg. training sample:</p> <div class=highlight><pre><span></span><code><span class=n>top</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>])</span> <span class=c1># checks all lines by value of (variable in) column var</span>
<span class=n>bot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>])</span>
<span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>-</span> <span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span>
</code></pre></div> <p><b>Event shuffling</b></p> <p>For shuffling events, we can apply the following numpy command on the full eg. training sample:</p> <div class=highlight><pre><span></span><code><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>full_train</span><span class=p>)</span> 
</code></pre></div> <p>Without the former line, the NN would be first exposed to S for many events, this because we have concatenated the entire training sample with this rather common command:</p> <div class=highlight><pre><span></span><code><span class=n>full_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>train_sig</span><span class=p>,</span> <span class=n>train_bkg</span><span class=p>))</span>
</code></pre></div> <p>To make sure, and with only the risk of redundancy, we can include the shuffle command in the very line which takes care of the training of the NN:</p> <div class=highlight><pre><span></span><code><span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>xTrn</span><span class=p>,</span> <span class=n>yTrn</span><span class=p>,</span> <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>xVal</span><span class=p>,</span><span class=n>yVal</span><span class=p>,</span><span class=n>weightVal</span><span class=p>),</span> <span class=n>sample_weight</span><span class=o>=</span><span class=n>weightTrn</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>checkpoint</span><span class=p>],</span> <span class=o>**</span><span class=n>trainParams</span><span class=p>)</span>
</code></pre></div> <p><b>Event balancing</b></p> <p>For balancing the events, we normalize the weights of S and B training sample as mentioned earlier. In the case of a binary classification, we can simply have:</p> <div class=highlight><pre><span></span><code><span class=n>train_bkg</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=o>*=</span>  <span class=n>train_bkg</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>train_bkg</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>])</span>
<span class=n>train_sig</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=o>*=</span>  <span class=n>train_bkg</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>train_sig</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>])</span>
</code></pre></div> <p>where the weight of each data sample is the penultimate element of datasets train_bkg and train_sig, hence the <span class=arithmatex>\([:-2]\)</span> numpy notation.</p> <hr> <h2 id=metrics>Metrics<a class=headerlink href=#metrics title="Permanent link">&para;</a></h2> <p>Various metrics exist in order to quantify the performance, and check the sanity of a NN. Below are the main ones.</p> <h3 id=training-validation-losses-versus-epoch>Training &amp; Validation losses versus epoch<a class=headerlink href=#training-validation-losses-versus-epoch title="Permanent link">&para;</a></h3> <p>The training of the NN by definition minimizes the loss, so this latter should decrease versus the epochs for events used for training. So the calculated loss in the validation sample where the weights, as calculated for a given epoch, should have the effect of decreasing the loss in a sample non-exposed to the training. However, a training is never perfect and the loss will never reach nil. As a result, and after a number of epochs, the losses will reach and remain at a minimal and non-zero value. A typical good and realistic example of how training and validation losses should be is given in the plot below: both training and validation losses decrease and plateau after a while, and the validation loss is superior or equal to the training loss, as we do not expect the same weights to yield a better result in the validation sample than for the training sample itself.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/TrnVal_loss.png alt style="width: 500px;"> <figcaption>Figure 5</p> </blockquote> <p>The following situations are cases where one should pay attention or pitfalls:</p> <ul> <li><b>The training &amp; validation losses are increasing after having reached a minimum</b>. This can happen when, ie. from an epoch, the NN is over-fitting the data. In such a case, collecting the weights of the NN at the end of the training will not be optimal, as they will correspond to a case where the loss function isn't minimal, resulting in an under-performing NN. In such a case, as illustrated above, one can/should collect the weights of the epoch where the validation loss is at its minimum.</li> <li><b>Validation loss smaller than training loss</b>. There can be 3 reasons why this can happen.<ul> <li>Regularization is applied during training, but not during validation. Regularization leads to a set of weights which generalize better, ie NN results which are more stable for different samples, but also to slightly lower classification performance (eg. higher loss, lower accuracy).</li> <li>Depending on the software used, the training loss can be calculated at the end of each batch and then averaged over all batches of a given epoch, while the validation loss after a full epoch. In such a case, the validation loss is calculated over the full validation set (all batches), without updating at the end of each batch. For example, the default option in Keras is to return the training loss as averaged over the individual batch losses.</li> <li>The validation can be easier (to learn) than the training sample. This can happen if the validation and training sample are not formed from the same dataset, or if, for any reason, the validation data isn't as hard to classify as the training data. This can also happen if some training events are also mixed in the validation sample. If the code creating the training, validation and testing samples splits them correctly, from the same dataset, these shouldn't happen.</li> </ul> </li> </ul> <h3 id=truefalse-positivenegative>True/False positive/negative<a class=headerlink href=#truefalse-positivenegative title="Permanent link">&para;</a></h3> <p>In a binary classification, each event is either in one or the other class, classes that we call "positive" and "negative" (eg. S or B). And each event is predicted to be in one of these two classes by the NN. We can define a confusion matrix which gives the fraction of each true category as classified in a predicted class, see the figure below. Obviously, the more diagonal is this matrix, the better is the classification of the NN; we will cover a quantitative measure of the entire matrix in the subsequent section.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/TFpn.png alt style="width: 500px;"> <figcaption>Figure 6</p> </blockquote> <p>A criterion for a good classifier can be to maximize the fraction of true positive events (ie. S events classified as S) while also minimizing the false positive (ie. B events classified as S). We can report the rate of each of these events for various cuts on the NN output, as illustrated in the figure below. With this criterion, the classification power of the NN is optimal when the curve the peaks as much as possible to the top-left corner of this plot (green curve). In the opposite case, when the classifier produces as much true positive as false positive, it means that it does not have any classification power (red curve). A classifier whose curve lies between these limits is fine, but again, the closer it gets to the top-left corner, the better.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/Good-vs-Bad_ROC.png alt style="width: 500px;"> <figcaption>Figure 7</p> </blockquote> <p>A quantitative measure of this "peaking" by the area under the (roc) curve, is reported in the figure below: the greater is this area, the better is the classification.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/TrnVal_roc.png alt style="width: 500px;"> <figcaption>Figure 8</p> </blockquote> <h3 id=accuracy-versus-epoch>Accuracy versus epoch<a class=headerlink href=#accuracy-versus-epoch title="Permanent link">&para;</a></h3> <p>A quantity measuring in a single shot all the elements of the binary confusion matrix is the accuracy, defined as the ratio of events classified in their correct classes to all events:</p> <div class=arithmatex>\[\begin{align} Accuracy = \frac{True_{positive} + True_{negative} }{ True_{positive} + True_{negative} + False_{positive} + False_{negative}} &amp; (12), \end{align}\]</div> <p>In the example below, we can observe an NN improving the accuracy after each epoch, and somehow plateau after a certain number of epochs:</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/TrnVal_accuracy.png alt style="width: 500px;"> <figcaption>Figure 9</p> </blockquote> <h3 id=multi-class-nn-confusion-matrix>Multi-class NN: confusion matrix<a class=headerlink href=#multi-class-nn-confusion-matrix title="Permanent link">&para;</a></h3> <p>In the case of a multi-class NN, the confusion simply has more than two classes, as illustrated below. Again, the more diagonal is the matrix, the more correct is the classification.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/Confusion_Matrix.png alt style="width: 500px;"> <figcaption>Figure 10</p> </blockquote> <h3 id=over-training>Over-training<a class=headerlink href=#over-training title="Permanent link">&para;</a></h3> <p>We briefly mentioned at the start of the previous section the justification for having a validation sample. Through a comparison of the performance of the NN in the training and validation samples, one is testing the reproducibility of the NN: whether the NN 's response is similar for events that it has been trained upon (training sample) or events that it hasn't been exposed to (validation sample); this response should not depend on events. Therefore, <b>the NN's response should be similar in the training and validation samples, for both S and B events</b>.</p> <p>\rightarrow One simple way to check for over-training is to overlay the NN output distribution in the training and validation samples (for S events on one hand, and for B events on the other), and make sure that that they are compatible within statistical uncertainties. In the example below, a comparison is provided between the validation and test samples.</p> <blockquote> <p><img src=../images/tutorials/nn_in_cms/Perf_NNoutput.png alt style="width: 500px;"> <figcaption>Figure 11</p> </blockquote> <h3 id=assess-performance-of-classification-in-analysis>Assess performance of classification in analysis<a class=headerlink href=#assess-performance-of-classification-in-analysis title="Permanent link">&para;</a></h3> <p>An area under the receiver operating characteristics curve (auroc) is essentially measuring true S and B events being predicted as S events. Maximizing the auroc is mainly maximizing the S/B ratio. Here, there is no uncertainty of any kind taken into account. This is obviously insufficient for gauging the classification power of an ML tool in a real analysis situation, where both statistical and systematic uncertainties have to be accounted for. Beyond the auroc's, and in order to capture a more complete statistical picture of an analysis, one can define a Figure Of Merit, which is a quantity :</p> <div class=arithmatex>\[\begin{align} FOM = \frac{S}{\sigma_T} &amp; (13), \end{align}\]</div> <p>where S and σT are the signal yield and the total uncertainty, respectively. The total uncertainty is the quadratic sum of the systematic uncertainty on the background σB and the total statistical uncertainty, itself the quadratic sum of the statistical uncertainties on the signal and background. If we assume Poisson uncertainty for the statistical uncertainty on the yields, we have:</p> <div class=arithmatex>\[\begin{align} FOM = \frac{S}{\sqrt{S+B+\sigma_B^2}} &amp; (14), \end{align}\]</div> <p>where B is the background yield. If the analyzer knows that the measurement is going to be dominated by statistical uncertainties, then the expression above simplifies to:</p> <div class=arithmatex>\[\begin{align} FOM = \frac{S}{\sqrt{S+B}} &amp; (14-a). \end{align}\]</div> <p>If the analyzer further thinks that the statistical uncertainty on the signal is negligible when compared to the one on the background, the expression further simplifies to the well known expression:</p> <div class=arithmatex>\[\begin{align} FOM = \frac{S}{\sqrt{B}} &amp; (14-b). \end{align}\]</div> <p>It has to be noted that even with the most simplifying assumptions, the FOM above is close to, but not the same than S/B, which is effectively what the auroc is about.</p> <h3 id=code-snippets_2>Code snippets<a class=headerlink href=#code-snippets_2 title="Permanent link">&para;</a></h3> <p><b>Loss &amp; accuracy curves</b></p> <p>For obtaining the loss and accuracy (versus epoch) curves, we should first include them among the very list of arguments to be compiled. For the loss, we should specify which type of loss we want, and for the accuracy, we should include it among the metrics:</p> <div class=highlight><pre><span></span><code><span class=n>compileArgs</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;loss&#39;</span><span class=p>:</span> <span class=s1>&#39;binary_crossentropy&#39;</span><span class=p>,</span> <span class=s1>&#39;optimizer&#39;</span><span class=p>:</span> <span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;accuracy&quot;</span><span class=p>]}</span>
</code></pre></div> <p>Then, and after having trained the model, we can obtain these curves for the training and validation samples with the following lines:</p> <div class=highlight><pre><span></span><code><span class=n>loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]</span>
<span class=n>val_loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_loss&#39;</span><span class=p>]</span>
<span class=n>acc</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s2>&quot;accuracy&quot;</span><span class=p>]</span>
<span class=n>val_acc</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_accuracy&#39;</span><span class=p>]</span>
</code></pre></div> <p><b>ROC curves</b></p> <p>In order calculate the roc curve and the auroc, one should first import the corresponding libraries:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>roc_curve</span><span class=p>,</span> <span class=n>auc</span>
</code></pre></div> <p>We can then obtain the roc cruve and the auroc, for both the training and validation samples, with the following lines:</p> <div class=highlight><pre><span></span><code><span class=n>y_pred_Trn</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xTrn</span><span class=p>)</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
<span class=n>fpr_Trn</span><span class=p>,</span> <span class=n>tpr_Trn</span><span class=p>,</span> <span class=n>thresholds_Trn</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>yTrn</span><span class=p>,</span> <span class=n>y_pred_Trn</span><span class=p>)</span>
<span class=n>auc_Trn</span> <span class=o>=</span> <span class=n>auc</span><span class=p>(</span><span class=n>fpr_Trn</span><span class=p>,</span> <span class=n>tpr_Trn</span><span class=p>)</span>
<span class=n>y_pred_Val</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xVal</span><span class=p>)</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
<span class=n>fpr_Val</span><span class=p>,</span> <span class=n>tpr_Val</span><span class=p>,</span> <span class=n>thresholds_Val</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>yVal</span><span class=p>,</span> <span class=n>y_pred_Val</span><span class=p>)</span>
<span class=n>auc_Val</span> <span class=o>=</span> <span class=n>auc</span><span class=p>(</span><span class=n>fpr_Val</span><span class=p>,</span> <span class=n>tpr_Val</span><span class=p>)</span>
</code></pre></div> <hr> <h2 id=full-codes>Full codes<a class=headerlink href=#full-codes title="Permanent link">&para;</a></h2> <p>The purpose of this part is to give an example of full and working script, for each type of classification (binary and multi-class). These scripts are meant to be illustrative and are naturally improvable. They are commented quite extensively as to guide explain the different aspects of the code. Each code has two type of outputs:</p> <ul> <li>Plots which provide information about the training (eg. loss, accuracy versus epoch)</li> <li>Files which are usable for further investigation of the NN (eg. performance).</li> </ul> <p>Both scripts are based on python, and use Keras. Both run on csv files where each line represents the entries for an event, and where:</p> <ul> <li>the N first columns are the N input variables: discriminating features, which can either be continuous or discrete variables. Examples: <span class=arithmatex>\(p_T\)</span> and spatial distribution of various reconstructed particles, invariant masses, charge and identification and isolation variables of leptons, jet- and b-tag multiplicities, b-tagging discriminant distributions, ...</li> <li>followed by a column containing the event weight:</li> <li>and then by a column containing the string specifying the physical process of the event; the way that the script expects this string is in the NameProcess.root (eg. ttbar.root) form.</li> </ul> <p>This order is important as the numpy manipulation the various elements of the csv file in the script naturally takes it into account. In a certain measure, and for secondary aspects, the two codes have different functionalities, as to illustrate various possible outcomes.</p> <h3 id=binary>Binary<a class=headerlink href=#binary title="Permanent link">&para;</a></h3> <p>The script for the binary NN uses numpy for the manipulation of vectors. It is meant to turn on csv files which provide N=12 input variables. It is integrating all snippets mentioned in previous sections. Its outcomes are:</p> <ul> <li>3 plots: TrnVal_loss.png, TrnVal_accuracy.png, TrnVal_roc.png, respectively showing the evolution of the loss, accuracy, and roc curves as a function of the epoch, these for the training and validation samples.</li> <li>A file for weights: best_weights.h5 which has the weights of the NN corresponding to the epoch where the validation loss is the lowest, ie. the best weights one can get from the NN training. This file is useful downstream calculations (eg. for calculating the performance of the NN).</li> <li>2 files val_output.csv and test_output.csv, where the outputs of the NN are saved for the validation and test samples, and which are necessary for downstream calculations.</li> </ul> <details class=example> <summary>Full Code Binary</summary> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>os</span>
<span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class=p>]</span><span class=o>=</span><span class=s1>&#39;2&#39;</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras</span> <span class=kn>import</span> <span class=o>*</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.optimizer_v2.adam</span> <span class=kn>import</span> <span class=n>Adam</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.models</span> <span class=kn>import</span> <span class=n>Sequential</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.layers</span> <span class=kn>import</span> <span class=n>Dense</span><span class=p>,</span> <span class=n>Dropout</span><span class=p>,</span> <span class=n>AlphaDropout</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.regularizers</span> <span class=kn>import</span> <span class=n>l2</span>
<span class=kn>from</span> <span class=nn>tensorflow.keras.mixed_precision</span> <span class=kn>import</span> <span class=n>experimental</span> <span class=k>as</span> <span class=n>mixed_precision</span>

<span class=c1>#from tensorflow.python.keras.utils import metrics_utils</span>

<span class=kn>import</span> <span class=nn>numpy</span>
<span class=kn>import</span> <span class=nn>time</span>
<span class=kn>import</span> <span class=nn>pandas</span>
<span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>cohen_kappa_score</span><span class=p>,</span> <span class=n>roc_curve</span><span class=p>,</span> <span class=n>auc</span>
<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
<span class=kn>import</span> <span class=nn>pickle</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>

<span class=k>def</span> <span class=nf>assure_path_exists</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
        <span class=n>os</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>path</span><span class=p>)</span>

<span class=k>def</span> <span class=nf>load_data</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>tag</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot; Read data from CSV</span>
<span class=sd>    Args:</span>
<span class=sd>    path (str): path to the data</span>
<span class=sd>    tag (int): 1 if signal, 0 if background</span>
<span class=sd>    Returns:</span>
<span class=sd>    np.c_[data, tag] (np.array): array with data and tag</span>
<span class=sd>    label (np.array): array with the name of event process</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>full_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>loadtxt</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>delimiter</span><span class=o>=</span><span class=s2>&quot;,&quot;</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;str&quot;</span><span class=p>)</span>
    <span class=n>tag</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>full_data</span><span class=p>))</span><span class=o>*</span><span class=n>tag</span>
    <span class=n>label</span> <span class=o>=</span> <span class=n>full_data</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span>
    <span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>full_data</span><span class=p>[:,:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;float&quot;</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>data</span><span class=p>,</span> <span class=n>tag</span><span class=p>],</span> <span class=n>label</span>

<span class=k>def</span> <span class=nf>mae</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>):</span>
    <span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>y_true</span><span class=p>)</span>
    <span class=n>error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>error</span> <span class=o>/</span> <span class=n>n</span>

<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
    <span class=kn>import</span> <span class=nn>argparse</span>
    <span class=kn>import</span> <span class=nn>sys</span>

    <span class=c1># Uses the &quot;weight&quot; variable of roottuples: provided as (N(input vars)+1)th variable in csv files</span>
    <span class=c1># Passed on weightTrn &amp; weightVal for appropriate samples</span>
    <span class=c1># Weighting each event by these vectors: effectively weighting samples of various XS &amp; Nevts, thus</span>
    <span class=c1># no need of a single &quot;Background.root&quot;</span>

    <span class=c1># Input arguments from command line</span>
    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>(</span><span class=n>description</span><span class=o>=</span><span class=s1>&#39;Process the command line options&#39;</span><span class=p>)</span>
    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;-v&#39;</span><span class=p>,</span> <span class=s1>&#39;--verbose&#39;</span><span class=p>,</span> <span class=n>action</span><span class=o>=</span><span class=s1>&#39;store_true&#39;</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s1>&#39;Whether to print verbose output&#39;</span><span class=p>)</span>
    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;-y&#39;</span><span class=p>,</span> <span class=s1>&#39;--year&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s1>&#39;Year of data being trained&#39;</span><span class=p>)</span>
    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;-c&#39;</span><span class=p>,</span> <span class=s1>&#39;--channel&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s1>&#39;Final state of data being trained&#39;</span><span class=p>)</span>
    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;-n&#39;</span><span class=p>,</span> <span class=s1>&#39;--name&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s1>&#39;model name&#39;</span><span class=p>)</span>

    <span class=n>args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>

    <span class=c1>### Read input arguments</span>
    <span class=n>year</span> <span class=o>=</span> <span class=n>args</span><span class=o>.</span><span class=n>year</span>
    <span class=n>channel</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>channel</span>
    <span class=n>name</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>name</span>
    <span class=n>verbose</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>if</span> <span class=n>args</span><span class=o>.</span><span class=n>verbose</span><span class=p>:</span>
        <span class=n>verbose</span> <span class=o>=</span> <span class=mi>1</span>
    <span class=c1>###</span>

    <span class=c1>### NN parameters</span>
    <span class=n>activ</span> <span class=o>=</span> <span class=s2>&quot;relu&quot;</span>
    <span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>5.e-3</span>
    <span class=n>decay_rate</span> <span class=o>=</span> <span class=mf>0.</span>
    <span class=c1># Each number (here 50) is the number of nodes (Nnode) in each layer.</span>
    <span class=c1># The number of different Nnode (here 2) is the number of layers.</span>
    <span class=n>NodeLayer</span> <span class=o>=</span> <span class=s2>&quot;50 50&quot;</span>
    <span class=n>architecture</span><span class=o>=</span><span class=n>NodeLayer</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
    <span class=n>ini</span> <span class=o>=</span> <span class=s2>&quot;he_normal&quot;</span> <span class=c1># Function for initialising the random weights of the layer</span>
    <span class=n>n_epochs</span> <span class=o>=</span> <span class=mi>2000</span>
    <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>5000</span>
    <span class=n>dropout_rate</span> <span class=o>=</span> <span class=mf>0.</span>
    <span class=c1>###</span>

    <span class=c1># Model&#39;s compilation arguments, training parameters and optimizer</span>
    <span class=n>compileArgs</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;loss&#39;</span><span class=p>:</span> <span class=s1>&#39;binary_crossentropy&#39;</span><span class=p>,</span> <span class=s1>&#39;optimizer&#39;</span><span class=p>:</span> <span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;accuracy&quot;</span><span class=p>]}</span>
    <span class=n>trainParams</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;epochs&#39;</span><span class=p>:</span> <span class=n>n_epochs</span><span class=p>,</span> <span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=n>batch_size</span><span class=p>,</span> <span class=s1>&#39;verbose&#39;</span><span class=p>:</span> <span class=n>verbose</span><span class=p>}</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>Adam</span><span class=p>)</span>
    <span class=c1># Define optimizer which has the learning- &amp; decay-rates</span>
    <span class=n>myOpt</span> <span class=o>=</span> <span class=n>Adam</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span> <span class=n>decay</span><span class=o>=</span><span class=n>decay_rate</span><span class=p>)</span>
    <span class=c1># Protect from rounding errors: Number by which the loss-function is multiplied to protect from rounding errors</span>
    <span class=c1>#                               dynamically scales the loss to prevent underflow</span>
<span class=c1>#    myOpt = mixed_precision.LossScaleOptimizer(myOpt, 1e5)</span>
    <span class=n>compileArgs</span><span class=p>[</span><span class=s1>&#39;optimizer&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>myOpt</span>

    <span class=c1># Creating the directory where the files will be stored</span>
    <span class=n>dirname</span> <span class=o>=</span> <span class=n>year</span><span class=o>+</span><span class=s2>&quot;_&quot;</span><span class=o>+</span><span class=n>channel</span><span class=o>+</span><span class=s2>&quot;_&quot;</span><span class=o>+</span><span class=n>name</span>
    <span class=n>filepath</span> <span class=o>=</span> <span class=s2>&quot;models/</span><span class=si>{}</span><span class=s2>/&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>dirname</span><span class=p>)</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>filepath</span><span class=p>):</span>
        <span class=n>os</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>filepath</span><span class=p>)</span>

    <span class=c1># Printing info and starting time</span>
    <span class=k>if</span> <span class=n>args</span><span class=o>.</span><span class=n>verbose</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Dir &quot;</span><span class=o>+</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot; created.&quot;</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Starting the training&quot;</span><span class=p>)</span>
        <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>

    <span class=c1>##### Build the model</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>()</span>

    <span class=c1># 1st hidden layer: it has as many nodes as provided by architecture[0]: 12 b/c that much input variables</span>
    <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>architecture</span><span class=p>[</span><span class=mi>0</span><span class=p>]),</span> <span class=n>input_dim</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activ</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>ini</span><span class=p>))</span>

    <span class=n>i</span><span class=o>=</span><span class=mi>1</span>
    <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>architecture</span><span class=p>)</span> <span class=p>:</span>
        <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>architecture</span><span class=p>[</span><span class=n>i</span><span class=p>]),</span> <span class=n>activation</span><span class=o>=</span><span class=n>activ</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>ini</span><span class=p>))</span>
<span class=c1>#        model.add(kernel_regularizer=l2(1e-5))</span>
<span class=c1>#        model.add(Dropout(dropout_rate))</span>
        <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span>
    <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>))</span> <span class=c1># Output layer: 1 node, with sigmoid</span>

    <span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=o>**</span><span class=n>compileArgs</span><span class=p>)</span>
    <span class=n>model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
    <span class=c1>#####</span>

    <span class=c1># Read input data</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;LOADING DATA&quot;</span><span class=p>)</span>
    <span class=c1># Do the labeling for S &amp; B to 1 &amp; 0 for train, val and test samples</span>
    <span class=c1># For train sample: avoid writing the value of label with &quot;_&quot;, </span>
    <span class=n>train_sig</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>load_data</span><span class=p>(</span><span class=s2>&quot;data/train_sig.csv&quot;</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>train_bkg</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>load_data</span><span class=p>(</span><span class=s2>&quot;data/train_bkg.csv&quot;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
    <span class=c1># validation sample</span>
    <span class=n>val_sig</span><span class=p>,</span> <span class=n>label_val_sig</span> <span class=o>=</span> <span class=n>load_data</span><span class=p>(</span><span class=s2>&quot;data/val_sig.csv&quot;</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>val_bkg</span><span class=p>,</span> <span class=n>label_val_bkg</span> <span class=o>=</span> <span class=n>load_data</span><span class=p>(</span><span class=s2>&quot;data/val_bkg.csv&quot;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
    <span class=n>val_label</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>label_val_sig</span><span class=p>,</span> <span class=n>label_val_bkg</span><span class=p>))</span>
    <span class=n>val_label</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>l</span><span class=p>[:</span><span class=o>-</span><span class=mi>5</span><span class=p>]</span> <span class=k>for</span> <span class=n>l</span> <span class=ow>in</span> <span class=n>val_label</span><span class=p>])</span> <span class=c1># Keep all file/process name except &quot;.root&quot; to identify processes</span>
    <span class=c1># test sample</span>
    <span class=n>test_sig</span><span class=p>,</span> <span class=n>label_test_sig</span> <span class=o>=</span> <span class=n>load_data</span><span class=p>(</span><span class=s2>&quot;data/test_sig.csv&quot;</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>test_bkg</span><span class=p>,</span> <span class=n>label_test_bkg</span> <span class=o>=</span> <span class=n>load_data</span><span class=p>(</span><span class=s2>&quot;data/test_bkg.csv&quot;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
    <span class=n>test_label</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>label_test_sig</span><span class=p>,</span> <span class=n>label_test_bkg</span><span class=p>))</span>
    <span class=n>test_label</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>l</span><span class=p>[:</span><span class=o>-</span><span class=mi>5</span><span class=p>]</span> <span class=k>for</span> <span class=n>l</span> <span class=ow>in</span> <span class=n>test_label</span><span class=p>])</span> <span class=c1>#  Keep all file/process name except &quot;.root&quot; to identify processes</span>
    <span class=c1># Concatenation of variables and weights only</span>
    <span class=c1># NB: could have been done in the general form (concatenate the total object, as above)</span>
    <span class=n>test_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>test_sig</span><span class=p>[:,</span> <span class=p>:</span><span class=o>-</span><span class=mi>2</span><span class=p>],</span> <span class=n>test_bkg</span><span class=p>[:,</span> <span class=p>:</span><span class=o>-</span><span class=mi>2</span><span class=p>]))</span>
    <span class=n>test_weight</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>test_sig</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>2</span><span class=p>],</span> <span class=n>test_bkg</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>2</span><span class=p>]))</span>

    <span class=c1># Weight normalisation, event balancing:</span>
    <span class=c1># Render the sum of S events equal to sum of B events</span>
    <span class=c1># The totality of weights should be equal, even though the relative weights</span>
    <span class=c1># among B or S signal are correct by weighting each event by the &quot;weight&quot;</span>
    <span class=c1># variable in the roottuples</span>
<span class=c1>#    train_sig[:, -2]*=np.sum(train_bkg[:, -2])/np.sum(train_sig[:, -2])</span>
    <span class=c1># AND</span>
    <span class=c1># each sample should be numerically not too small: normalize by the N(B),</span>
    <span class=c1># both for S &amp; B, in both training &amp; validation sample</span>
    <span class=n>train_bkg</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=o>*=</span>  <span class=n>train_bkg</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>train_bkg</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>])</span>
    <span class=n>train_sig</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=o>*=</span>  <span class=n>train_bkg</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>train_sig</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>])</span>
    <span class=c1># Save unweighted values of validation weights, to be written in val_output.csv</span>
    <span class=n>full_val_not_scaled</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>val_sig</span><span class=p>,</span> <span class=n>val_bkg</span><span class=p>))</span>
    <span class=n>weightVal_not_scaled</span> <span class=o>=</span> <span class=n>full_val_not_scaled</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>2</span><span class=p>]</span>
    <span class=n>val_bkg</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=o>*=</span>  <span class=n>val_bkg</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>val_bkg</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>])</span>
    <span class=n>val_sig</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=o>*=</span>  <span class=n>val_bkg</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>val_sig</span><span class=p>[:,</span><span class=o>-</span><span class=mi>2</span><span class=p>])</span>

    <span class=c1># Concatenate signal and background for train and validation</span>
    <span class=n>full_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>train_sig</span><span class=p>,</span> <span class=n>train_bkg</span><span class=p>))</span>
    <span class=n>full_val</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>val_sig</span><span class=p>,</span> <span class=n>val_bkg</span><span class=p>))</span>

    <span class=c1># Variables normalisation to [-1,+1]</span>
    <span class=c1># Looping over number of variables:</span>
    <span class=c1>#   shape = Dimension of the full_train (variables * Nevts) array</span>
    <span class=c1>#   shape[0] gives lines: the dimension is Nevts</span>
    <span class=c1>#   shape[1] gives columns: the dimension here is 12 (for input vars.) + 1 (weight) + 1 (tag=0,1)</span>
    <span class=k>for</span> <span class=n>var</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>full_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=mi>2</span><span class=p>):</span>
    <span class=n>top</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>])</span> <span class=c1># checks all lines by value of (variable in) column var</span>
    <span class=n>bot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>])</span>
    <span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_train</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>-</span> <span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span>
    <span class=n>full_val</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_val</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>-</span> <span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span>
    <span class=n>test_data</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>test_data</span><span class=p>[:,</span> <span class=n>var</span><span class=p>]</span> <span class=o>-</span> <span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span> <span class=o>-</span> <span class=n>bot</span><span class=p>)</span>

    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>full_train</span><span class=p>)</span> <span class=c1># Without this line: NN first exposed to S for many events: b/c fullt_train = np.concatenate((train_sig, train_bkg))</span>
    <span class=n>xTrn</span> <span class=o>=</span> <span class=n>full_train</span><span class=p>[:,</span> <span class=p>:</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=c1># Input of NN (kinematic variables)</span>
    <span class=n>yTrn</span> <span class=o>=</span> <span class=n>full_train</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=c1># Target of NN (1 for signal, 0 for background)</span>
    <span class=n>weightTrn</span> <span class=o>=</span> <span class=n>full_train</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>2</span><span class=p>]</span>
    <span class=n>xVal</span> <span class=o>=</span> <span class=n>full_val</span><span class=p>[:,</span> <span class=p>:</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span>
    <span class=n>yVal</span> <span class=o>=</span> <span class=n>full_val</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span>
    <span class=n>weightVal</span> <span class=o>=</span> <span class=n>full_val</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>2</span><span class=p>]</span>

    <span class=c1># Define criterium for best epoch saving</span>
    <span class=c1># Returns the weights as they are at the minimum, b/c of argument of mode</span>
    <span class=n>checkpoint</span> <span class=o>=</span> <span class=n>callbacks</span><span class=o>.</span><span class=n>ModelCheckpoint</span><span class=p>(</span>
    <span class=n>filepath</span><span class=o>=</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;best_weights.h5&quot;</span><span class=p>,</span>
    <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
    <span class=n>save_weights_only</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>monitor</span><span class=o>=</span><span class=s2>&quot;val_loss&quot;</span><span class=p>,</span>
    <span class=n>mode</span><span class=o>=</span><span class=s2>&quot;min&quot;</span><span class=p>,</span>
    <span class=n>save_best_only</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

    <span class=c1>### Train model ###</span>
    <span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>xTrn</span><span class=p>,</span> <span class=n>yTrn</span><span class=p>,</span> <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>xVal</span><span class=p>,</span><span class=n>yVal</span><span class=p>,</span><span class=n>weightVal</span><span class=p>),</span> <span class=n>sample_weight</span><span class=o>=</span><span class=n>weightTrn</span><span class=p>,</span><span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>checkpoint</span><span class=p>],</span> <span class=o>**</span><span class=n>trainParams</span><span class=p>)</span>

    <span class=n>loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]</span>
    <span class=n>val_loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_loss&#39;</span><span class=p>]</span>
    <span class=n>acc</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s2>&quot;accuracy&quot;</span><span class=p>]</span>
    <span class=n>val_acc</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_accuracy&#39;</span><span class=p>]</span>

    <span class=c1># Saving accuracy and loss values in a pickle file for later plotting</span>
    <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>acc</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;acc.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>
    <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;loss.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>
    <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>val_acc</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;val_acc.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>
    <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>val_loss</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;val_loss.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>

    <span class=c1># Getting the roc curve</span>
    <span class=n>y_pred_Trn</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xTrn</span><span class=p>)</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
    <span class=n>fpr_Trn</span><span class=p>,</span> <span class=n>tpr_Trn</span><span class=p>,</span> <span class=n>thresholds_Trn</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>yTrn</span><span class=p>,</span> <span class=n>y_pred_Trn</span><span class=p>)</span>
    <span class=n>auc_Trn</span> <span class=o>=</span> <span class=n>auc</span><span class=p>(</span><span class=n>fpr_Trn</span><span class=p>,</span> <span class=n>tpr_Trn</span><span class=p>)</span>
    <span class=n>y_pred_Val</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xVal</span><span class=p>)</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
    <span class=n>fpr_Val</span><span class=p>,</span> <span class=n>tpr_Val</span><span class=p>,</span> <span class=n>thresholds_Val</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>yVal</span><span class=p>,</span> <span class=n>y_pred_Val</span><span class=p>)</span>
    <span class=n>auc_Val</span> <span class=o>=</span> <span class=n>auc</span><span class=p>(</span><span class=n>fpr_Val</span><span class=p>,</span> <span class=n>tpr_Val</span><span class=p>)</span>

    <span class=c1># Getting errors</span>
<span class=c1>#    mae_Trn = mae(yTrn, y_pred_Trn)</span>
<span class=c1>#    mae_Val = mae(yVal, y_pred_Val)</span>

    <span class=c1># Plot loss curves</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Training loss&quot;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>val_loss</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Validation loss&quot;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>    
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Epoch&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Loss&#39;</span><span class=p>)</span>
<span class=c1>#    plt.yscale(&quot;log&quot;)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;TrnVal_loss.png&quot;</span><span class=p>)</span>
    <span class=c1># Plot accuracy curves</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>acc</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Training accuracy&quot;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>val_acc</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Validation accuracy&quot;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Epoch&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Accuracy&#39;</span><span class=p>)</span>
<span class=c1>#    plt.yscale(&quot;log&quot;)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;TrnVal_accuracy.png&quot;</span><span class=p>)</span>
    <span class=c1># Plot ROC curves</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=s1>&#39;k--&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>fpr_Trn</span><span class=p>,</span> <span class=n>tpr_Trn</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Training ROC (area = </span><span class=si>{:.2f}</span><span class=s1>)&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>auc_Trn</span><span class=p>))</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>fpr_Val</span><span class=p>,</span> <span class=n>tpr_Val</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Validation ROC (area = </span><span class=si>{:.2f}</span><span class=s1>)&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>auc_Val</span><span class=p>))</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;False positive rate&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True positive rate&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;TrnVal_roc.png&quot;</span><span class=p>)</span>
<span class=c1>#    plt.figure(4)</span>
<span class=c1>##    plt.plot([0, 100], &#39;k--&#39;)</span>
<span class=c1>#    plt.plot(mae_Trn, label=&quot;Training MAE&quot;)</span>
<span class=c1>#    plt.plot(mae_Val, label=&quot;Validation MAE&quot;)</span>
<span class=c1>#    plt.legend()</span>
<span class=c1>#    plt.xlabel(&#39;N(events)&#39;)</span>
<span class=c1>#    plt.ylabel(&#39;MAE&#39;)</span>
<span class=c1>#    plt.savefig(filepath+&quot;TrnVal_mae.png&quot;)</span>

    <span class=c1># Time of the training</span>
    <span class=k>if</span> <span class=n>args</span><span class=o>.</span><span class=n>verbose</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training took &quot;</span><span class=p>,</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span><span class=o>-</span><span class=n>start</span><span class=p>)</span><span class=o>//</span><span class=mi>60</span><span class=p>,</span> <span class=s2>&quot; minutes&quot;</span><span class=p>)</span>

    <span class=c1># Getting predictions</span>
    <span class=k>if</span> <span class=n>args</span><span class=o>.</span><span class=n>verbose</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Getting predictions&quot;</span><span class=p>)</span>

    <span class=n>model</span><span class=o>.</span><span class=n>load_weights</span><span class=p>(</span><span class=n>filepath</span> <span class=o>+</span> <span class=s2>&quot;best_weights.h5&quot;</span><span class=p>)</span> <span class=c1># Loading best epoch weights</span>

    <span class=c1># Compute and save prediction for best epoch</span>
    <span class=n>trnPredict</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xTrn</span><span class=p>)</span>
    <span class=n>valPredict</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xVal</span><span class=p>)</span>
    <span class=n>testPredict</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>test_data</span><span class=p>)</span>
<span class=c1>#    np.savetxt(filepath+&quot;val_output.csv&quot;, np.c_[valPredict, weightVal, val_label], delimiter=&quot;,&quot;, fmt=&quot;%s&quot;)</span>
    <span class=n>np</span><span class=o>.</span><span class=n>savetxt</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;val_output.csv&quot;</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>valPredict</span><span class=p>,</span> <span class=n>weightVal_not_scaled</span><span class=p>,</span> <span class=n>val_label</span><span class=p>],</span> <span class=n>delimiter</span><span class=o>=</span><span class=s2>&quot;,&quot;</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s2>&quot;</span><span class=si>%s</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=n>np</span><span class=o>.</span><span class=n>savetxt</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;test_output.csv&quot;</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>testPredict</span><span class=p>,</span> <span class=n>test_weight</span><span class=p>,</span> <span class=n>test_label</span><span class=p>],</span> <span class=n>delimiter</span><span class=o>=</span><span class=s2>&quot;,&quot;</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s2>&quot;</span><span class=si>%s</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Outputs</span>
<span class=c1>#    plt.savefig(filepath+&quot;loss.png&quot;)</span>
    <span class=n>val_file</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span> <span class=o>+</span> <span class=s2>&quot;val_loss.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;rb&quot;</span><span class=p>)</span>
    <span class=n>val</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>val_file</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Epoch of the best training: &quot;</span><span class=p>,</span><span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>val</span><span class=p>))</span>
</code></pre></div> </details> <h3 id=multiclass>Multiclass<a class=headerlink href=#multiclass title="Permanent link">&para;</a></h3> <p>The script for the multi-class NN is classifying 5 different processes (Signal, Wjets, TTbar, Z2nu, Other), and has thus 5 different classes. It uses panda for the manipulation of vectors, and is performing this manipulation slightly differently than in the binary script, but with similar outcomes. It is meant to turn on csv files which provide N=17 input variables. This script is performing 2 loops, the first being nested in the second:</p> <ul> <li>It is simply running 10 times, letting all random-based processes (initialization, shuffling, seeding) produce 10 different results, which are close in performance.</li> <li>It is scanning the decay-rate from <span class=arithmatex>\(10^{-5}\)</span> to <span class=arithmatex>\(10^{-3}\)</span>.</li> </ul> <p>It goes without saying that these loops can be taken out, or modified. This script has performance calculation capacity embedded in it, and doesn't need a downstream script to be run. The outcomes of the script are:</p> <ul> <li>A file 17var_fom.csv necessary for possible downstream performance calculations.</li> <li>10 different subdirectories, corresponding to the 10 runs, with each containing:</li> <li>2 plots: TrnVal_loss.png, TrnVal_accuracy.png, as in the binary case.</li> <li>A file for weights best_weights.h5, as in the binary case.</li> <li>A subdirectory FOM_figures_runs/ which has the performance plots of all 10 runs in it.</li> </ul> <p>As for the event balancing used in the case of multi-class NN, we do an event weighting similar yet different than in the "Event weighting &amp; balancing" section. Interested users are invited to look at slides 10-13 and 23 of <a href=https://indico.cern.ch/event/1503118/contributions/6327106/subcontributions/539906/attachments/3037743/5366723/PBargassa_ML3.pdf>this presentation</a>; referring to these slides, the balancing scheme used in this script is the "SQRT".</p> <details class=example> <summary>Full Code Multiclass</summary> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>os</span>
<span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class=p>]</span><span class=o>=</span><span class=s1>&#39;2&#39;</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras</span> <span class=kn>import</span> <span class=o>*</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras</span> <span class=kn>import</span> <span class=n>backend</span> <span class=k>as</span> <span class=n>K</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.optimizer_v2.adam</span> <span class=kn>import</span> <span class=n>Adam</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.models</span> <span class=kn>import</span> <span class=n>Sequential</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.layers</span> <span class=kn>import</span> <span class=n>Dense</span><span class=p>,</span> <span class=n>Dropout</span>
<span class=kn>from</span> <span class=nn>tensorflow.python.keras.regularizers</span> <span class=kn>import</span> <span class=n>l2</span>
<span class=c1>#from tensorflow.keras.mixed_precision import experimental as mixed_precision</span>

<span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>

<span class=kn>import</span> <span class=nn>numpy</span>
<span class=kn>import</span> <span class=nn>time</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>cohen_kappa_score</span><span class=p>,</span> <span class=n>roc_curve</span><span class=p>,</span> <span class=n>auc</span>
<span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
<span class=kn>import</span> <span class=nn>pickle</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>

<span class=k>def</span> <span class=nf>assure_path_exists</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
        <span class=n>os</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>path</span><span class=p>)</span>

<span class=c1># Takes strings of processes from XYZ.root and returns abbreviated name XY as name of the process</span>
<span class=k>def</span> <span class=nf>rename_rows</span><span class=p>(</span><span class=n>label</span><span class=p>):</span>
    <span class=n>filenames</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>label</span><span class=p>)</span>
    <span class=n>names</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>filenames</span><span class=p>:</span>
        <span class=n>tag</span> <span class=o>=</span> <span class=n>i</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>i</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
        <span class=k>if</span> <span class=n>tag</span><span class=o>==</span><span class=s2>&quot;Wj&quot;</span><span class=p>:</span>
            <span class=n>names</span> <span class=o>+=</span> <span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=s2>&quot;Wjets&quot;</span><span class=p>]</span>
        <span class=k>elif</span> <span class=n>tag</span><span class=o>==</span><span class=s2>&quot;TT&quot;</span><span class=p>:</span>
            <span class=n>names</span> <span class=o>+=</span> <span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=s2>&quot;TTbar&quot;</span><span class=p>]</span>
        <span class=k>elif</span> <span class=n>tag</span><span class=o>==</span><span class=s2>&quot;ZJ&quot;</span><span class=p>:</span>
            <span class=n>names</span> <span class=o>+=</span> <span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=s2>&quot;Z2nu&quot;</span><span class=p>]</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>names</span> <span class=o>+=</span> <span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=s2>&quot;Other&quot;</span><span class=p>]</span>
    <span class=n>N</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>names</span><span class=p>)</span>
    <span class=n>dictionary</span> <span class=o>=</span> <span class=p>{</span><span class=n>names</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=p>:</span> <span class=n>names</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=n>N</span><span class=p>,</span><span class=mi>2</span><span class=p>)}</span>
    <span class=k>return</span> <span class=n>dictionary</span>


<span class=c1># Maps a 1 for a specific process and 0&#39;s elsewhere, in an array of (here 5) elements</span>
<span class=k>def</span> <span class=nf>Tag</span><span class=p>(</span><span class=n>dataframe</span><span class=p>):</span>
    <span class=n>data</span> <span class=o>=</span> <span class=n>dataframe</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span> <span class=c1># Makes a copy -&gt; another address in memory</span>
    <span class=c1># Mapping (input mapping) of various process strings to 1, and 0&#39;s for other processes</span>
    <span class=n>data</span><span class=p>[</span><span class=s2>&quot;SigTag&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>index</span><span class=o>.</span><span class=n>map</span><span class=p>({</span><span class=s2>&quot;Signal&quot;</span><span class=p>:</span><span class=mi>1</span><span class=p>})</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
    <span class=n>data</span><span class=p>[</span><span class=s2>&quot;WjTag&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>index</span><span class=o>.</span><span class=n>map</span><span class=p>({</span><span class=s2>&quot;Wjets&quot;</span><span class=p>:</span><span class=mi>1</span><span class=p>})</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
    <span class=n>data</span><span class=p>[</span><span class=s2>&quot;TTTag&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>index</span><span class=o>.</span><span class=n>map</span><span class=p>({</span><span class=s2>&quot;TTbar&quot;</span><span class=p>:</span><span class=mi>1</span><span class=p>})</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
    <span class=n>data</span><span class=p>[</span><span class=s2>&quot;Z2nuTag&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>index</span><span class=o>.</span><span class=n>map</span><span class=p>({</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>:</span><span class=mi>1</span><span class=p>})</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
    <span class=n>data</span><span class=p>[</span><span class=s2>&quot;OtherTag&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>index</span><span class=o>.</span><span class=n>map</span><span class=p>({</span><span class=s2>&quot;Other&quot;</span><span class=p>:</span><span class=mi>1</span><span class=p>})</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
    <span class=c1># Makes the arry of (here 5) elements made of 0/1</span>
    <span class=k>return</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>data</span><span class=p>[</span><span class=s2>&quot;SigTag&quot;</span><span class=p>],</span><span class=n>data</span><span class=p>[</span><span class=s2>&quot;WjTag&quot;</span><span class=p>],</span><span class=n>data</span><span class=p>[</span><span class=s2>&quot;TTTag&quot;</span><span class=p>],</span><span class=n>data</span><span class=p>[</span><span class=s2>&quot;Z2nuTag&quot;</span><span class=p>],</span> <span class=n>data</span><span class=p>[</span><span class=s2>&quot;OtherTag&quot;</span><span class=p>]],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>N_runs</span><span class=o>=</span><span class=mi>10</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Loading data...&quot;</span><span class=p>)</span>

<span class=c1># PREPARING DATA #######################################</span>

<span class=c1>### Reading data</span>
<span class=n>names</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;LepChg&quot;</span><span class=p>,</span> <span class=s2>&quot;LepPt&quot;</span><span class=p>,</span> <span class=s2>&quot;LepEta&quot;</span><span class=p>,</span> <span class=s2>&quot;Dxy&quot;</span><span class=p>,</span> <span class=s2>&quot;Dz&quot;</span><span class=p>,</span> <span class=s2>&quot;RelIso&quot;</span><span class=p>,</span> <span class=s2>&quot;Met&quot;</span><span class=p>,</span> <span class=s2>&quot;mt&quot;</span><span class=p>,</span> <span class=s2>&quot;Njet&quot;</span><span class=p>,</span>
        <span class=s2>&quot;Jet1Pt&quot;</span><span class=p>,</span> <span class=s2>&quot;Jet2Pt&quot;</span><span class=p>,</span> <span class=s2>&quot;HT&quot;</span><span class=p>,</span> <span class=s2>&quot;NbLoose&quot;</span><span class=p>,</span> <span class=s2>&quot;JetHBpt&quot;</span><span class=p>,</span> <span class=s2>&quot;JetHBCSV&quot;</span><span class=p>,</span> <span class=s2>&quot;JetB2pt&quot;</span><span class=p>,</span> <span class=s2>&quot;DrJetHBLep&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=s2>&quot;Tag&quot;</span><span class=p>]</span>

<span class=c1># index_col defines last column as index (row names) of DataFrame. Resulting DataFrame has xyz.root as its last column (indexing starts @ 0)</span>
<span class=c1># When interpreting it as index column it plays the same part as do numbers 0,1,2,3... in numpy array (eg. a[i] is i-th element of array a).</span>
<span class=c1># It disappears from the list of values you are &quot;interpreting as data&quot;</span>
<span class=n>train_sig</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;17var/data/train_sig.csv&quot;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=n>names</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>
<span class=n>train_bkg</span><span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;17var/data/train_bkg.csv&quot;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=n>names</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>

<span class=n>val_sig</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;17var/data/val_sig.csv&quot;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=n>names</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>
<span class=n>val_bkg</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;17var/data/val_bkg.csv&quot;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=n>names</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>

<span class=n>test_sig</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;17var/data/test_sig.csv&quot;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=n>names</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>
<span class=n>test_bkg</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;17var/data/test_bkg.csv&quot;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=n>names</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>

<span class=c1>### Get S=(550,520) lines</span>
<span class=n>val_sig_S</span> <span class=o>=</span> <span class=n>val_sig</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s1>&#39;T2DegStop_550_520.root&#39;</span><span class=p>]</span> <span class=c1># Filter DataFrame rows (only 1 argument) by name</span>
<span class=n>val_sig_S</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Signal&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>val_sig_S</span><span class=p>)</span>

<span class=n>train_sig_S</span> <span class=o>=</span> <span class=n>train_sig</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s1>&#39;T2DegStop_550_520.root&#39;</span><span class=p>]</span>
<span class=n>train_sig_S</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Signal&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_sig_S</span><span class=p>)</span>

<span class=c1>### Index = category of the process (&quot;Signal&quot;, &quot;Wjets&quot;, &quot;TTbar&quot;, &quot;Z2nu&quot;, &quot;Other&quot;)</span>
<span class=n>train_sig</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Signal&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_sig</span><span class=p>)</span> <span class=c1># </span>
<span class=n>names</span> <span class=o>=</span> <span class=n>rename_rows</span><span class=p>(</span><span class=n>train_bkg</span><span class=o>.</span><span class=n>index</span><span class=p>)</span> <span class=c1># train_bkg.index holds the name of the process from index_col=18</span>
<span class=n>train_bkg</span> <span class=o>=</span> <span class=n>train_bkg</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=n>names</span><span class=p>)</span> <span class=c1># Rename (here) index labels</span>

<span class=n>val_sig</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Signal&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>val_sig</span><span class=p>)</span>
<span class=n>names</span> <span class=o>=</span> <span class=n>rename_rows</span><span class=p>(</span><span class=n>val_bkg</span><span class=o>.</span><span class=n>index</span><span class=p>)</span>
<span class=n>val_bkg</span> <span class=o>=</span> <span class=n>val_bkg</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=n>names</span><span class=p>)</span>

<span class=n>test_sig</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Signal&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>test_sig</span><span class=p>)</span>
<span class=n>names</span> <span class=o>=</span> <span class=n>rename_rows</span><span class=p>(</span><span class=n>test_bkg</span><span class=o>.</span><span class=n>index</span><span class=p>)</span>
<span class=n>test_bkg</span> <span class=o>=</span> <span class=n>test_bkg</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=n>names</span><span class=p>)</span>

<span class=c1>### Separate processes</span>
<span class=n>train_wj</span> <span class=o>=</span> <span class=n>train_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>]]</span>
<span class=n>train_tt</span> <span class=o>=</span> <span class=n>train_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>]]</span>
<span class=n>train_z2nu</span> <span class=o>=</span> <span class=n>train_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>]]</span>
<span class=n>train_other</span> <span class=o>=</span> <span class=n>train_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;Other&quot;</span><span class=p>]]</span>

<span class=n>val_wj</span> <span class=o>=</span> <span class=n>val_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>]]</span>
<span class=n>val_tt</span> <span class=o>=</span> <span class=n>val_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>]]</span>
<span class=n>val_z2nu</span> <span class=o>=</span> <span class=n>val_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>]]</span>
<span class=n>val_other</span> <span class=o>=</span> <span class=n>val_bkg</span><span class=o>.</span><span class=n>loc</span><span class=p>[[</span><span class=s2>&quot;Other&quot;</span><span class=p>]]</span>

<span class=k>for</span> <span class=n>dlta</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>):</span> <span class=c1># ?</span>

    <span class=c1>### Weight normalisation</span>

    <span class=n>delta</span> <span class=o>=</span> <span class=n>dlta</span> <span class=c1># Useless</span>

    <span class=n>N_sig</span> <span class=o>=</span> <span class=n>train_sig</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>

    <span class=n>S</span> <span class=o>=</span> <span class=n>train_sig</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>W</span> <span class=o>=</span> <span class=n>train_wj</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>T</span> <span class=o>=</span> <span class=n>train_tt</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>Z</span> <span class=o>=</span> <span class=n>train_z2nu</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>O</span> <span class=o>=</span> <span class=n>train_other</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

    <span class=n>sig</span> <span class=o>=</span> <span class=mf>1.</span>
    <span class=n>wj</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>W</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>
    <span class=n>tt</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>T</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>
    <span class=n>z2nu</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>Z</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>
    <span class=n>other</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>O</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>

    <span class=n>weightTrn_sig</span> <span class=o>=</span> <span class=n>train_sig</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>S</span><span class=o>*</span><span class=n>sig</span>
    <span class=n>weightTrn_wj</span> <span class=o>=</span> <span class=n>train_wj</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>W</span><span class=o>*</span><span class=n>wj</span>
    <span class=n>weightTrn_tt</span> <span class=o>=</span> <span class=n>train_tt</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>T</span><span class=o>*</span><span class=n>tt</span>
    <span class=n>weightTrn_z2nu</span> <span class=o>=</span> <span class=n>train_z2nu</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>Z</span><span class=o>*</span><span class=n>z2nu</span>
    <span class=n>weightTrn_other</span> <span class=o>=</span> <span class=n>train_other</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>O</span><span class=o>*</span><span class=n>other</span>

    <span class=n>N_sig</span> <span class=o>=</span> <span class=n>val_sig</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>

    <span class=n>S</span> <span class=o>=</span> <span class=n>val_sig</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>W</span> <span class=o>=</span> <span class=n>val_wj</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>T</span> <span class=o>=</span> <span class=n>val_tt</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>Z</span> <span class=o>=</span> <span class=n>val_z2nu</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>O</span> <span class=o>=</span> <span class=n>val_other</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

    <span class=n>sig</span> <span class=o>=</span> <span class=mf>1.</span>
    <span class=n>wj</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>W</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>
    <span class=n>tt</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>T</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>
    <span class=n>z2nu</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>Z</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>
    <span class=n>other</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>O</span><span class=o>/</span><span class=n>S</span><span class=p>)</span>

    <span class=n>weightVal_sig</span> <span class=o>=</span> <span class=n>val_sig</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>S</span><span class=o>*</span><span class=n>sig</span>
    <span class=n>weightVal_wj</span> <span class=o>=</span> <span class=n>val_wj</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>W</span><span class=o>*</span><span class=n>wj</span>
    <span class=n>weightVal_tt</span> <span class=o>=</span> <span class=n>val_tt</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>T</span><span class=o>*</span><span class=n>tt</span>
    <span class=n>weightVal_z2nu</span> <span class=o>=</span> <span class=n>val_z2nu</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>Z</span><span class=o>*</span><span class=n>z2nu</span>
    <span class=n>weightVal_other</span> <span class=o>=</span> <span class=n>val_other</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>*</span><span class=n>N_sig</span><span class=o>/</span><span class=n>O</span><span class=o>*</span><span class=n>other</span>

        <span class=c1>###</span>

    <span class=c1># Full train</span>
    <span class=n>full_train</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>train_sig</span><span class=p>,</span> <span class=n>train_wj</span><span class=p>,</span> <span class=n>train_tt</span><span class=p>,</span> <span class=n>train_z2nu</span><span class=p>,</span> <span class=n>train_other</span><span class=p>])</span>
    <span class=n>full_train_weights</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>weightTrn_sig</span><span class=p>,</span> <span class=n>weightTrn_wj</span><span class=p>,</span> <span class=n>weightTrn_tt</span><span class=p>,</span> <span class=n>weightTrn_z2nu</span><span class=p>,</span> <span class=n>weightTrn_other</span><span class=p>])</span>
    <span class=n>weights_not_scaled_train</span> <span class=o>=</span> <span class=n>full_train</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
    <span class=c1>### Only S=(550,520) for plotting</span>
    <span class=n>full_train_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>train_sig_S</span><span class=p>,</span> <span class=n>train_wj</span><span class=p>,</span> <span class=n>train_tt</span><span class=p>,</span> <span class=n>train_z2nu</span><span class=p>,</span> <span class=n>train_other</span><span class=p>])</span>
    <span class=n>weights_not_scaled_train_S</span> <span class=o>=</span> <span class=n>full_train_S</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

    <span class=c1># Full validation</span>
    <span class=n>full_val</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>val_sig</span><span class=p>,</span> <span class=n>val_wj</span><span class=p>,</span> <span class=n>val_tt</span><span class=p>,</span> <span class=n>val_z2nu</span><span class=p>,</span> <span class=n>val_other</span><span class=p>])</span>
    <span class=n>full_val_weights</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>weightVal_sig</span><span class=p>,</span> <span class=n>weightVal_wj</span><span class=p>,</span> <span class=n>weightVal_tt</span><span class=p>,</span> <span class=n>weightVal_z2nu</span><span class=p>,</span> <span class=n>weightVal_other</span><span class=p>])</span>
    <span class=n>weights_not_scaled_val</span> <span class=o>=</span> <span class=n>full_val</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
    <span class=c1>### Only S=(550,520) for plotting</span>
    <span class=n>full_val_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>val_sig_S</span><span class=p>,</span> <span class=n>val_wj</span><span class=p>,</span> <span class=n>val_tt</span><span class=p>,</span> <span class=n>val_z2nu</span><span class=p>,</span> <span class=n>val_other</span><span class=p>])</span>
    <span class=n>weights_not_scaled_val_S</span> <span class=o>=</span> <span class=n>full_val_S</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

    <span class=c1># Full test</span>
    <span class=n>full_test</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>test_sig</span><span class=p>,</span> <span class=n>test_bkg</span><span class=p>])</span>
    <span class=n>full_test_weights</span> <span class=o>=</span> <span class=n>full_test</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
    <span class=n>weights_not_scaled_test</span> <span class=o>=</span> <span class=n>full_test</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

    <span class=c1>### Variable normalisation to [-1,1]</span>
    <span class=n>top</span> <span class=o>=</span> <span class=n>full_train</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=p>;</span> <span class=n>bot</span> <span class=o>=</span> <span class=n>full_train</span><span class=o>.</span><span class=n>min</span><span class=p>()</span>
    <span class=n>full_val</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_val</span><span class=o>-</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span>
    <span class=n>full_val_S</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_val_S</span><span class=o>-</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span>
    <span class=n>full_test</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_test</span><span class=o>-</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span>
    <span class=n>full_train</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_train</span><span class=o>-</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span>
    <span class=n>full_train_S</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>full_train_S</span><span class=o>-</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>top</span><span class=o>-</span><span class=n>bot</span><span class=p>)</span>

        <span class=c1># Replace original weights with balanced weights</span>
    <span class=n>full_val</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>full_val</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>full_val_weights</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># Along columns (axis=1): drops the column &quot;Weights&quot; &amp; replaces</span>
    <span class=n>full_val_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>full_val_S</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>weights_not_scaled_val_S</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>full_train_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>full_train_S</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>weights_not_scaled_train_S</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>full_test</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>full_test</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>full_test_weights</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>full_train</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>full_train</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>full_train_weights</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

    <span class=c1>### INFO for plotting</span>
    <span class=n>xTrn_p</span> <span class=o>=</span> <span class=n>full_train</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yTrn_p</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_train</span><span class=p>)</span>
    <span class=n>weightTrn_p</span> <span class=o>=</span> <span class=n>weights_not_scaled_train</span>
    <span class=c1>###### S=(550,520)</span>
    <span class=n>xTrn_S</span> <span class=o>=</span> <span class=n>full_train_S</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yTrn_S</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_train_S</span><span class=p>)</span>
    <span class=n>weightTrn_S</span> <span class=o>=</span> <span class=n>weights_not_scaled_train_S</span>

    <span class=n>xVal_p</span> <span class=o>=</span> <span class=n>full_val</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yVal_p</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_val</span><span class=p>)</span>
    <span class=n>weightVal_p</span> <span class=o>=</span> <span class=n>weights_not_scaled_val</span>
    <span class=c1>###### S=(550,520)</span>
    <span class=n>xVal_S</span> <span class=o>=</span> <span class=n>full_val_S</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yVal_S</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_val_S</span><span class=p>)</span>
    <span class=n>weightVal_S</span> <span class=o>=</span> <span class=n>weights_not_scaled_val_S</span>

    <span class=n>xTest_p</span> <span class=o>=</span> <span class=n>full_test</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yTest_p</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_test</span><span class=p>)</span>
    <span class=n>weightTest_p</span> <span class=o>=</span> <span class=n>weights_not_scaled_test</span>

    <span class=c1>### Shuffling</span>
    <span class=n>full_train</span> <span class=o>=</span> <span class=n>full_train</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>frac</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># Returns a random sample of items from an axis of object</span>
    <span class=n>full_val</span> <span class=o>=</span> <span class=n>full_val</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>frac</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>     <span class=c1># with fraction of axis items to return</span>
    <span class=n>full_test</span> <span class=o>=</span> <span class=n>full_test</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>frac</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

    <span class=c1>### NN training</span>
        <span class=c1># When dropping the weights, only input vars remain, the Tag column having been interpreted as index</span>
    <span class=n>xTrn</span> <span class=o>=</span> <span class=n>full_train</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yTrn</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_train</span><span class=p>)</span>
    <span class=n>weightTrn</span> <span class=o>=</span> <span class=n>full_train</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

    <span class=n>xVal</span> <span class=o>=</span> <span class=n>full_val</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yVal</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_val</span><span class=p>)</span>
    <span class=n>weightVal</span> <span class=o>=</span> <span class=n>full_val</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

    <span class=n>xTest</span> <span class=o>=</span> <span class=n>full_test</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s2>&quot;Weights&quot;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>yTest</span> <span class=o>=</span> <span class=n>Tag</span><span class=p>(</span><span class=n>full_test</span><span class=p>)</span>
    <span class=n>weightTest</span> <span class=o>=</span> <span class=n>full_test</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

    <span class=k>for</span> <span class=n>q</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>):</span>
        <span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>5.e-5</span>
        <span class=n>decay_rate</span> <span class=o>=</span> <span class=mi>10</span><span class=o>**</span><span class=p>(</span><span class=o>-</span><span class=mf>1.</span><span class=o>*</span><span class=n>q</span><span class=p>)</span>
        <span class=n>NodeLayer</span> <span class=o>=</span> <span class=s2>&quot;100 100&quot;</span> <span class=c1># Means 2 layers of 100 nodes each</span>
        <span class=n>architecture</span><span class=o>=</span><span class=n>NodeLayer</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
        <span class=n>ini</span> <span class=o>=</span> <span class=s2>&quot;he_normal&quot;</span> <span class=c1># Function for initialising the random weights of the layer</span>
        <span class=n>n_epochs</span> <span class=o>=</span> <span class=mi>1000</span>
        <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>5000</span>
        <span class=n>dropout_rate</span> <span class=o>=</span> <span class=mf>0.</span>

        <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span>

        <span class=n>activ</span> <span class=o>=</span> <span class=s2>&quot;tanh&quot;</span>
        <span class=n>loss_function</span> <span class=o>=</span> <span class=s2>&quot;categorical_crossentropy&quot;</span>

        <span class=n>name</span><span class=o>=</span><span class=s2>&quot;levels_00&quot;</span><span class=c1>#+str(dlta)</span>
        <span class=n>lrdr</span><span class=o>=</span><span class=s2>&quot;LR4e-1_DR5e-7&quot;</span>

        <span class=n>dirname</span> <span class=o>=</span><span class=s2>&quot;2016_1l_Tanh_CatCrossEnt_100-100_L5e-5_D1e-&quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>q</span><span class=p>)</span> 

        <span class=n>fom_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Scaling Function&quot;</span><span class=p>,</span><span class=s2>&quot;NN Configuration&quot;</span><span class=p>,</span><span class=s2>&quot;Activation Function&quot;</span><span class=p>,</span> <span class=s2>&quot;Loss Function&quot;</span><span class=p>,</span> <span class=s2>&quot;Learning Rate&quot;</span><span class=p>,</span> <span class=s2>&quot;Decay Rate&quot;</span><span class=p>,</span> <span class=s2>&quot;Max Val FOM&quot;</span><span class=p>,</span> <span class=s2>&quot;at x_cut&quot;</span><span class=p>,</span> <span class=s2>&quot;Test FOM&quot;</span><span class=p>,</span> <span class=s2>&quot;Max Test FOM&quot;</span><span class=p>])</span>

        <span class=n>org_path</span> <span class=o>=</span> <span class=s2>&quot;17var_models_5C/&quot;</span><span class=o>+</span><span class=n>dirname</span><span class=o>+</span><span class=s2>&quot;/&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>org_path</span><span class=p>):</span>
            <span class=n>os</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>org_path</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>N_runs</span><span class=p>):</span>
            <span class=n>string</span> <span class=o>=</span> <span class=s2>&quot;17var_models_5C/</span><span class=si>{}</span><span class=s2>/run&quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>k</span><span class=p>)</span><span class=o>+</span><span class=s2>&quot;/&quot;</span>
            <span class=n>filepath</span> <span class=o>=</span> <span class=n>string</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>dirname</span><span class=p>)</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>filepath</span><span class=p>):</span>
                <span class=n>os</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>filepath</span><span class=p>)</span>
            <span class=c1># MULTICLASS NEURAL NETWORK TRAINING ###################</span>

            <span class=c1># Model&#39;s compilation arguments, training parameters and optimizer #categorical_crossentropy</span>
            <span class=n>compileArgs</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;loss&#39;</span><span class=p>:</span><span class=n>loss_function</span><span class=p>,</span> <span class=s1>&#39;optimizer&#39;</span><span class=p>:</span> <span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;accuracy&quot;</span><span class=p>]}</span>
            <span class=n>trainParams</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;epochs&#39;</span><span class=p>:</span> <span class=n>n_epochs</span><span class=p>,</span> <span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=n>batch_size</span><span class=p>,</span> <span class=s1>&#39;verbose&#39;</span><span class=p>:</span> <span class=n>verbose</span><span class=p>}</span>
            <span class=nb>print</span><span class=p>(</span><span class=n>Adam</span><span class=p>)</span>
            <span class=c1># Define optimizer which has the learning- &amp; decay-rates</span>
            <span class=n>myOpt</span> <span class=o>=</span> <span class=n>Adam</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span> <span class=n>decay</span><span class=o>=</span><span class=n>decay_rate</span><span class=p>)</span>
            <span class=n>compileArgs</span><span class=p>[</span><span class=s1>&#39;optimizer&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>myOpt</span>

            <span class=c1># Printing info and starting time</span>
            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Dir &quot;</span><span class=o>+</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot; created.&quot;</span><span class=p>)</span>
            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Starting the training&quot;</span><span class=p>)</span>
            <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>

            <span class=c1>### Build the NN model</span>
            <span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>()</span>
            <span class=c1># 1st hidden layer: it has as many nodes as provided by architecture[0]</span>
            <span class=c1># input_dim: as many as input variables</span>
            <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>architecture</span><span class=p>[</span><span class=mi>0</span><span class=p>]),</span> <span class=n>input_dim</span><span class=o>=</span><span class=mi>17</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activ</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>ini</span><span class=p>))</span>
            <span class=n>i</span><span class=o>=</span><span class=mi>1</span>
            <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>architecture</span><span class=p>)</span> <span class=p>:</span>
                <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>architecture</span><span class=p>[</span><span class=n>i</span><span class=p>]),</span> <span class=n>activation</span><span class=o>=</span><span class=n>activ</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>ini</span><span class=p>))</span>
                <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span>
            <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;softmax&#39;</span><span class=p>))</span> <span class=c1># Output layer: 5 nodes, with softmax b/c multi-class NN</span>
            <span class=c1>#        model.add(kernel_regularizer=l2(1e-5))</span>
            <span class=c1>#        model.add(Dropout(dropout_rate))</span>
            <span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=o>**</span><span class=n>compileArgs</span><span class=p>)</span>
            <span class=n>model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
            <span class=c1>########</span>
            <span class=c1># Define criterium for best epoch saving</span>
            <span class=c1># Returns the weights as they are at the minimum, b/c of argument of mode</span>
            <span class=n>checkpoint</span> <span class=o>=</span> <span class=n>callbacks</span><span class=o>.</span><span class=n>ModelCheckpoint</span><span class=p>(</span><span class=n>filepath</span><span class=o>=</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;best_weights.h5&quot;</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>save_weights_only</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>monitor</span><span class=o>=</span><span class=s2>&quot;val_loss&quot;</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s2>&quot;min&quot;</span><span class=p>,</span> <span class=n>save_best_only</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

            <span class=c1>### Train model ###</span>
            <span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>xTrn</span><span class=p>,</span> <span class=n>yTrn</span><span class=p>,</span> <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>xVal</span><span class=p>,</span><span class=n>yVal</span><span class=p>,</span><span class=n>weightVal</span><span class=p>),</span> <span class=n>sample_weight</span><span class=o>=</span><span class=n>weightTrn</span><span class=p>,</span><span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>  <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>checkpoint</span><span class=p>],</span> <span class=o>**</span><span class=n>trainParams</span><span class=p>)</span>
            <span class=c1># Get weights for best epoch    </span>
            <span class=n>model</span><span class=o>.</span><span class=n>load_weights</span><span class=p>(</span><span class=n>filepath</span> <span class=o>+</span> <span class=s2>&quot;best_weights.h5&quot;</span><span class=p>)</span>
            <span class=c1>### Time of the training</span>
            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training took: &quot;</span><span class=p>,</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span><span class=o>-</span><span class=n>start</span><span class=p>)</span><span class=o>//</span><span class=mi>60</span><span class=p>,</span> <span class=s2>&quot; minutes&quot;</span><span class=p>)</span>

            <span class=c1>########################################################</span>


            <span class=c1>########################################################</span>

            <span class=c1># SAVING OUTPUT ########################################</span>

            <span class=c1># LOSS #################################################</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]</span>
            <span class=n>val_loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_loss&#39;</span><span class=p>]</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Training loss&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>val_loss</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Validation loss&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;LOSS&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;EPOCHS&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;TrnVal_loss.png&quot;</span><span class=p>)</span>
            <span class=c1>########################################################</span>

            <span class=c1># ACCURACY #############################################</span>
            <span class=n>acc</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s2>&quot;accuracy&quot;</span><span class=p>]</span>
            <span class=n>val_acc</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s2>&quot;val_accuracy&quot;</span><span class=p>]</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>acc</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Training accuracy&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>val_acc</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Validation accuracy&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;ACCURACY&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;EPOCH&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>yscale</span><span class=p>(</span><span class=s2>&quot;log&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;TrnVal_accuracy.png&quot;</span><span class=p>)</span>
            <span class=c1>########################################################</span>

            <span class=c1>### Saving accuracy and loss values in a pickle file for later plotting</span>
            <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>acc</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;acc.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>
            <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;loss.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>
            <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>val_acc</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;val_acc.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>
            <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>val_loss</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=o>+</span><span class=s2>&quot;val_loss.pickle&quot;</span><span class=p>,</span> <span class=s2>&quot;wb&quot;</span><span class=p>))</span>

            <span class=c1>### Test</span>
            <span class=n>predicted_test</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xTest_p</span><span class=p>))</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>{</span><span class=mi>0</span><span class=p>:</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span><span class=mi>1</span><span class=p>:</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span><span class=mi>2</span><span class=p>:</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span><span class=mi>3</span><span class=p>:</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span><span class=mi>4</span><span class=p>:</span><span class=s2>&quot;Other&quot;</span><span class=p>})</span>
            <span class=n>true_test</span> <span class=o>=</span> <span class=n>yTest_p</span>

            <span class=n>predicted_test</span><span class=p>[</span><span class=s2>&quot;Predicted&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>predicted_test</span><span class=o>.</span><span class=n>idxmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>predicted_test</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=n>yTest_p</span><span class=o>.</span><span class=n>index</span>
            <span class=n>data_test</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>predicted_test</span><span class=p>,</span> <span class=n>weightTest_p</span><span class=p>],</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

            <span class=c1>#data_test.to_csv(filepath+&quot;Test_Data.csv&quot;)</span>

            <span class=c1>### Train</span>
            <span class=n>predicted_train</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xTrn_p</span><span class=p>))</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>{</span><span class=mi>0</span><span class=p>:</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span><span class=mi>1</span><span class=p>:</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span><span class=mi>2</span><span class=p>:</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span><span class=mi>3</span><span class=p>:</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span><span class=mi>4</span><span class=p>:</span><span class=s2>&quot;Other&quot;</span><span class=p>})</span>
            <span class=n>true_train</span> <span class=o>=</span> <span class=n>yTrn_p</span>

            <span class=n>predicted_train</span><span class=p>[</span><span class=s2>&quot;Predicted&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>predicted_train</span><span class=o>.</span><span class=n>idxmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>predicted_train</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=n>yTrn_p</span><span class=o>.</span><span class=n>index</span>
            <span class=n>data_train</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>predicted_train</span><span class=p>,</span> <span class=n>weightTrn_p</span><span class=p>],</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=c1>### Train (550,520)</span>
            <span class=n>predicted_train_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xTrn_S</span><span class=p>))</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>{</span><span class=mi>0</span><span class=p>:</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span><span class=mi>1</span><span class=p>:</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span><span class=mi>2</span><span class=p>:</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span><span class=mi>3</span><span class=p>:</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span><span class=mi>4</span><span class=p>:</span><span class=s2>&quot;Other&quot;</span><span class=p>})</span>
            <span class=n>true_train_S</span> <span class=o>=</span> <span class=n>yTrn_S</span>

            <span class=n>predicted_train_S</span><span class=p>[</span><span class=s2>&quot;Predicted&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>predicted_train_S</span><span class=o>.</span><span class=n>idxmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>predicted_train_S</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=n>yTrn_S</span><span class=o>.</span><span class=n>index</span>
            <span class=n>data_train_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>predicted_train_S</span><span class=p>,</span> <span class=n>weightTrn_S</span><span class=p>],</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

            <span class=c1>#data_train.to_csv(filepath+&quot;Train_Data.csv&quot;)</span>

            <span class=c1>### Validation</span>
            <span class=n>predicted_val</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xVal_p</span><span class=p>))</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>{</span><span class=mi>0</span><span class=p>:</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span><span class=mi>1</span><span class=p>:</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span><span class=mi>2</span><span class=p>:</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span><span class=mi>3</span><span class=p>:</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span><span class=mi>4</span><span class=p>:</span><span class=s2>&quot;Other&quot;</span><span class=p>})</span>
            <span class=n>true_val</span> <span class=o>=</span> <span class=n>yVal_p</span>

            <span class=n>predicted_val</span><span class=p>[</span><span class=s2>&quot;Predicted&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>predicted_val</span><span class=o>.</span><span class=n>idxmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>predicted_val</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=n>yVal_p</span><span class=o>.</span><span class=n>index</span>
            <span class=n>data_val</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>predicted_val</span><span class=p>,</span> <span class=n>weightVal_p</span><span class=p>],</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

            <span class=c1>#data_val.to_csv(filepath+&quot;Validation_Data.csv&quot;)</span>

            <span class=c1>### Validation (550,520)</span>
            <span class=n>predicted_val_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>xVal_S</span><span class=p>))</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>{</span><span class=mi>0</span><span class=p>:</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span><span class=mi>1</span><span class=p>:</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span><span class=mi>2</span><span class=p>:</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span><span class=mi>3</span><span class=p>:</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span><span class=mi>4</span><span class=p>:</span><span class=s2>&quot;Other&quot;</span><span class=p>})</span>
            <span class=n>true_val_S</span> <span class=o>=</span> <span class=n>yVal_S</span>

            <span class=n>predicted_val_S</span><span class=p>[</span><span class=s2>&quot;Predicted&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>predicted_val_S</span><span class=o>.</span><span class=n>idxmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>predicted_val_S</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=n>yVal_S</span><span class=o>.</span><span class=n>index</span>
            <span class=n>data_val_S</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>predicted_val_S</span><span class=p>,</span> <span class=n>weightVal_S</span><span class=p>],</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

            <span class=c1>#data_val_S.to_csv(filepath+&quot;Validation_550_520_Data.csv&quot;)</span>

            <span class=c1>#### FOM ###################################################################################</span>

            <span class=c1>### Split factors ###</span>
            <span class=c1># For OPTION 5</span>
            <span class=n>svs</span> <span class=o>=</span> <span class=mf>4.</span> <span class=c1># Compensate for use of 25% of signal in validation</span>
            <span class=n>svbb</span> <span class=o>=</span> <span class=mf>4.</span> <span class=c1># Compensate for use of 25% of big background in validation</span>
            <span class=n>svsb</span> <span class=o>=</span> <span class=mf>4.</span> <span class=c1># Compensate for use of 25% of small background in validation</span>
            <span class=n>sts</span> <span class=o>=</span> <span class=mf>2.</span> <span class=c1># Compensate for use of 50% of signal in test</span>
            <span class=n>stbb</span> <span class=o>=</span> <span class=mf>2.</span> <span class=c1># Compensate for use of 50% of big background in test</span>
            <span class=n>stsb</span> <span class=o>=</span> <span class=mf>2.</span> <span class=c1># Compensate for use of 50% of small background in test</span>
            <span class=n>strs</span> <span class=o>=</span> <span class=mf>4.</span> <span class=c1># Compensate for use of 25% of signal in train</span>
            <span class=n>strbb</span> <span class=o>=</span> <span class=mf>4.</span> <span class=c1># Compensate for use of 25% of big background in train</span>
            <span class=n>strsb</span> <span class=o>=</span> <span class=mf>4.</span> <span class=c1># Compensate for use of 25% of small background in train</span>
            <span class=c1>#####################</span>

            <span class=c1># Integrated luminosity: the one of 2016</span>
            <span class=n>luminosity</span> <span class=o>=</span> <span class=mi>35866</span>

            <span class=c1># Relative systematics for FOM</span>
            <span class=n>f</span> <span class=o>=</span> <span class=mf>0.2</span>

            <span class=c1># DataFrame -&gt; index=(process category), Signal (output), Wjets (output), TTbar (output), Z2nu (output), Predicted, Weights</span>
            <span class=n>data_val</span> <span class=o>=</span> <span class=n>data_val_S</span>
            <span class=n>data_train</span> <span class=o>=</span> <span class=n>data_train_S</span>
            <span class=c1># Rescale weights ###############################</span>

            <span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>svs</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>svbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>svbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>svbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>stbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

            <span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>sts</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>stbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>stbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>stbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>stbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>

            <span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>strs</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>strbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>strbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>strbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>
            <span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>strbb</span><span class=o>*</span><span class=n>luminosity</span><span class=o>*</span><span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span>


            <span class=c1># FIGURE OF MERIT CALCULATION</span>

            <span class=k>def</span> <span class=nf>FOM</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=n>B</span><span class=p>):</span>
                <span class=n>fom1</span> <span class=o>=</span> <span class=p>(</span><span class=n>S</span><span class=o>+</span><span class=n>B</span><span class=p>)</span><span class=o>*</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(((</span><span class=n>S</span><span class=o>+</span><span class=n>B</span><span class=p>)</span><span class=o>*</span><span class=p>(</span><span class=n>B</span><span class=o>+</span><span class=n>f</span><span class=o>*</span><span class=n>f</span><span class=o>*</span><span class=n>B</span><span class=o>*</span><span class=n>B</span><span class=p>))</span><span class=o>/</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=n>B</span><span class=o>+</span><span class=p>(</span><span class=n>S</span><span class=o>+</span><span class=n>B</span><span class=p>)</span><span class=o>*</span><span class=n>f</span><span class=o>*</span><span class=n>f</span><span class=o>*</span><span class=n>B</span><span class=o>*</span><span class=n>B</span><span class=p>))</span>
                <span class=n>fom2</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=p>(</span><span class=n>f</span><span class=o>*</span><span class=n>f</span><span class=p>))</span><span class=o>*</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>1</span><span class=o>+</span><span class=p>(</span><span class=n>f</span><span class=o>*</span><span class=n>f</span><span class=o>*</span><span class=n>B</span><span class=o>*</span><span class=n>B</span><span class=o>*</span><span class=n>S</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=p>(</span><span class=n>B</span><span class=o>+</span><span class=n>f</span><span class=o>*</span><span class=n>f</span><span class=o>*</span><span class=n>B</span><span class=o>*</span><span class=n>B</span><span class=p>)))</span>
                <span class=k>if</span> <span class=n>fom1</span><span class=o>&gt;</span><span class=n>fom2</span><span class=p>:</span>
                    <span class=n>fom</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=p>(</span><span class=n>fom1</span><span class=o>-</span><span class=n>fom2</span><span class=p>))</span>
                <span class=k>else</span><span class=p>:</span> <span class=n>fom</span> <span class=o>=</span> <span class=mi>0</span>
                <span class=k>return</span> <span class=n>fom</span>


            <span class=c1># process -&gt; which histogram is summed over  |  predicted_events -&gt; on which plot |||||| node -&gt; of NN output</span>
            <span class=k>def</span> <span class=nf>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>process</span><span class=p>,</span> <span class=n>predicted_events</span><span class=p>,</span> <span class=n>node</span><span class=p>,</span> <span class=n>cut</span><span class=p>):</span>
                <span class=n>lower</span> <span class=o>=</span> <span class=n>cut</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
                <span class=n>upper</span> <span class=o>=</span> <span class=n>cut</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
                <span class=n>new_data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s2>&quot;Predicted&quot;</span><span class=p>]</span><span class=o>==</span><span class=n>predicted_events</span><span class=p>]</span>
                <span class=k>if</span> <span class=n>process</span><span class=o>==</span><span class=s2>&quot;Signal&quot;</span><span class=p>:</span>
                    <span class=n>new_data</span> <span class=o>=</span> <span class=n>new_data</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>]</span>
                <span class=k>else</span><span class=p>:</span> <span class=n>new_data</span> <span class=o>=</span> <span class=n>new_data</span><span class=o>.</span><span class=n>drop</span><span class=p>([</span><span class=s2>&quot;Signal&quot;</span><span class=p>])</span>
                <span class=n>new_data</span> <span class=o>=</span> <span class=n>new_data</span><span class=o>.</span><span class=n>loc</span><span class=p>[(</span><span class=n>new_data</span><span class=p>[</span><span class=n>node</span><span class=p>]</span><span class=o>&gt;</span><span class=n>lower</span><span class=p>)</span><span class=o>&amp;</span><span class=p>(</span><span class=n>new_data</span><span class=p>[</span><span class=n>node</span><span class=p>]</span><span class=o>&lt;</span><span class=n>upper</span><span class=p>)]</span>
                <span class=n>SUM</span> <span class=o>=</span> <span class=n>new_data</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
                <span class=k>return</span> <span class=n>SUM</span>

            <span class=c1># Total number of true events</span>
            <span class=n>S_tot_test</span> <span class=o>=</span> <span class=n>data_test</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
            <span class=n>B_tot_test</span> <span class=o>=</span> <span class=n>data_test</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=s2>&quot;Signal&quot;</span><span class=p>)[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>S_tot_val</span> <span class=o>=</span> <span class=n>data_val</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
            <span class=n>B_tot_val</span> <span class=o>=</span> <span class=n>data_val</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=s2>&quot;Signal&quot;</span><span class=p>)[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>S_tot_train</span> <span class=o>=</span> <span class=n>data_train</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
            <span class=n>B_tot_train</span> <span class=o>=</span> <span class=n>data_train</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=s2>&quot;Signal&quot;</span><span class=p>)[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=c1># FIRST VERSION ####################################################################################################</span>

            <span class=c1># Steps in cuts -&gt; epsilon</span>
            <span class=n>N</span> <span class=o>=</span> <span class=mi>200</span>
            <span class=n>epsilon0_lower</span> <span class=o>=</span> <span class=mf>0.7</span>
            <span class=n>epsilon0_upper</span> <span class=o>=</span> <span class=mf>1.</span>
            <span class=n>epsilon</span> <span class=o>=</span> <span class=p>(</span><span class=n>epsilon0_upper</span><span class=o>-</span><span class=n>epsilon0_lower</span><span class=p>)</span><span class=o>/</span><span class=n>N</span>

            <span class=n>fom</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>
            <span class=n>eff_sig</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>
            <span class=n>eff_bkg</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>
            <span class=n>upper_cut</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span> <span class=o>+</span> <span class=n>epsilon0_upper</span>
            <span class=n>lower_cut</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span> <span class=o>+</span> <span class=n>epsilon0_lower</span>

            <span class=n>fom_test</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>
            <span class=n>eff_sig_test</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>
            <span class=n>eff_bkg_test</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>

            <span class=n>fom_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>
            <span class=n>eff_sig_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>
            <span class=n>eff_bkg_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>N</span><span class=p>)</span>

            <span class=c1># Fill the values</span>
            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>N</span><span class=p>):</span>
                <span class=n>upper_cut</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+=</span> <span class=o>-</span><span class=n>i</span><span class=o>*</span><span class=n>epsilon</span>
                <span class=n>lower_cut</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+=</span> <span class=n>i</span><span class=o>*</span><span class=n>epsilon</span>


            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>N</span><span class=p>):</span>
                <span class=n>S</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_val</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
                <span class=n>B</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_val</span><span class=p>,</span> <span class=s2>&quot;Background&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
                <span class=n>fom</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>FOM</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=n>B</span><span class=p>)</span>
                <span class=n>eff_sig</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>S</span><span class=o>/</span><span class=n>S_tot_val</span>
                <span class=n>eff_bkg</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>B</span><span class=o>/</span><span class=n>B_tot_val</span>

                <span class=n>S</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
                <span class=n>B</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Background&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
                <span class=n>fom_test</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>FOM</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=n>B</span><span class=p>)</span>
                <span class=n>eff_sig_test</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>S</span><span class=o>/</span><span class=n>S_tot_test</span>
                <span class=n>eff_bkg_test</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>B</span><span class=o>/</span><span class=n>B_tot_test</span>

                <span class=n>S</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_train</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
                <span class=n>B</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_train</span><span class=p>,</span> <span class=s2>&quot;Background&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>i</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
                <span class=n>fom_train</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>FOM</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=n>B</span><span class=p>)</span>
                <span class=n>eff_sig_train</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>S</span><span class=o>/</span><span class=n>S_tot_train</span>
                <span class=n>eff_bkg_train</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>B</span><span class=o>/</span><span class=n>B_tot_train</span>

            <span class=n>fom_max_val</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>fom</span><span class=p>),</span> <span class=mi>8</span><span class=p>)</span>
            <span class=n>imax</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>fom</span><span class=p>)</span>
            <span class=n>x_cut_val</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>epsilon0_lower</span> <span class=o>+</span> <span class=n>imax</span><span class=o>*</span><span class=n>epsilon</span><span class=p>,</span><span class=mi>4</span><span class=p>)</span>
            <span class=n>fom_max_test</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>fom_test</span><span class=p>),</span> <span class=mi>8</span><span class=p>)</span>
            <span class=n>jmax</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>fom_test</span><span class=p>)</span>
            <span class=n>x_cut_test</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>epsilon0_lower</span> <span class=o>+</span> <span class=n>jmax</span><span class=o>*</span><span class=n>epsilon</span><span class=p>,</span><span class=mi>4</span><span class=p>)</span>
            <span class=n>fom_max_train</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>fom_train</span><span class=p>),</span> <span class=mi>8</span><span class=p>)</span>
            <span class=n>kmax</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>fom_train</span><span class=p>)</span>
            <span class=n>x_cut_train</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>epsilon0_lower</span> <span class=o>+</span> <span class=n>kmax</span><span class=o>*</span><span class=n>epsilon</span><span class=p>,</span><span class=mi>4</span><span class=p>)</span>

            <span class=c1># Maximum FOM in test</span>
            <span class=n>S</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=p>[</span><span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Other&quot;</span><span class=p>],</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>fom_max</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>FOM</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=n>B</span><span class=p>),</span> <span class=mi>8</span><span class=p>)</span>

            <span class=n>fom_data</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=nb>str</span><span class=p>(</span><span class=n>k</span><span class=p>)]</span> <span class=o>=</span> <span class=p>[</span><span class=n>name</span><span class=p>,</span> <span class=s2>&quot;100-100&quot;</span><span class=p>,</span> <span class=n>activ</span><span class=p>,</span> <span class=n>loss_function</span><span class=p>,</span> <span class=n>learning_rate</span><span class=p>,</span> <span class=n>decay_rate</span><span class=p>,</span> <span class=n>fom_max_val</span><span class=p>,</span> <span class=n>x_cut_val</span><span class=p>,</span> <span class=n>fom_max</span><span class=p>,</span> <span class=n>fom_max_test</span><span class=p>]</span>

            <span class=k>def</span> <span class=nf>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>process</span><span class=p>,</span> <span class=n>predicted_events</span><span class=p>,</span> <span class=n>node</span><span class=p>,</span> <span class=n>cut</span><span class=p>):</span>
                <span class=n>lower</span> <span class=o>=</span> <span class=n>cut</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
                <span class=n>upper</span> <span class=o>=</span> <span class=n>cut</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
                <span class=n>new_data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s2>&quot;Predicted&quot;</span><span class=p>]</span><span class=o>==</span><span class=n>predicted_events</span><span class=p>]</span>
                <span class=k>if</span> <span class=n>process</span><span class=o>==</span><span class=s2>&quot;Signal&quot;</span><span class=p>:</span>
                    <span class=n>new_data</span> <span class=o>=</span> <span class=n>new_data</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=s2>&quot;Signal&quot;</span><span class=p>]</span>
                <span class=k>else</span><span class=p>:</span> 
                    <span class=n>new_data</span> <span class=o>=</span> <span class=n>new_data</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>process</span><span class=p>]</span>
                <span class=n>new_data</span> <span class=o>=</span> <span class=n>new_data</span><span class=o>.</span><span class=n>loc</span><span class=p>[(</span><span class=n>new_data</span><span class=p>[</span><span class=n>node</span><span class=p>]</span><span class=o>&gt;</span><span class=n>lower</span><span class=p>)</span><span class=o>&amp;</span><span class=p>(</span><span class=n>new_data</span><span class=p>[</span><span class=n>node</span><span class=p>]</span><span class=o>&lt;</span><span class=n>upper</span><span class=p>)]</span>
                <span class=n>SUM</span> <span class=o>=</span> <span class=n>new_data</span><span class=p>[</span><span class=s2>&quot;Weights&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
                <span class=k>return</span> <span class=n>SUM</span>

            <span class=n>B_W</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_T</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_Z</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_O</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>15</span><span class=p>))</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>lower_cut</span><span class=p>,</span> <span class=n>fom</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;blue&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Validation Data&quot;</span><span class=p>)</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>lower_cut</span><span class=p>,</span> <span class=n>fom_test</span><span class=p>,</span> <span class=n>ls</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Test Data&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>lower_cut</span><span class=p>,</span> <span class=n>fom_train</span><span class=p>,</span> <span class=n>ls</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;yellow&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Train Data&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Figure Of Merit&quot;</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;RUN &quot;</span><span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>k</span><span class=p>),</span> <span class=n>size</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>fontsize</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>
            <span class=n>maximum</span> <span class=o>=</span> <span class=nb>max</span><span class=p>([</span><span class=n>fom_max_val</span><span class=p>,</span> <span class=n>fom_max_train</span><span class=p>,</span> <span class=n>fom_max_test</span><span class=p>])</span>
            <span class=n>ticks</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=nb>round</span><span class=p>(</span><span class=n>maximum</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>+</span><span class=mf>0.1</span><span class=p>,</span><span class=mf>0.1</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>(</span><span class=n>ticks</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>
            <span class=n>number</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>ticks</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>/</span><span class=mf>0.5</span><span class=p>)</span>
            <span class=k>for</span> <span class=n>num</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>number</span><span class=p>):</span>
                <span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>num</span><span class=o>*</span><span class=mf>0.5</span><span class=o>+</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;black&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Test FOM: &quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>fom_max</span><span class=p>,</span><span class=mi>3</span><span class=p>))</span> <span class=o>+</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Max Validation FOM: &quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>fom_max_val</span><span class=p>,</span><span class=mi>4</span><span class=p>)),</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;gray&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>jmax</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Max Test FOM: &quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>fom_max_test</span><span class=p>,</span><span class=mi>4</span><span class=p>)),</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;red&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>kmax</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Max Train FOM: &quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>fom_max_train</span><span class=p>,</span><span class=mi>4</span><span class=p>)),</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;green&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>fontsize</span><span class=o>=</span><span class=mi>25</span><span class=p>,</span> <span class=n>loc</span><span class=o>=</span><span class=s2>&quot;lower left&quot;</span><span class=p>)</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>lower_cut</span><span class=p>,</span> <span class=n>eff_sig</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;red&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Signal Efficiency&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>lower_cut</span><span class=p>,</span> <span class=n>eff_bkg</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;purple&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Background Efficiency&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>yscale</span><span class=p>(</span><span class=s2>&quot;log&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Efficiency&quot;</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>imax</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;S: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span> <span class=o>+</span> <span class=s2>&quot;  W: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_W</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  T: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_T</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  Z: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_Z</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  O: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_O</span><span class=p>,</span><span class=mi>1</span><span class=p>)),</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;gray&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>)</span>

            <span class=n>S</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>jmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_W</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>jmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_T</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>jmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_Z</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>jmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_O</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>jmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>jmax</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;S: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span> <span class=o>+</span> <span class=s2>&quot;  W: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_W</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  T: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_T</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  Z: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_Z</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  O: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_O</span><span class=p>,</span><span class=mi>1</span><span class=p>)),</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;red&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>)</span>

            <span class=n>S</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>kmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_W</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Wjets&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>kmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_T</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;TTbar&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>kmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_Z</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Z2nu&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>kmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>
            <span class=n>B_O</span> <span class=o>=</span> <span class=n>SUM_OF_EVENTS</span><span class=p>(</span><span class=n>data_test</span><span class=p>,</span> <span class=s2>&quot;Other&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=s2>&quot;Signal&quot;</span><span class=p>,</span> <span class=p>[</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>kmax</span><span class=p>],</span><span class=n>epsilon0_upper</span><span class=p>])</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>lower_cut</span><span class=p>[</span><span class=n>kmax</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;S: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>S</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span> <span class=o>+</span> <span class=s2>&quot;  W: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_W</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  T: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_T</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  Z: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_Z</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span><span class=o>+</span><span class=s2>&quot;  O: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>B_O</span><span class=p>,</span><span class=mi>1</span><span class=p>)),</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;green&quot;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>)</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>fontsize</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>(</span><span class=n>fontsize</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>fontsize</span><span class=o>=</span><span class=mi>25</span><span class=p>,</span> <span class=n>loc</span><span class=o>=</span><span class=s2>&quot;lower left&quot;</span><span class=p>)</span>
            <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;Lower Cut On Signal Node Of NN Output&quot;</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>

            <span class=n>runs_path</span> <span class=o>=</span> <span class=n>org_path</span><span class=o>+</span><span class=s2>&quot;FOM_figures_runs/&quot;</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>runs_path</span><span class=p>):</span>
                <span class=n>os</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>runs_path</span><span class=p>)</span>

            <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=n>runs_path</span><span class=o>+</span><span class=s2>&quot;FOM_run&quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>k</span><span class=p>)</span><span class=o>+</span><span class=s2>&quot;.png&quot;</span><span class=p>)</span>

        <span class=n>fom_data</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=s2>&quot;17var_fom.csv&quot;</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s2>&quot;a&quot;</span><span class=p>)</span>
</code></pre></div> </details> <hr> <h2 id=how-to-train-on-a-gpu>How to train on a GPU<a class=headerlink href=#how-to-train-on-a-gpu title="Permanent link">&para;</a></h2> <p>Instructions on how to use a GPU to train NNs are given in <a href=https://cms-ml.github.io/documentation/resources/gpu_resources/cms_resources/lxplus_gpu.html#how-to-use-it>this page</a>.</p> <hr> <h2 id=reading-suggestions-references>Reading suggestions &amp; references<a class=headerlink href=#reading-suggestions-references title="Permanent link">&para;</a></h2> <ul> <li>Book available online, for free: <a href=https://www.deeplearningbook.org/ >https://www.deeplearningbook.org/</a></li> <li>"Deep learning for physics research" M. Erdmann, G. Kasieczka, J. Glombitza, U. Klemradt</li> </ul> <p>[1] “Adam: A Method for Stochastic Optimization”, Diederik P. Kingma, Jimmy Ba, arXiv:1412.6980</p> <hr> <p style="font-size: 0.8em; color: gray;"> Author: <strong>Pedrame Bargassa</strong><br> </p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2025</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2020-2023 CMS Machine Learning Group </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/cms-ml target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </a> <a href=https://hub.docker.com/orgs/cmsml/repositories target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1v59.4zm0-204.3h-66.1v60.7h66.1V32zm78.2 144.8H362v59.4h66.1v-59.4zm-156.3-72.1h-66.1v60.1h66.1v-60.1zm78.1 0h-66.1v60.1h66.1v-60.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1l-13.3-8.9zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm-78.1-72.1h-66.1v60.1h66.1v-60.1z"/></svg> </a> <a href=https://cms-talk.web.cern.ch/c/physics/ml/104 target=_blank rel=noopener title=cms-talk.web.cern.ch class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 448c141.4 0 256-93.1 256-208S397.4 32 256 32 0 125.1 0 240c0 45.1 17.7 86.8 47.7 120.9-1.9 24.5-11.4 46.3-21.4 62.9-5.5 9.2-11.1 16.6-15.2 21.6-2.1 2.5-3.7 4.4-4.9 5.7-.6.6-1 1.1-1.3 1.4l-.3.3c-4.6 4.6-5.9 11.4-3.4 17.4 2.5 6 8.3 9.9 14.8 9.9 28.7 0 57.6-8.9 81.6-19.3 22.9-10 42.4-21.9 54.3-30.6 31.8 11.5 67 17.9 104.1 17.9zM128 208a32 32 0 1 1 0 64 32 32 0 1 1 0-64zm128 0a32 32 0 1 1 0 64 32 32 0 1 1 0-64zm96 32a32 32 0 1 1 64 0 32 32 0 1 1-64 0z"/></svg> </a> <a href=mailto:cms-conveners-ml-knowledge@cern.ch target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l217.6 163.2c11.4 8.5 27 8.5 38.4 0l217.6-163.2c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48H48zM0 176v208c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V176L294.4 339.2a63.9 63.9 0 0 1-76.8 0L0 176z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["instant", "navigation.sections", "announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../assets/javascripts/bundle.ebd0bdb7.min.js></script> <script src=https://unpkg.com/mermaid@10.9/dist/mermaid.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../termynal.js></script> </body> </html>