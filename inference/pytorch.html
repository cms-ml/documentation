<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Documentation of the CMS Machine Learning Group"><meta name=author content="CMS Machine Learning Group"><link rel=canonical href=https://cms-ml.github.io/documentation/inference/pytorch.html><link rel=prev href=tensorflow2.html><link rel=next href=pyg.html><link rel=icon href=../images/favicon.png><meta name=generator content="mkdocs-1.4.2, mkdocs-material-9.0.3"><title>PyTorch - CMS Machine Learning Documentation</title><link rel=stylesheet href=../assets/stylesheets/main.6b71719e.min.css><link rel=stylesheet href=../assets/stylesheets/palette.2505c338.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=orange> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#pytorch-inference class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../index.html title="CMS Machine Learning Documentation" class="md-header__button md-logo" aria-label="CMS Machine Learning Documentation" data-md-component=logo> <img src=../images/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> CMS Machine Learning Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> PyTorch </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=orange aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=orange aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/cms-ml/documentation title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../index.html title="CMS Machine Learning Documentation" class="md-nav__button md-logo" aria-label="CMS Machine Learning Documentation" data-md-component=logo> <img src=../images/logo.png alt=logo> </a> CMS Machine Learning Documentation </label> <div class=md-nav__source> <a href=https://github.com/cms-ml/documentation title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../index.html class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2 type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 tabindex=0 aria-expanded=false> Innovation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Innovation data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Innovation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../innovation/journal_club.html class=md-nav__link> ML Journal Club </a> </li> <li class=md-nav__item> <a href=../innovation/hackathons.html class=md-nav__link> ML Hackathons </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 tabindex=0 aria-expanded=false> Resources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Resources data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../resources/cloud_resources/index.html class=md-nav__link> Cloud Resources </a> </li> <li class=md-nav__item> <a href=../resources/dataset_resources/index.html class=md-nav__link> Dataset Resources </a> </li> <li class=md-nav__item> <a href=../resources/fpga_resources/index.html class=md-nav__link> FPGA Resource </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_3_4 type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4 tabindex=0 aria-expanded=false> GPU Resources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="GPU Resources" data-md-level=2> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> GPU Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/lxplus_gpu.html class=md-nav__link> lxplus-gpu </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/lxplus_htcondor.html class=md-nav__link> CERN HTCondor </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/swan.html class=md-nav__link> SWAN </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/ml_cern_ch.html class=md-nav__link> ml.cern.ch </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4 type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 tabindex=0 aria-expanded=true> Guides <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Guides data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_1 type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 tabindex=0 aria-expanded=false> Software environments <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Software environments" data-md-level=2> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Software environments </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../software_envs/lcg_environments.html class=md-nav__link> LCG environments </a> </li> <li class=md-nav__item> <a href=../software_envs/containers.html class=md-nav__link> Using containers </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_2 type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 tabindex=0 aria-expanded=false> Optimization <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Optimization data-md-level=2> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../optimization/model_optimization.html class=md-nav__link> Model optimization </a> </li> <li class=md-nav__item> <a href=../optimization/importance.html class=md-nav__link> Feature importance </a> </li> <li class=md-nav__item> <a href=../optimization/data_augmentation.html class=md-nav__link> Data augmentation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_3 type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 tabindex=0 aria-expanded=false> General Advice <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="General Advice" data-md-level=2> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> General Advice </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/intro.html class=md-nav__link> Introduction </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_3_2 type=checkbox id=__nav_4_3_2> <label class=md-nav__link for=__nav_4_3_2 tabindex=0 aria-expanded=false> Before training <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Before training" data-md-level=3> <label class=md-nav__title for=__nav_4_3_2> <span class="md-nav__icon md-icon"></span> Before training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/before/domains.html class=md-nav__link> Domains </a> </li> <li class=md-nav__item> <a href=../general_advice/before/features.html class=md-nav__link> Features </a> </li> <li class=md-nav__item> <a href=../general_advice/before/inputs.html class=md-nav__link> Inputs </a> </li> <li class=md-nav__item> <a href=../general_advice/before/model.html class=md-nav__link> Model </a> </li> <li class=md-nav__item> <a href=../general_advice/before/metrics.html class=md-nav__link> Metrics & Losses </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_3_3 type=checkbox id=__nav_4_3_3> <label class=md-nav__link for=__nav_4_3_3 tabindex=0 aria-expanded=false> During training <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="During training" data-md-level=3> <label class=md-nav__title for=__nav_4_3_3> <span class="md-nav__icon md-icon"></span> During training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/during/overfitting.html class=md-nav__link> Overfitting </a> </li> <li class=md-nav__item> <a href=../general_advice/during/xvalidation.html class=md-nav__link> Cross-validation </a> </li> <li class=md-nav__item> <a href=../general_advice/during/opt.html class=md-nav__link> Optimisation problems </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../general_advice/after/after.html class=md-nav__link> After training </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4 type=checkbox id=__nav_4_4 checked> <label class=md-nav__link for=__nav_4_4 tabindex=0 aria-expanded=true> Inference <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Inference data-md-level=2> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> Inference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_1 type=checkbox id=__nav_4_4_1 checked> <label class=md-nav__link for=__nav_4_4_1 tabindex=0 aria-expanded=true> Direct inference <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Direct inference" data-md-level=3> <label class=md-nav__title for=__nav_4_4_1> <span class="md-nav__icon md-icon"></span> Direct inference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=tensorflow1.html class=md-nav__link> TensorFlow 1 </a> </li> <li class=md-nav__item> <a href=tensorflow2.html class=md-nav__link> TensorFlow 2 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> PyTorch <span class="md-nav__icon md-icon"></span> </label> <a href=pytorch.html class="md-nav__link md-nav__link--active"> PyTorch </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introductory-references class=md-nav__link> Introductory References </a> </li> <li class=md-nav__item> <a href=#the-basics class=md-nav__link> The Basics </a> <nav class=md-nav aria-label="The Basics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensors class=md-nav__link> Tensors </a> <nav class=md-nav aria-label=Tensors> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-support class=md-nav__link> GPU Support </a> </li> <li class=md-nav__item> <a href=#autograd class=md-nav__link> Autograd </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-utils class=md-nav__link> Data Utils </a> </li> <li class=md-nav__item> <a href=#neural-networks class=md-nav__link> Neural Networks </a> </li> <li class=md-nav__item> <a href=#optimizers class=md-nav__link> Optimizers </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#pytorch-in-cmssw class=md-nav__link> PyTorch in CMSSW </a> <nav class=md-nav aria-label="PyTorch in CMSSW"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#via-onnx class=md-nav__link> Via ONNX </a> <nav class=md-nav aria-label="Via ONNX"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#example-use-cases class=md-nav__link> Example Use Cases </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#via-triton class=md-nav__link> Via Triton </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#training-tips class=md-nav__link> Training Tips </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=pyg.html class=md-nav__link> PyTorch Geometric </a> </li> <li class=md-nav__item> <a href=onnx.html class=md-nav__link> ONNX </a> </li> <li class=md-nav__item> <a href=xgboost.html class=md-nav__link> XGBoost </a> </li> <li class=md-nav__item> <a href=hls4ml.html class=md-nav__link> hls4ml </a> </li> <li class=md-nav__item> <a href=conifer.html class=md-nav__link> conifer </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_2 type=checkbox id=__nav_4_4_2> <label class=md-nav__link for=__nav_4_4_2 tabindex=0 aria-expanded=false> Inference as a service <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Inference as a service" data-md-level=3> <label class=md-nav__title for=__nav_4_4_2> <span class="md-nav__icon md-icon"></span> Inference as a service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=sonic_triton.html class=md-nav__link> Sonic/Triton </a> </li> <li class=md-nav__item> <a href=tfaas.html class=md-nav__link> TFaaS </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_3 type=checkbox id=__nav_4_4_3> <label class=md-nav__link for=__nav_4_4_3 tabindex=0 aria-expanded=false> Non-standard workflows <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Non-standard workflows" data-md-level=3> <label class=md-nav__title for=__nav_4_4_3> <span class="md-nav__icon md-icon"></span> Non-standard workflows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=standalone.html class=md-nav__link> Standalone framework </a> </li> <li class=md-nav__item> <a href=swan_aws.html class=md-nav__link> SWAN + AWS </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=checklist.html class=md-nav__link> Integration checklist </a> </li> <li class=md-nav__item> <a href=performance.html class=md-nav__link> Performance </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_6 type=checkbox id=__nav_4_4_6> <label class=md-nav__link for=__nav_4_4_6 tabindex=0 aria-expanded=false> Successful integrations <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Successful integrations" data-md-level=3> <label class=md-nav__title for=__nav_4_4_6> <span class="md-nav__icon md-icon"></span> Successful integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=particlenet.html class=md-nav__link> ParticleNet </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_5 type=checkbox id=__nav_4_5> <label class=md-nav__link for=__nav_4_5 tabindex=0 aria-expanded=false> Training <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Training data-md-level=2> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/Decorrelation.html class=md-nav__link> Decorrelation </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_5_2 type=checkbox id=__nav_4_5_2> <label class=md-nav__link for=__nav_4_5_2 tabindex=0 aria-expanded=false> Training as a Service <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Training as a Service" data-md-level=3> <label class=md-nav__title for=__nav_4_5_2> <span class="md-nav__icon md-icon"></span> Training as a Service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/MLaaS4HEP.html class=md-nav__link> MLaaS4HEP </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../training/autoencoders.html class=md-nav__link> Autoencoders </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introductory-references class=md-nav__link> Introductory References </a> </li> <li class=md-nav__item> <a href=#the-basics class=md-nav__link> The Basics </a> <nav class=md-nav aria-label="The Basics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensors class=md-nav__link> Tensors </a> <nav class=md-nav aria-label=Tensors> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-support class=md-nav__link> GPU Support </a> </li> <li class=md-nav__item> <a href=#autograd class=md-nav__link> Autograd </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-utils class=md-nav__link> Data Utils </a> </li> <li class=md-nav__item> <a href=#neural-networks class=md-nav__link> Neural Networks </a> </li> <li class=md-nav__item> <a href=#optimizers class=md-nav__link> Optimizers </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#pytorch-in-cmssw class=md-nav__link> PyTorch in CMSSW </a> <nav class=md-nav aria-label="PyTorch in CMSSW"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#via-onnx class=md-nav__link> Via ONNX </a> <nav class=md-nav aria-label="Via ONNX"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#example-use-cases class=md-nav__link> Example Use Cases </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#via-triton class=md-nav__link> Via Triton </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#training-tips class=md-nav__link> Training Tips </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=pytorch-inference>PyTorch Inference<a class=headerlink href=#pytorch-inference title="Permanent link">&para;</a></h1> <p>PyTorch is an open source ML library developed by Facebook's AI Research lab. Initially released in late-2016, PyTorch is a relatively new tool, but has become increasingly popular among ML researchers (in fact, <a href=http://horace.io/pytorch-vs-tensorflow/ >some analyses</a> suggest it's becoming more popular than TensorFlow in academic communities!). PyTorch is written in idiomatic Python, so its syntax is easy to parse for experienced Python programmers. Additionally, it is highly compatible with graphics processing units (GPUs), which can substantially accelerate many deep learning workflows. To date PyTorch has not been integrated into CMSSW. Trained PyTorch models may be evaluated in CMSSW via ONNX Runtime, but model construction and training workflows must currently exist outside of CMSSW. Given the considerable interest in PyTorch within the HEP/ML community, we have reason to believe it will soon be available, so stay tuned! </p> <h2 id=introductory-references>Introductory References<a class=headerlink href=#introductory-references title="Permanent link">&para;</a></h2> <ul> <li><a href=https://pytorch.org/get-started/locally/ >PyTorch Install Guide</a></li> <li><a href=https://pytorch.org/tutorials/ >PyTorch Tutorials</a></li> <li><a href=https://github.com/FNALLPC/machine-learning-hats/blob/master/3.1-dense-pytorch.ipynb>LPC HATs: PyTorch</a></li> <li><a href=https://github.com/Atcold/pytorch-Deep-Learning>Deep Learning w/ PyTorch Course Repo</a></li> <li><a href=https://codas-hep.org/ >CODAS-HEP</a></li> </ul> <h2 id=the-basics>The Basics<a class=headerlink href=#the-basics title="Permanent link">&para;</a></h2> <p>The following documentation surrounds a set of code snippets designed to highlight some important ML features made available in PyTorch. In the following sections, we'll break down snippets from this script, highlighting specifically the PyTorch objects in it. </p> <h3 id=tensors>Tensors<a class=headerlink href=#tensors title="Permanent link">&para;</a></h3> <p>The fundamental PyTorch object is the tensor. At a glance, tensors behave similarly to NumPy arrays. For example, they are broadcasted, concatenated, and sliced in exactly the same way. The following examples highlight some common numpy-like tensor transformations: <div class=highlight><pre><span></span><code><span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>))</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
            <span class=p>[</span> <span class=mf>1.2677</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>],</span>
            <span class=p>[</span><span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
            <span class=p>[</span> <span class=mf>1.2677</span><span class=p>],</span>
            <span class=p>[</span><span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>,</span>  <span class=mf>1.2677</span><span class=p>],</span>
            <span class=p>[</span><span class=o>-</span><span class=mf>0.0204</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[[</span> <span class=mf>1.3552</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
             <span class=p>[</span> <span class=mf>1.2677</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
            <span class=p>[</span> <span class=mf>1.2677</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
</code></pre></div> Additionally, torch supports familiar matrix operations with various syntax options: <div class=highlight><pre><span></span><code><span class=n>m1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>))</span>
<span class=n>m2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>2</span><span class=p>))</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>

<span class=n>m1</span> <span class=o>@</span> <span class=n>m2</span> <span class=o>==</span> <span class=n>m1</span><span class=o>.</span><span class=n>mm</span><span class=p>(</span><span class=n>m2</span><span class=p>)</span> <span class=c1># matrix multiplication</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>],</span>
            <span class=p>[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>]])</span>

<span class=n>m1</span> <span class=o>@</span> <span class=n>x</span> <span class=o>==</span> <span class=n>m1</span><span class=o>.</span><span class=n>mv</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># matrix-vector multiplication</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>])</span>

<span class=n>m1</span><span class=o>.</span><span class=n>t</span><span class=p>()</span> <span class=o>==</span> <span class=n>m1</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=c1># matrix transpose</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>],</span>
            <span class=p>[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>],</span>
            <span class=p>[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>]])</span>
</code></pre></div> Note that <code>tensor.transpose(dim0, dim1)</code> is a more general operation than <code>tensor.t()</code>. It is important to note that tensors have been ''upgraded'' from Numpy arrays in two key ways: 1) Tensors have native GPU support. If a GPU is available at runtime, tensors can be transferred from CPU to GPU, where computations such as matrix operations are substantially faster. Note that tensor operations must be performed on objects on the same device. PyTorch supports CUDA tensor types for GPU computation (see the <a href=https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics>PyTorch Cuda Semantics</a> guide). 2) Tensors support automatic gradient (audograd) calculations, such that operations on tensors flagged with <code>requires_grad=True</code> are automatically tracked. The flow of tracked tensor operations defines a <em>computation graph</em> in which nodes are tensors and edges are functions mapping input tensors to output tensors. Gradients are calculated numerically via autograd by walking through this computation graph. </p> <h4 id=gpu-support>GPU Support<a class=headerlink href=#gpu-support title="Permanent link">&para;</a></h4> <p>Tensors are created on the host CPU by default: <div class=highlight><pre><span></span><code><span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
<span class=n>b</span><span class=o>.</span><span class=n>device</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>cpu</span>
</code></pre></div></p> <p>You can also create tensors on any available GPUs: <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=c1># check that a GPU is available</span>
<span class=o>&gt;&gt;&gt;</span> <span class=kc>True</span> 
<span class=n>cuda0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda:0&#39;</span><span class=p>)</span>
<span class=n>c</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>cuda0</span><span class=p>)</span>
<span class=n>c</span><span class=o>.</span><span class=n>device</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span>
</code></pre></div></p> <p>You can also move tensors between devices: <div class=highlight><pre><span></span><code><span class=n>b</span> <span class=o>=</span> <span class=n>b</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>cuda0</span><span class=p>)</span>
<span class=n>b</span><span class=o>.</span><span class=n>device</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span>
</code></pre></div></p> <p>There are trade-offs between computations on the CPU and GPU. GPUs have limited memory and there is a cost associated with transfering data from CPUs to GPUs. However, GPUs perform heavy matrix operations much faster than CPUs, and are therefore often used to speed up training routines. </p> <div class=highlight><pre><span></span><code><span class=n>N</span> <span class=o>=</span> <span class=mi>1000</span> <span class=c1># </span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>500</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=mi>5000</span><span class=p>]):</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;(</span><span class=si>{}</span><span class=s2>,</span><span class=si>{}</span><span class=s2>) Matrices:&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>))</span>
    <span class=n>M1_cpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
    <span class=n>M2_cpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
    <span class=n>M1_gpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=n>cuda0</span><span class=p>)</span>
    <span class=n>M2_gpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=n>cuda0</span><span class=p>)</span>
    <span class=k>if</span> <span class=p>(</span><span class=n>i</span><span class=o>==</span><span class=mi>0</span><span class=p>):</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Check devices for each tensor:&#39;</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;M1_cpu, M2_cpu devices:&#39;</span><span class=p>,</span> <span class=n>M1_cpu</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>M2_cpu</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;M1_gpu, M2_gpu devices:&#39;</span><span class=p>,</span> <span class=n>M1_gpu</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>M2_gpu</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>large_matrix_multiply</span><span class=p>(</span><span class=n>M1</span><span class=p>,</span> <span class=n>M2</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>M1</span> <span class=o>*</span> <span class=n>M2</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>

    <span class=n>n_iter</span> <span class=o>=</span> <span class=mi>1000</span>
    <span class=n>t_cpu</span> <span class=o>=</span> <span class=n>Timer</span><span class=p>(</span><span class=k>lambda</span><span class=p>:</span> <span class=n>large_matrix_multiply</span><span class=p>(</span><span class=n>M1_cpu</span><span class=p>,</span> <span class=n>M2_cpu</span><span class=p>))</span>
    <span class=n>cpu_time</span> <span class=o>=</span> <span class=n>t_cpu</span><span class=o>.</span><span class=n>timeit</span><span class=p>(</span><span class=n>number</span><span class=o>=</span><span class=n>n_iter</span><span class=p>)</span><span class=o>/</span><span class=n>n_iter</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;cpu time per call: </span><span class=si>{:.6f}</span><span class=s1> s&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cpu_time</span><span class=p>))</span>

    <span class=n>t_gpu</span> <span class=o>=</span> <span class=n>Timer</span><span class=p>(</span><span class=k>lambda</span><span class=p>:</span> <span class=n>large_matrix_multiply</span><span class=p>(</span><span class=n>M1_gpu</span><span class=p>,</span> <span class=n>M2_gpu</span><span class=p>))</span>
    <span class=n>gpu_time</span> <span class=o>=</span> <span class=n>t_gpu</span><span class=o>.</span><span class=n>timeit</span><span class=p>(</span><span class=n>number</span><span class=o>=</span><span class=n>n_iter</span><span class=p>)</span><span class=o>/</span><span class=n>n_iter</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;gpu time per call: </span><span class=si>{:.6f}</span><span class=s1> s&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>gpu_time</span><span class=p>))</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;gpu_time/cpu_time: </span><span class=si>{:.6f}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>))</span>

<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>10</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>Check</span> <span class=n>devices</span> <span class=k>for</span> <span class=n>each</span> <span class=n>tensor</span><span class=p>:</span>
<span class=n>M1_cpu</span><span class=p>,</span> <span class=n>M2_cpu</span> <span class=n>devices</span><span class=p>:</span> <span class=n>cpu</span> <span class=n>cpu</span>
<span class=n>M1_gpu</span><span class=p>,</span> <span class=n>M2_gpu</span> <span class=n>devices</span><span class=p>:</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000008</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>1.904711</span>

<span class=p>(</span><span class=mi>100</span><span class=p>,</span><span class=mi>100</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.993163</span>

<span class=p>(</span><span class=mi>500</span><span class=p>,</span><span class=mi>500</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000058</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000016</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.267371</span>

<span class=p>(</span><span class=mi>1000</span><span class=p>,</span><span class=mi>1000</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000170</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.089784</span>

<span class=p>(</span><span class=mi>5000</span><span class=p>,</span><span class=mi>5000</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.025083</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000011</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.000419</span>
</code></pre></div> <p>The complete list of Torch Tensor operations is available in the <a href="https://pytorch.org/docs/stable/torch.html?highlight=mm">docs</a>. </p> <h4 id=autograd>Autograd<a class=headerlink href=#autograd title="Permanent link">&para;</a></h4> <p>Backpropagation occurs automatically through autograd. For example, consider the following function and its derivatives:</p> <div class=arithmatex>\[\begin{aligned} f(\textbf{a}, \textbf{b}) &amp;= \textbf{a}^T \textbf{X} \textbf{b} \\ \frac{\partial f}{\partial \textbf{a}} &amp;= \textbf{b}^T \textbf{X}^T\\ \frac{\partial f}{\partial \textbf{b}} &amp;= \textbf{a}^T \textbf{X} \end{aligned}\]</div> <p>Given specific choices of <span class=arithmatex>\(\textbf{X}\)</span>, <span class=arithmatex>\(\textbf{a}\)</span>, and <span class=arithmatex>\(\textbf{b}\)</span>, we can calculate the corresponding derivatives via autograd by requiring a gradient to be stored in each relevant tensor: <div class=highlight><pre><span></span><code><span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>),</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>0.5</span><span class=p>,</span> <span class=o>-</span><span class=mi>2</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>f</span> <span class=o>=</span> <span class=n>a</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>X</span> <span class=o>@</span> <span class=n>b</span>
<span class=n>f</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>(</span><span class=o>-</span><span class=mf>2.2500</span><span class=p>,</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>DotBackward</span><span class=o>&gt;</span><span class=p>)</span> 
<span class=n>f</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span> <span class=c1># backprop </span>
<span class=n>a</span><span class=o>.</span><span class=n>grad</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>1.5000</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.5000</span><span class=p>])</span>
<span class=n>b</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>X</span><span class=o>.</span><span class=n>T</span> 
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>1.5000</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.5000</span><span class=p>],</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>SqueezeBackward3</span><span class=o>&gt;</span><span class=p>)</span>
<span class=n>b</span><span class=o>.</span><span class=n>grad</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.5000</span><span class=p>,</span> <span class=mf>1.5000</span><span class=p>])</span>
<span class=n>a</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>X</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.5000</span><span class=p>,</span> <span class=mf>1.5000</span><span class=p>],</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>SqueezeBackward3</span><span class=o>&gt;</span><span class=p>)</span>
</code></pre></div> The <code>tensor.backward()</code> call initiates backpropagation, accumulating the gradient backward through a series of <code>grad_fn</code> labels tied to each tensor (e.g. <code>&lt;DotBackward&gt;</code>, indicating the dot product <span class=arithmatex>\((\textbf{a}^T\textbf{X})\textbf{b}\)</span>). </p> <h3 id=data-utils>Data Utils<a class=headerlink href=#data-utils title="Permanent link">&para;</a></h3> <p>PyTorch is equipped with many useful data-handling utilities. For example, the <code>torch.utils.data</code> package implements datasets (<code>torch.utils.data.Dataset</code>) and iterable data loaders (<code>torch.utils.data.DataLoader</code>). Additionally, various batching and sampling schemes are available. </p> <p>You can create custom iterable datasets via <code>torch.utils.data.Dataset</code>, for example a dataset collecting the results of XOR on two binary inputs: <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>Dataset</span>

<span class=k>class</span> <span class=nc>Data</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>samples</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>]])</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>targets</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>logical_xor</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>samples</span><span class=p>[:,</span><span class=mi>0</span><span class=p>],</span> 
                                      <span class=bp>self</span><span class=o>.</span><span class=n>samples</span><span class=p>[:,</span><span class=mi>1</span><span class=p>])</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>targets</span><span class=p>)</span>

    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>idx</span><span class=p>):</span>
        <span class=k>return</span><span class=p>({</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>samples</span><span class=p>[</span><span class=n>idx</span><span class=p>],</span>
                <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>targets</span><span class=p>[</span><span class=n>idx</span><span class=p>]})</span>
</code></pre></div> Dataloaders, from <code>torch.utils.data.DataLoader</code>, can generate shuffled batches of data via multiple workers. Here, we load our datasets onto the GPU: <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span>

<span class=n>device</span> <span class=o>=</span> <span class=s1>&#39;cpu&#39;</span>
<span class=n>train_data</span> <span class=o>=</span> <span class=n>Data</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>test_data</span> <span class=o>=</span> <span class=n>Data</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>train_data</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>test_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>test_data</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>batch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>batch</span><span class=p>)</span>

<span class=o>&gt;&gt;&gt;</span> <span class=mi>0</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>0.</span><span class=p>,</span> <span class=mf>0.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>0.</span><span class=p>])}</span>
    <span class=mi>1</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>1.</span><span class=p>,</span> <span class=mf>0.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.</span><span class=p>])}</span>
    <span class=mi>2</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>1.</span><span class=p>,</span> <span class=mf>1.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>0.</span><span class=p>])}</span>
    <span class=mi>3</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>0.</span><span class=p>,</span> <span class=mf>1.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.</span><span class=p>])}</span>
</code></pre></div> The full set of data utils is available in the <a href="https://pytorch.org/docs/stable/data.html?highlight=dataset">docs</a>. </p> <h3 id=neural-networks>Neural Networks<a class=headerlink href=#neural-networks title="Permanent link">&para;</a></h3> <p>The PyTorch <em>nn</em> package specifies a set of modules that correspond to different neural network (NN) components and operations. For example, the <code>torch.nn.Linear</code> module defines a linear transform with learnable parameters and the <code>torch.nn.Flatten</code> module flattens two contiguous tensor dimensions. The <code>torch.nn.Sequential</code> module contains a set of modules such as <code>torch.nn.Linear</code> and <code>torch.nn.Sequential</code>, chaining them together to form the forward pass of a forward network. Furthermore, one may specify various pre-implemented loss functions, for example <code>torch.nn.BCELoss</code> and <code>torch.nn.KLDivLoss</code>. The full set of PyTorch NN building blocks is available in the <a href=https://pytorch.org/docs/stable/nn.html>docs</a>. </p> <p>As an example, we can design a simple neural network designed to reproduce the output of the XOR operation on binary inputs. To do so, we can compute a simple NN of the form:</p> <div class=arithmatex>\[\begin{aligned} x_{in}&amp;\in\{0,1\}^{2}\\ l_1 &amp;= \sigma(W_1^Tx_{in} + b_1); \ W_1\in\mathbb{R}^{2\times2},\ b_1\in\mathbb{R}^{2}\\ l_2 &amp;= \sigma(W_2^Tx + b_2); \ W_2\in\mathbb{R}^{2},\ b_1\in\mathbb{R}\\ \end{aligned}\]</div> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>

<span class=k>class</span> <span class=nc>Network</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>l1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>l2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>l1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>l2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=k>return</span> <span class=n>x</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>Network</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>model</span><span class=p>(</span><span class=n>train_data</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>

<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>0.5000</span><span class=p>],</span>
            <span class=p>[</span><span class=mf>0.4814</span><span class=p>],</span>
            <span class=p>[</span><span class=mf>0.5148</span><span class=p>],</span>
            <span class=p>[</span><span class=mf>0.4957</span><span class=p>]],</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>SigmoidBackward</span><span class=o>&gt;</span><span class=p>)</span>
</code></pre></div> <h3 id=optimizers>Optimizers<a class=headerlink href=#optimizers title="Permanent link">&para;</a></h3> <p>Training a neural network involves minimizing a loss function; classes in the <code>torch.optim</code> package implement various optimization strategies for example stochastic gradient descent and Adam through <code>torch.optim.SGD</code> and <code>torch.optim.Adam</code> respectively. Optimizers are configurable through parameters such as the learning rate (configuring the optimizer's step size). The full set of optimizers and accompanying tutorials are available in the <a href=https://pytorch.org/docs/stable/optim.html>docs</a>.</p> <p>To demonstrate the use of an optimizer, let's train the NN above to produce the results of the XOR operation on binary inputs. Here we'll use the <a href=https://arxiv.org/abs/1412.6980>Adam optimizer</a>:</p> <p><div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>torch</span> <span class=kn>import</span> <span class=n>optim</span>
<span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>StepLR</span>
<span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>

<span class=c1># helpful references:</span>
<span class=c1># Learning XOR: exploring the space of a classic problem</span>
<span class=c1># https://towardsdatascience.com/how-neural-networks-solve-the-xor-problem-59763136bdd7</span>
<span class=c1># https://courses.cs.washington.edu/courses/cse446/18wi/sections/section8/XOR-Pytorch.html</span>

<span class=c1># the training function initiates backprop and </span>
<span class=c1># steps the optimizer towards the weights that </span>
<span class=c1># optimize the loss function </span>
<span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>epoch</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=n>losses</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>batch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>
        <span class=n>y</span><span class=p>,</span> <span class=n>output</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;y&#39;</span><span class=p>],</span> <span class=n>output</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>

        <span class=c1># optimize binary cross entropy:</span>
        <span class=c1># https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>binary_cross_entropy</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>reduction</span><span class=o>=</span><span class=s1>&#39;mean&#39;</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
        <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>())</span>

    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>losses</span><span class=p>)</span>

<span class=c1># the test function does not adjust the model&#39;s weights</span>
<span class=k>def</span> <span class=nf>test</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=n>losses</span><span class=p>,</span> <span class=n>n_correct</span><span class=p>,</span> <span class=n>n_incorrect</span> <span class=o>=</span> <span class=p>[],</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span>
    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>batch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>test_loader</span><span class=p>):</span>
            <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>
            <span class=n>y</span><span class=p>,</span> <span class=n>output</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;y&#39;</span><span class=p>],</span> <span class=n>output</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>binary_cross_entropy</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> 
                                          <span class=n>reduction</span><span class=o>=</span><span class=s1>&#39;mean&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
            <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>

            <span class=c1># determine accuracy by thresholding model output at 0.5</span>
            <span class=n>batch_correct</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(((</span><span class=n>output</span><span class=o>&gt;</span><span class=mf>0.5</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>y</span><span class=o>==</span><span class=mi>1</span><span class=p>))</span> <span class=o>|</span>
                                      <span class=p>((</span><span class=n>output</span><span class=o>&lt;</span><span class=mf>0.5</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>y</span><span class=o>==</span><span class=mi>0</span><span class=p>)))</span>
            <span class=n>batch_incorrect</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>y</span><span class=p>)</span> <span class=o>-</span> <span class=n>batch_correct</span>
            <span class=n>n_correct</span> <span class=o>+=</span> <span class=n>batch_correct</span>
            <span class=n>n_incorrect</span> <span class=o>+=</span> <span class=n>batch_incorrect</span>

    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>losses</span><span class=p>),</span> <span class=n>n_correct</span><span class=o>/</span><span class=p>(</span><span class=n>n_correct</span><span class=o>+</span><span class=n>n_incorrect</span><span class=p>)</span>


<span class=c1># randomly initialize the model&#39;s weights</span>
<span class=k>for</span> <span class=n>module</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
        <span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

<span class=c1># send weights to optimizer </span>
<span class=n>lr</span> <span class=o>=</span> <span class=mf>2.5e-2</span>
<span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>)</span>

<span class=n>epochs</span> <span class=o>=</span> <span class=mi>500</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>epochs</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
    <span class=n>train_loss</span> <span class=o>=</span> <span class=n>train</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>epoch</span><span class=p>)</span>
    <span class=n>test_loss</span><span class=p>,</span> <span class=n>test_acc</span> <span class=o>=</span> <span class=n>test</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>epoch</span><span class=o>%</span><span class=mi>25</span><span class=o>==</span><span class=mi>0</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;epoch=</span><span class=si>{}</span><span class=s1>: train_loss=</span><span class=si>{:.3f}</span><span class=s1>, test_loss=</span><span class=si>{:.3f}</span><span class=s1>, test_acc=</span><span class=si>{:.3f}</span><span class=s1>&#39;</span>
              <span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>epoch</span><span class=p>,</span> <span class=n>train_loss</span><span class=p>,</span> <span class=n>test_loss</span><span class=p>,</span> <span class=n>test_acc</span><span class=p>))</span>

<span class=o>&gt;&gt;&gt;</span> <span class=n>epoch</span><span class=o>=</span><span class=mi>25</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.683</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.681</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.500</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>50</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.665</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.664</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>75</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.640</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.635</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>100</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.598</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.595</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>125</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.554</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.550</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>150</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.502</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.498</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>175</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.435</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.432</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>200</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.360</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.358</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>225</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.290</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.287</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>250</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.230</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.228</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>275</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.184</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.183</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>300</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.149</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.148</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>325</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.122</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.122</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>350</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.102</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.101</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>375</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.086</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.086</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>400</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.074</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.073</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>425</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.064</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.063</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>450</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.056</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.055</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>475</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.049</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.049</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>500</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.043</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.043</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
</code></pre></div> Here, the model has converged to 100% test accuracy, indicating that it has learned to reproduce the XOR outputs perfectly. Note that even though the test accuracy is 100%, the test loss (BCE) decreases steadily; this is because the BCE loss is nonzero when <span class=arithmatex>\(y_{output}\)</span> is not exactly 0 or 1, while accuracy is determined by thresholding the model outputs such that each prediction is the boolean <span class=arithmatex>\((y_{output} &gt; 0.5)\)</span>. This highlights that it is important to choose the correct performance metric for an ML problem. In the case of XOR, perfect test accuracy is sufficient. Let's check that we've recovered the XOR output by extracting the model's weights and using them to build a custom XOR function:</p> <div class=highlight><pre><span></span><code><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
    <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>param</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>

<span class=o>&gt;&gt;&gt;</span> <span class=n>l1</span><span class=o>.</span><span class=n>weight</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>7.2888</span><span class=p>,</span> <span class=o>-</span><span class=mf>6.4168</span><span class=p>],</span>
                      <span class=p>[</span> <span class=mf>7.2824</span><span class=p>,</span> <span class=o>-</span><span class=mf>8.1637</span><span class=p>]])</span>
    <span class=n>l1</span><span class=o>.</span><span class=n>bias</span> <span class=n>tensor</span><span class=p>([</span> <span class=mf>2.6895</span><span class=p>,</span> <span class=o>-</span><span class=mf>3.9633</span><span class=p>])</span>
    <span class=n>l2</span><span class=o>.</span><span class=n>weight</span> <span class=n>tensor</span><span class=p>([[</span><span class=o>-</span><span class=mf>6.3500</span><span class=p>,</span>  <span class=mf>8.0990</span><span class=p>]])</span>
    <span class=n>l2</span><span class=o>.</span><span class=n>bias</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>2.5058</span><span class=p>])</span>
</code></pre></div> <p>Because our model was built with <code>nn.Linear</code> modules, we have weight matrices and bias terms. Next, we'll hard-code the matrix operations into a custom XOR function based on the architecture of the NN: </p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>XOR</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=n>w1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span> <span class=mf>7.2888</span><span class=p>,</span> <span class=o>-</span><span class=mf>6.4168</span><span class=p>],</span>
                       <span class=p>[</span> <span class=mf>7.2824</span><span class=p>,</span> <span class=o>-</span><span class=mf>8.1637</span><span class=p>]])</span><span class=o>.</span><span class=n>t</span><span class=p>()</span>
    <span class=n>b1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span> <span class=mf>2.6895</span><span class=p>,</span> <span class=o>-</span><span class=mf>3.9633</span><span class=p>])</span>
    <span class=n>layer1_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>b1</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
                               <span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>b1</span><span class=p>[</span><span class=mi>1</span><span class=p>]])</span>
    <span class=n>layer1_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>layer1_out</span><span class=p>)</span>

    <span class=n>w2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>6.3500</span><span class=p>,</span>  <span class=mf>8.0990</span><span class=p>])</span>
    <span class=n>b2</span> <span class=o>=</span> <span class=mf>2.5058</span>
    <span class=n>layer2_out</span> <span class=o>=</span> <span class=n>layer1_out</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=n>w2</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>layer1_out</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=n>w2</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>b2</span>
    <span class=n>layer2_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>layer2_out</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>layer2_out</span><span class=p>,</span> <span class=p>(</span><span class=n>layer2_out</span> <span class=o>&gt;</span> <span class=mf>0.5</span><span class=p>)</span>

<span class=n>XOR</span><span class=p>([</span><span class=mf>0.</span><span class=p>,</span><span class=mf>0.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.0359</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>False</span><span class=p>))</span>
<span class=n>XOR</span><span class=p>([</span><span class=mf>0.</span><span class=p>,</span><span class=mf>1.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.9135</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>True</span><span class=p>))</span>
<span class=n>XOR</span><span class=p>([</span><span class=mf>1.</span><span class=p>,</span><span class=mf>0.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.9815</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>True</span><span class=p>))</span>
<span class=n>XOR</span><span class=p>([</span><span class=mf>1.</span><span class=p>,</span><span class=mf>1.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.0265</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>False</span><span class=p>))</span>
</code></pre></div> <p>There we have it - the NN learned XOR! </p> <h2 id=pytorch-in-cmssw>PyTorch in CMSSW<a class=headerlink href=#pytorch-in-cmssw title="Permanent link">&para;</a></h2> <h3 id=via-onnx>Via ONNX<a class=headerlink href=#via-onnx title="Permanent link">&para;</a></h3> <p>One way to incorporate your PyTorch models into CMSSW is through the <a href=https://www.onnxruntime.ai/about.html>Open Neural Network Exchange</a> (ONNX) Runtime tool. In brief, ONNX supports training and inference for a variety of ML frameworks, and is currently integrated into CMSSW (see the CMS ML tutorial). PyTorch hosts an excellent tutorial on <a href=https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html>exporting a model from PyTorch to ONNX</a>. ONNX is available in CMSSW (see a relevant <a href=https://github.com/cms-sw/cmssw/issues/27458>discussion</a> in the CMSSW git repo). </p> <h4 id=example-use-cases>Example Use Cases<a class=headerlink href=#example-use-cases title="Permanent link">&para;</a></h4> <p>The <span class=arithmatex>\(ZZ\rightarrow 4b\)</span> analysis utilizes trained PyTorch models via ONNX in CMSSW (see the corresponding <a href=https://github.com/patrickbryant/ZZ4b/blob/master/README.md>repo</a>). Briefly, they run ONNX in CMSSW_11_X via the CMSSW package <code>PhysicsTools/ONNXRuntime</code>, using it to define a <a href=https://github.com/patrickbryant/ZZ4b/blob/5931a21d8005683e23166c0b44b9594b52ad1126/nTupleAnalysis/interface/multiClassifierONNX.h>multiClassifierONNX</a> class. This multiclassifier is capable of loading pre-trained PyTorch models specified by a <code>modelFile</code> string as follows:</p> <div class=highlight><pre><span></span><code><span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h&quot;</span>

<span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>cms</span><span class=o>::</span><span class=n>Ort</span><span class=o>::</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=w> </span><span class=n>model</span><span class=p>;</span>
<span class=n>Ort</span><span class=o>::</span><span class=n>SessionOptions</span><span class=o>*</span><span class=w> </span><span class=n>session_options</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>new</span><span class=w> </span><span class=n>Ort</span><span class=o>::</span><span class=n>SessionOptions</span><span class=p>();</span>
<span class=n>session_options</span><span class=o>-&gt;</span><span class=n>SetIntraOpNumThreads</span><span class=p>(</span><span class=mi>1</span><span class=p>);</span>
<span class=n>model</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>make_unique</span><span class=o>&lt;</span><span class=n>cms</span><span class=o>::</span><span class=n>Ort</span><span class=o>::</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=p>(</span><span class=n>modelFile</span><span class=p>,</span><span class=w> </span><span class=n>session_options</span><span class=p>);</span>
</code></pre></div> <h3 id=via-triton>Via Triton<a class=headerlink href=#via-triton title="Permanent link">&para;</a></h3> <p>Coprocessors (GPUs, FPGAs, etc.) are frequently used to accelerate ML operations such as inference and training. In the 'as-a-service' paradigm, users can access cloud-based applications through lightweight client inferfaces. The Services for Optimized Network Inference on Coprocessors (<a href=https://github.com/cms-sw/cmssw/tree/master/HeterogeneousCore/SonicCore>SONIC</a>) framework implements this paradigm in CMSSW, allowing the optimal integration of GPUs into event processing workflows. One powerful implementation of SONIC is the the NVIDIA Triton Inference Server, which is flexible with respect to ML framework, storage source, and hardware infrastructure. For more details, see the corresponding <a href=https://developer.nvidia.com/blog/scaling-inference-in-high-energy-particle-physics-at-fermilab-using-nvidia-triton-inference-server/ >NVIDIA developer blog entry</a>. </p> <p>A Graph Attention Network (GAN) is available via Triton in CMSSW, and can be accessed here: <a href=https://github.com/cms-sw/cmssw/tree/master/HeterogeneousCore/SonicTriton/test>https://github.com/cms-sw/cmssw/tree/master/HeterogeneousCore/SonicTriton/test</a></p> <h2 id=training-tips>Training Tips<a class=headerlink href=#training-tips title="Permanent link">&para;</a></h2> <ul> <li>When instantiating a <code>DataLoader</code>, <code>shuffle=True</code> should be enabled for training data but not for validation and testing data. At each training epoch, this will vary the order of data objects in each batch; accordingly, it is not efficient to load the full dataset (in its original ordering) into GPU memory before training. Instead, enable <code>num_workers&gt;1</code>; this allows the <code>DataLoader</code> to load batches to the GPU as they're prepared. Note that this launches muliple threads on the CPU. For more information, see a corresponding <a href=https://discuss.pytorch.org/t/keras-trains-significantly-faster-than-pytorch-for-simple-network/124303/5>discussion</a> in the PyTorch forum. </li> </ul> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 13, 2023</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2020-2023 CMS Machine Learning Group </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/cms-ml target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </a> <a href=https://hub.docker.com/orgs/cmsml/repositories target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1v59.4zm0-204.3h-66.1v60.7h66.1V32zm78.2 144.8H362v59.4h66.1v-59.4zm-156.3-72.1h-66.1v60.1h66.1v-60.1zm78.1 0h-66.1v60.1h66.1v-60.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1l-13.3-8.9zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm-78.1-72.1h-66.1v60.1h66.1v-60.1z"/></svg> </a> <a href=https://cms-talk.web.cern.ch/c/physics/ml/104 target=_blank rel=noopener title=cms-talk.web.cern.ch class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M256 448c141.4 0 256-93.1 256-208S397.4 32 256 32 0 125.1 0 240c0 45.1 17.7 86.8 47.7 120.9-1.9 24.5-11.4 46.3-21.4 62.9-5.5 9.2-11.1 16.6-15.2 21.6-2.1 2.5-3.7 4.4-4.9 5.7-.6.6-1 1.1-1.3 1.4l-.3.3c-4.6 4.6-5.9 11.4-3.4 17.4 2.5 6 8.3 9.9 14.8 9.9 28.7 0 57.6-8.9 81.6-19.3 22.9-10 42.4-21.9 54.3-30.6 31.8 11.5 67 17.9 104.1 17.9zM128 272c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm128 0c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm160-32c0 17.7-14.3 32-32 32s-32-14.3-32-32 14.3-32 32-32 32 14.3 32 32z"/></svg> </a> <a href=mailto:cms-conveners-ml-knowledge@cern.ch target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l217.6 163.2c11.4 8.5 27 8.5 38.4 0l217.6-163.2c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48H48zM0 176v208c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V176L294.4 339.2a63.9 63.9 0 0 1-76.8 0L0 176z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["instant", "navigation.sections"], "search": "../assets/javascripts/workers/search.e5c33ebb.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../assets/javascripts/bundle.ba449ae6.min.js></script> <script src=https://unpkg.com/mermaid@9.3/dist/mermaid.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>