<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Documentation of the CMS Machine Learning Group"><link rel=canonical href=https://cms-ml.github.io/documentation/inference/pytorch.html><meta name=author content="CMS Machine Learning Group"><link rel="shortcut icon" href=../images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.5.3"><title>PyTorch - CMS Machine Learning Documentation</title><link rel=stylesheet href=../assets/stylesheets/main.947af8d5.min.css><link rel=stylesheet href=../assets/stylesheets/palette.7f672a1f.min.css><meta name=theme-color content=#3f51b5><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style></head> <body dir=ltr data-md-color-scheme=preference data-md-color-primary=indigo data-md-color-accent=orange> <script>matchMedia("(prefers-color-scheme: dark)").matches&&document.body.setAttribute("data-md-color-scheme","slate")</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#pytorch-inference class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://cms-ml.github.io/documentation title="CMS Machine Learning Documentation" class="md-header-nav__button md-logo" aria-label="CMS Machine Learning Documentation"> <img src=../images/logo.png alt=logo> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> CMS Machine Learning Documentation </span> <span class="md-header-nav__topic md-ellipsis"> PyTorch </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/cms-ml/documentation/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://cms-ml.github.io/documentation title="CMS Machine Learning Documentation" class="md-nav__button md-logo" aria-label="CMS Machine Learning Documentation"> <img src=../images/logo.png alt=logo> </a> CMS Machine Learning Documentation </label> <div class=md-nav__source> <a href=https://github.com/cms-ml/documentation/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../index.html title=Home class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Innovation <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Innovation data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Innovation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../innovation/journal_club.html title="ML Journal Club" class=md-nav__link> ML Journal Club </a> </li> <li class=md-nav__item> <a href=../innovation/hackathons.html title="ML Hackathons" class=md-nav__link> ML Hackathons </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Resources <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Resources data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Resources/Cloud_Resources/index.html title="Cloud Resources" class=md-nav__link> Cloud Resources </a> </li> <li class=md-nav__item> <a href=../Resources/FPGA_Resources/index.html title="FPGA Resource" class=md-nav__link> FPGA Resource </a> </li> <li class=md-nav__item> <a href=../Resources/GPU_Resources/index.html title="GPU Resources" class=md-nav__link> GPU Resources </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4 checked> <label class=md-nav__link for=nav-4> Tutorials <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Tutorials data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-1 type=checkbox id=nav-4-1> <label class=md-nav__link for=nav-4-1> Optimization <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Optimization data-md-level=2> <label class=md-nav__title for=nav-4-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../optimization/model_optimization.html title="Model optimization" class=md-nav__link> Model optimization </a> </li> <li class=md-nav__item> <a href=../optimization/importance.html title="Feature importance" class=md-nav__link> Feature importance </a> </li> <li class=md-nav__item> <a href=../optimization/data_augmentation.html title="Data augmentation" class=md-nav__link> Data augmentation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-2 type=checkbox id=nav-4-2> <label class=md-nav__link for=nav-4-2> Validation <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Validation data-md-level=2> <label class=md-nav__title for=nav-4-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Validation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../validation/overtraining.html title=Overtraining class=md-nav__link> Overtraining </a> </li> <li class=md-nav__item> <a href=../validation/cross_validation.html title="Cross validation" class=md-nav__link> Cross validation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3 type=checkbox id=nav-4-3 checked> <label class=md-nav__link for=nav-4-3> Inference <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Inference data-md-level=2> <label class=md-nav__title for=nav-4-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Inference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-1 type=checkbox id=nav-4-3-1 checked> <label class=md-nav__link for=nav-4-3-1> Direct inference <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Direct inference" data-md-level=3> <label class=md-nav__title for=nav-4-3-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Direct inference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=tensorflow1.html title="TensorFlow 1" class=md-nav__link> TensorFlow 1 </a> </li> <li class=md-nav__item> <a href=tensorflow2.html title="TensorFlow 2" class=md-nav__link> TensorFlow 2 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> PyTorch <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg> </span> </label> <a href=pytorch.html title=PyTorch class="md-nav__link md-nav__link--active"> PyTorch </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#introductory-references class=md-nav__link> Introductory References </a> </li> <li class=md-nav__item> <a href=#the-basics class=md-nav__link> The Basics </a> <nav class=md-nav aria-label="The Basics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensors class=md-nav__link> Tensors </a> <nav class=md-nav aria-label=Tensors> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-support class=md-nav__link> GPU Support </a> </li> <li class=md-nav__item> <a href=#autograd class=md-nav__link> Autograd </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-utils class=md-nav__link> Data Utils </a> </li> <li class=md-nav__item> <a href=#neural-networks class=md-nav__link> Neural Networks </a> </li> <li class=md-nav__item> <a href=#optimizers class=md-nav__link> Optimizers </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#pytorch-in-cmssw class=md-nav__link> PyTorch in CMSSW </a> <nav class=md-nav aria-label="PyTorch in CMSSW"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#via-onnx class=md-nav__link> Via ONNX </a> <nav class=md-nav aria-label="Via ONNX"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#example-use-cases class=md-nav__link> Example Use Cases </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#via-triton class=md-nav__link> Via Triton </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#training-tips class=md-nav__link> Training Tips </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=pyg.html title="PyTorch Geometric" class=md-nav__link> PyTorch Geometric </a> </li> <li class=md-nav__item> <a href=onnx.html title=ONNX class=md-nav__link> ONNX </a> </li> <li class=md-nav__item> <a href=xgboost.html title=XGBoost class=md-nav__link> XGBoost </a> </li> <li class=md-nav__item> <a href=hls4ml.html title=hls4ml class=md-nav__link> hls4ml </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-2 type=checkbox id=nav-4-3-2> <label class=md-nav__link for=nav-4-3-2> Inference as a service <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Inference as a service" data-md-level=3> <label class=md-nav__title for=nav-4-3-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Inference as a service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=sonic_triton.html title=Sonic/Triton class=md-nav__link> Sonic/Triton </a> </li> <li class=md-nav__item> <a href=tfaas.html title=TFaaS class=md-nav__link> TFaaS </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-3 type=checkbox id=nav-4-3-3> <label class=md-nav__link for=nav-4-3-3> Non-standard workflows <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Non-standard workflows" data-md-level=3> <label class=md-nav__title for=nav-4-3-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Non-standard workflows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=standalone.html title="Standalone framework" class=md-nav__link> Standalone framework </a> </li> <li class=md-nav__item> <a href=swan_aws.html title="SWAN + AWS" class=md-nav__link> SWAN + AWS </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=checklist.html title="Integration checklist" class=md-nav__link> Integration checklist </a> </li> <li class=md-nav__item> <a href=performance.html title=Performance class=md-nav__link> Performance </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-6 type=checkbox id=nav-4-3-6> <label class=md-nav__link for=nav-4-3-6> Successful integrations <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Successful integrations" data-md-level=3> <label class=md-nav__title for=nav-4-3-6> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Successful integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=particlenet.html title=ParticleNet class=md-nav__link> ParticleNet </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4 type=checkbox id=nav-4-4> <label class=md-nav__link for=nav-4-4> Training <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Training data-md-level=2> <label class=md-nav__title for=nav-4-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Training </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4-1 type=checkbox id=nav-4-4-1> <label class=md-nav__link for=nav-4-4-1> Training as a Service <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Training as a Service" data-md-level=3> <label class=md-nav__title for=nav-4-4-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Training as a Service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/MLaaS4HEP.html title=MLaaS4HEP class=md-nav__link> MLaaS4HEP </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#introductory-references class=md-nav__link> Introductory References </a> </li> <li class=md-nav__item> <a href=#the-basics class=md-nav__link> The Basics </a> <nav class=md-nav aria-label="The Basics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensors class=md-nav__link> Tensors </a> <nav class=md-nav aria-label=Tensors> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-support class=md-nav__link> GPU Support </a> </li> <li class=md-nav__item> <a href=#autograd class=md-nav__link> Autograd </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-utils class=md-nav__link> Data Utils </a> </li> <li class=md-nav__item> <a href=#neural-networks class=md-nav__link> Neural Networks </a> </li> <li class=md-nav__item> <a href=#optimizers class=md-nav__link> Optimizers </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#pytorch-in-cmssw class=md-nav__link> PyTorch in CMSSW </a> <nav class=md-nav aria-label="PyTorch in CMSSW"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#via-onnx class=md-nav__link> Via ONNX </a> <nav class=md-nav aria-label="Via ONNX"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#example-use-cases class=md-nav__link> Example Use Cases </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#via-triton class=md-nav__link> Via Triton </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#training-tips class=md-nav__link> Training Tips </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/cms-ml/documentation/blob/master/content/inference/pytorch.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=pytorch-inference>PyTorch Inference<a class=headerlink href=#pytorch-inference title="Permanent link">&para;</a></h1> <p>PyTorch is an open source ML library developed by Facebook's AI Research lab. Initially released in late-2016, PyTorch is a relatively new tool, but has become increasingly popular among ML researchers (in fact, <a href=http://horace.io/pytorch-vs-tensorflow/ >some analyses</a> suggest it's becoming more popular than TensorFlow in academic communities!). PyTorch is written in idiomatic Python, so its syntax is easy to parse for experienced Python programmers. Additionally, it is highly compatible with graphics processing units (GPUs), which can substantially accelerate many deep learning workflows. To date PyTorch has not been integrated into CMSSW. Trained PyTorch models may be evaluated in CMSSW via ONNX Runtime, but model construction and training workflows must currently exist outside of CMSSW. Given the considerable interest in PyTorch within the HEP/ML community, we have reason to believe it will soon be available, so stay tuned! </p> <h2 id=introductory-references>Introductory References<a class=headerlink href=#introductory-references title="Permanent link">&para;</a></h2> <ul> <li><a href=https://pytorch.org/get-started/locally/ >PyTorch Install Guide</a></li> <li><a href=https://pytorch.org/tutorials/ >PyTorch Tutorials</a></li> <li><a href=https://github.com/FNALLPC/machine-learning-hats/blob/master/3.1-dense-pytorch.ipynb>LPC HATs: PyTorch</a></li> <li><a href=https://github.com/Atcold/pytorch-Deep-Learning>Deep Learning w/ PyTorch Course Repo</a></li> <li><a href=https://codas-hep.org/ >CODAS-HEP</a></li> </ul> <h2 id=the-basics>The Basics<a class=headerlink href=#the-basics title="Permanent link">&para;</a></h2> <p>The following documentation surrounds a set of code snippets designed to highlight some important ML features made available in PyTorch. In the following sections, we'll break down snippets from this script, highlighting specifically the PyTorch objects in it. </p> <h3 id=tensors>Tensors<a class=headerlink href=#tensors title="Permanent link">&para;</a></h3> <p>The fundamental PyTorch object is the tensor. At a glance, tensors behave similarly to NumPy arrays. For example, they are broadcasted, concatenated, and sliced in exactly the same way. The following examples highlight some common numpy-like tensor transformations: <div class=highlight><pre><span></span><code><span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>))</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
            <span class=p>[</span> <span class=mf>1.2677</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>],</span>
            <span class=p>[</span><span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
            <span class=p>[</span> <span class=mf>1.2677</span><span class=p>],</span>
            <span class=p>[</span><span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>,</span>  <span class=mf>1.2677</span><span class=p>],</span>
            <span class=p>[</span><span class=o>-</span><span class=mf>0.0204</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[[</span> <span class=mf>1.3552</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
             <span class=p>[</span> <span class=mf>1.2677</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]]])</span>
<span class=n>a</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>1.3552</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0204</span><span class=p>],</span>
            <span class=p>[</span> <span class=mf>1.2677</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8926</span><span class=p>]])</span>
</code></pre></div> Additionally, torch supports familiar matrix operations with various syntax options: <div class=highlight><pre><span></span><code><span class=n>m1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>))</span>
<span class=n>m2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>2</span><span class=p>))</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>

<span class=n>m1</span> <span class=o>@</span> <span class=n>m2</span> <span class=o>==</span> <span class=n>m1</span><span class=o>.</span><span class=n>mm</span><span class=p>(</span><span class=n>m2</span><span class=p>)</span> <span class=c1># matrix multiplication</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>],</span>
            <span class=p>[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>]])</span>

<span class=n>m1</span> <span class=o>@</span> <span class=n>x</span> <span class=o>==</span> <span class=n>m1</span><span class=o>.</span><span class=n>mv</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># matrix-vector multiplication</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>])</span>

<span class=n>m1</span><span class=o>.</span><span class=n>t</span><span class=p>()</span> <span class=o>==</span> <span class=n>m1</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=c1># matrix transpose</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>],</span>
            <span class=p>[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>],</span>
            <span class=p>[</span><span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>]])</span>
</code></pre></div> Note that <code>tensor.transpose(dim0, dim1)</code> is a more general operation than <code>tensor.t()</code>. It is important to note that tensors have been ''upgraded'' from Numpy arrays in two key ways: 1) Tensors have native GPU support. If a GPU is available at runtime, tensors can be transferred from CPU to GPU, where computations such as matrix operations are substantially faster. Note that tensor operations must be performed on objects on the same device. PyTorch supports CUDA tensor types for GPU computation (see the <a href=https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics>PyTorch Cuda Semantics</a> guide). 2) Tensors support automatic gradient (audograd) calculations, such that operations on tensors flagged with <code>requires_grad=True</code> are automatically tracked. The flow of tracked tensor operations defines a <em>computation graph</em> in which nodes are tensors and edges are functions mapping input tensors to output tensors. Gradients are calculated numerically via autograd by walking through this computation graph. </p> <h4 id=gpu-support>GPU Support<a class=headerlink href=#gpu-support title="Permanent link">&para;</a></h4> <p>Tensors are created on the host CPU by default: <div class=highlight><pre><span></span><code><span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
<span class=n>b</span><span class=o>.</span><span class=n>device</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>cpu</span>
</code></pre></div></p> <p>You can also create tensors on any available GPUs: <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=c1># check that a GPU is available</span>
<span class=o>&gt;&gt;&gt;</span> <span class=kc>True</span> 
<span class=n>cuda0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda:0&#39;</span><span class=p>)</span>
<span class=n>c</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>cuda0</span><span class=p>)</span>
<span class=n>c</span><span class=o>.</span><span class=n>device</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span>
</code></pre></div></p> <p>You can also move tensors between devices: <div class=highlight><pre><span></span><code><span class=n>b</span> <span class=o>=</span> <span class=n>b</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>cuda0</span><span class=p>)</span>
<span class=n>b</span><span class=o>.</span><span class=n>device</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span>
</code></pre></div></p> <p>There are trade-offs between computations on the CPU and GPU. GPUs have limited memory and there is a cost associated with transfering data from CPUs to GPUs. However, GPUs perform heavy matrix operations much faster than CPUs, and are therefore often used to speed up training routines. </p> <div class=highlight><pre><span></span><code><span class=n>N</span> <span class=o>=</span> <span class=mi>1000</span> <span class=c1># </span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>500</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=mi>5000</span><span class=p>]):</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;(</span><span class=si>{}</span><span class=s2>,</span><span class=si>{}</span><span class=s2>) Matrices:&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>))</span>
    <span class=n>M1_cpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
    <span class=n>M2_cpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
    <span class=n>M1_gpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=n>cuda0</span><span class=p>)</span>
    <span class=n>M2_gpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span><span class=n>N</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=n>cuda0</span><span class=p>)</span>
    <span class=k>if</span> <span class=p>(</span><span class=n>i</span><span class=o>==</span><span class=mi>0</span><span class=p>):</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Check devices for each tensor:&#39;</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;M1_cpu, M2_cpu devices:&#39;</span><span class=p>,</span> <span class=n>M1_cpu</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>M2_cpu</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;M1_gpu, M2_gpu devices:&#39;</span><span class=p>,</span> <span class=n>M1_gpu</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>M2_gpu</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>large_matrix_multiply</span><span class=p>(</span><span class=n>M1</span><span class=p>,</span> <span class=n>M2</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>M1</span> <span class=o>*</span> <span class=n>M2</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>

    <span class=n>n_iter</span> <span class=o>=</span> <span class=mi>1000</span>
    <span class=n>t_cpu</span> <span class=o>=</span> <span class=n>Timer</span><span class=p>(</span><span class=k>lambda</span><span class=p>:</span> <span class=n>large_matrix_multiply</span><span class=p>(</span><span class=n>M1_cpu</span><span class=p>,</span> <span class=n>M2_cpu</span><span class=p>))</span>
    <span class=n>cpu_time</span> <span class=o>=</span> <span class=n>t_cpu</span><span class=o>.</span><span class=n>timeit</span><span class=p>(</span><span class=n>number</span><span class=o>=</span><span class=n>n_iter</span><span class=p>)</span><span class=o>/</span><span class=n>n_iter</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;cpu time per call: </span><span class=si>{:.6f}</span><span class=s1> s&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cpu_time</span><span class=p>))</span>

    <span class=n>t_gpu</span> <span class=o>=</span> <span class=n>Timer</span><span class=p>(</span><span class=k>lambda</span><span class=p>:</span> <span class=n>large_matrix_multiply</span><span class=p>(</span><span class=n>M1_gpu</span><span class=p>,</span> <span class=n>M2_gpu</span><span class=p>))</span>
    <span class=n>gpu_time</span> <span class=o>=</span> <span class=n>t_gpu</span><span class=o>.</span><span class=n>timeit</span><span class=p>(</span><span class=n>number</span><span class=o>=</span><span class=n>n_iter</span><span class=p>)</span><span class=o>/</span><span class=n>n_iter</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;gpu time per call: </span><span class=si>{:.6f}</span><span class=s1> s&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>gpu_time</span><span class=p>))</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;gpu_time/cpu_time: </span><span class=si>{:.6f}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>))</span>

<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>10</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>Check</span> <span class=n>devices</span> <span class=k>for</span> <span class=n>each</span> <span class=n>tensor</span><span class=p>:</span>
<span class=n>M1_cpu</span><span class=p>,</span> <span class=n>M2_cpu</span> <span class=n>devices</span><span class=p>:</span> <span class=n>cpu</span> <span class=n>cpu</span>
<span class=n>M1_gpu</span><span class=p>,</span> <span class=n>M2_gpu</span> <span class=n>devices</span><span class=p>:</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span> <span class=n>cuda</span><span class=p>:</span><span class=mi>0</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000008</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>1.904711</span>

<span class=p>(</span><span class=mi>100</span><span class=p>,</span><span class=mi>100</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.993163</span>

<span class=p>(</span><span class=mi>500</span><span class=p>,</span><span class=mi>500</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000058</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000016</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.267371</span>

<span class=p>(</span><span class=mi>1000</span><span class=p>,</span><span class=mi>1000</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000170</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000015</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.089784</span>

<span class=p>(</span><span class=mi>5000</span><span class=p>,</span><span class=mi>5000</span><span class=p>)</span> <span class=n>Matrices</span><span class=p>:</span>
<span class=n>cpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.025083</span> <span class=n>s</span>
<span class=n>gpu</span> <span class=n>time</span> <span class=n>per</span> <span class=n>call</span><span class=p>:</span> <span class=mf>0.000011</span> <span class=n>s</span>
<span class=n>gpu_time</span><span class=o>/</span><span class=n>cpu_time</span><span class=p>:</span> <span class=mf>0.000419</span>
</code></pre></div> <p>The complete list of Torch Tensor operations is available in the <a href="https://pytorch.org/docs/stable/torch.html?highlight=mm">docs</a>. </p> <h4 id=autograd>Autograd<a class=headerlink href=#autograd title="Permanent link">&para;</a></h4> <p>Backpropagation occurs automatically through autograd. For example, consider the following function and its derivatives:</p> <div class=arithmatex>\[\begin{aligned} f(\textbf{a}, \textbf{b}) &amp;= \textbf{a}^T \textbf{X} \textbf{b} \\ \frac{\partial f}{\partial \textbf{a}} &amp;= \textbf{b}^T \textbf{X}^T\\ \frac{\partial f}{\partial \textbf{b}} &amp;= \textbf{a}^T \textbf{X} \end{aligned}\]</div> <p>Given specific choices of <span class=arithmatex>\(\textbf{X}\)</span>, <span class=arithmatex>\(\textbf{a}\)</span>, and <span class=arithmatex>\(\textbf{b}\)</span>, we can calculate the corresponding derivatives via autograd by requiring a gradient to be stored in each relevant tensor: <div class=highlight><pre><span></span><code><span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>),</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>0.5</span><span class=p>,</span> <span class=o>-</span><span class=mi>2</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>f</span> <span class=o>=</span> <span class=n>a</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>X</span> <span class=o>@</span> <span class=n>b</span>
<span class=n>f</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>(</span><span class=o>-</span><span class=mf>2.2500</span><span class=p>,</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>DotBackward</span><span class=o>&gt;</span><span class=p>)</span> 
<span class=n>f</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span> <span class=c1># backprop </span>
<span class=n>a</span><span class=o>.</span><span class=n>grad</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>1.5000</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.5000</span><span class=p>])</span>
<span class=n>b</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>X</span><span class=o>.</span><span class=n>T</span> 
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>1.5000</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.5000</span><span class=p>],</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>SqueezeBackward3</span><span class=o>&gt;</span><span class=p>)</span>
<span class=n>b</span><span class=o>.</span><span class=n>grad</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.5000</span><span class=p>,</span> <span class=mf>1.5000</span><span class=p>])</span>
<span class=n>a</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>X</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.5000</span><span class=p>,</span> <span class=mf>1.5000</span><span class=p>],</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>SqueezeBackward3</span><span class=o>&gt;</span><span class=p>)</span>
</code></pre></div> The <code>tensor.backward()</code> call initiates backpropagation, accumulating the gradient backward through a series of <code>grad_fn</code> labels tied to each tensor (e.g. <code>&lt;DotBackward&gt;</code>, indicating the dot product <span class=arithmatex>\((\textbf{a}^T\textbf{X})\textbf{b}\)</span>). </p> <h3 id=data-utils>Data Utils<a class=headerlink href=#data-utils title="Permanent link">&para;</a></h3> <p>PyTorch is equipped with many useful data-handling utilities. For example, the <code>torch.utils.data</code> package implements datasets (<code>torch.utils.data.Dataset</code>) and iterable data loaders (<code>torch.utils.data.DataLoader</code>). Additionally, various batching and sampling schemes are available. </p> <p>You can create custom iterable datasets via <code>torch.utils.data.Dataset</code>, for example a dataset collecting the results of XOR on two binary inputs: <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>Dataset</span>

<span class=k>class</span> <span class=nc>Data</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>samples</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>]])</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>targets</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>logical_xor</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>samples</span><span class=p>[:,</span><span class=mi>0</span><span class=p>],</span> 
                                      <span class=bp>self</span><span class=o>.</span><span class=n>samples</span><span class=p>[:,</span><span class=mi>1</span><span class=p>])</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>targets</span><span class=p>)</span>

    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>idx</span><span class=p>):</span>
        <span class=k>return</span><span class=p>({</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>samples</span><span class=p>[</span><span class=n>idx</span><span class=p>],</span>
                <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>targets</span><span class=p>[</span><span class=n>idx</span><span class=p>]})</span>
</code></pre></div> Dataloaders, from <code>torch.utils.data.DataLoader</code>, can generate shuffled batches of data via multiple workers. Here, we load our datasets onto the GPU: <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span>

<span class=n>device</span> <span class=o>=</span> <span class=s1>&#39;cpu&#39;</span>
<span class=n>train_data</span> <span class=o>=</span> <span class=n>Data</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>test_data</span> <span class=o>=</span> <span class=n>Data</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>train_data</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>test_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>test_data</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>batch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>batch</span><span class=p>)</span>

<span class=o>&gt;&gt;&gt;</span> <span class=mi>0</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>0.</span><span class=p>,</span> <span class=mf>0.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>0.</span><span class=p>])}</span>
    <span class=mi>1</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>1.</span><span class=p>,</span> <span class=mf>0.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.</span><span class=p>])}</span>
    <span class=mi>2</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>1.</span><span class=p>,</span> <span class=mf>1.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>0.</span><span class=p>])}</span>
    <span class=mi>3</span> <span class=p>{</span><span class=s1>&#39;x&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>0.</span><span class=p>,</span> <span class=mf>1.</span><span class=p>]]),</span> <span class=s1>&#39;y&#39;</span><span class=p>:</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>1.</span><span class=p>])}</span>
</code></pre></div> The full set of data utils is available in the <a href="https://pytorch.org/docs/stable/data.html?highlight=dataset">docs</a>. </p> <h3 id=neural-networks>Neural Networks<a class=headerlink href=#neural-networks title="Permanent link">&para;</a></h3> <p>The PyTorch <em>nn</em> package specifies a set of modules that correspond to different neural network (NN) components and operations. For example, the <code>torch.nn.Linear</code> module defines a linear transform with learnable parameters and the <code>torch.nn.Flatten</code> module flattens two contiguous tensor dimensions. The <code>torch.nn.Sequential</code> module contains a set of modules such as <code>torch.nn.Linear</code> and <code>torch.nn.Sequential</code>, chaining them together to form the forward pass of a forward network. Furthermore, one may specify various pre-implemented loss functions, for example <code>torch.nn.BCELoss</code> and <code>torch.nn.KLDivLoss</code>. The full set of PyTorch NN building blocks is available in the <a href=https://pytorch.org/docs/stable/nn.html>docs</a>. </p> <p>As an example, we can design a simple neural network designed to reproduce the output of the XOR operation on binary inputs. To do so, we can compute a simple NN of the form:</p> <div class=arithmatex>\[\begin{aligned} x_{in}&amp;\in\{0,1\}^{2}\\ l_1 &amp;= \sigma(W_1^Tx_{in} + b_1); \ W_1\in\mathbb{R}^{2\times2},\ b_1\in\mathbb{R}^{2}\\ l_2 &amp;= \sigma(W_2^Tx + b_2); \ W_2\in\mathbb{R}^{2},\ b_1\in\mathbb{R}\\ \end{aligned}\]</div> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>

<span class=k>class</span> <span class=nc>Network</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>l1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>l2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>l1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>l2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=k>return</span> <span class=n>x</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>Network</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>model</span><span class=p>(</span><span class=n>train_data</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>

<span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span><span class=p>([[</span><span class=mf>0.5000</span><span class=p>],</span>
            <span class=p>[</span><span class=mf>0.4814</span><span class=p>],</span>
            <span class=p>[</span><span class=mf>0.5148</span><span class=p>],</span>
            <span class=p>[</span><span class=mf>0.4957</span><span class=p>]],</span> <span class=n>grad_fn</span><span class=o>=&lt;</span><span class=n>SigmoidBackward</span><span class=o>&gt;</span><span class=p>)</span>
</code></pre></div> <h3 id=optimizers>Optimizers<a class=headerlink href=#optimizers title="Permanent link">&para;</a></h3> <p>Training a neural network involves minimizing a loss function; classes in the <code>torch.optim</code> package implement various optimization strategies for example stochastic gradient descent and Adam through <code>torch.optim.SGD</code> and <code>torch.optim.Adam</code> respectively. Optimizers are configurable through parameters such as the learning rate (configuring the optimizer's step size). The full set of optimizers and accompanying tutorials are available in the <a href=https://pytorch.org/docs/stable/optim.html>docs</a>.</p> <p>To demonstrate the use of an optimizer, let's train the NN above to produce the results of the XOR operation on binary inputs. Here we'll use the <a href=https://arxiv.org/abs/1412.6980>Adam optimizer</a>:</p> <p><div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>torch</span> <span class=kn>import</span> <span class=n>optim</span>
<span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>StepLR</span>
<span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>

<span class=c1># helpful references:</span>
<span class=c1># Learning XOR: exploring the space of a classic problem</span>
<span class=c1># https://towardsdatascience.com/how-neural-networks-solve-the-xor-problem-59763136bdd7</span>
<span class=c1># https://courses.cs.washington.edu/courses/cse446/18wi/sections/section8/XOR-Pytorch.html</span>

<span class=c1># the training function initiates backprop and </span>
<span class=c1># steps the optimizer towards the weights that </span>
<span class=c1># optimize the loss function </span>
<span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>epoch</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=n>losses</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>batch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>
        <span class=n>y</span><span class=p>,</span> <span class=n>output</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;y&#39;</span><span class=p>],</span> <span class=n>output</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>

        <span class=c1># optimize binary cross entropy:</span>
        <span class=c1># https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>binary_cross_entropy</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>reduction</span><span class=o>=</span><span class=s1>&#39;mean&#39;</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
        <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>())</span>

    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>losses</span><span class=p>)</span>

<span class=c1># the test function does not adjust the model&#39;s weights</span>
<span class=k>def</span> <span class=nf>test</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=n>losses</span><span class=p>,</span> <span class=n>n_correct</span><span class=p>,</span> <span class=n>n_incorrect</span> <span class=o>=</span> <span class=p>[],</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span>
    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>batch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>test_loader</span><span class=p>):</span>
            <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>
            <span class=n>y</span><span class=p>,</span> <span class=n>output</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;y&#39;</span><span class=p>],</span> <span class=n>output</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>binary_cross_entropy</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> 
                                          <span class=n>reduction</span><span class=o>=</span><span class=s1>&#39;mean&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
            <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>

            <span class=c1># determine accuracy by thresholding model output at 0.5</span>
            <span class=n>batch_correct</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(((</span><span class=n>output</span><span class=o>&gt;</span><span class=mf>0.5</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>y</span><span class=o>==</span><span class=mi>1</span><span class=p>))</span> <span class=o>|</span>
                                      <span class=p>((</span><span class=n>output</span><span class=o>&lt;</span><span class=mf>0.5</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>y</span><span class=o>==</span><span class=mi>0</span><span class=p>)))</span>
            <span class=n>batch_incorrect</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>y</span><span class=p>)</span> <span class=o>-</span> <span class=n>batch_correct</span>
            <span class=n>n_correct</span> <span class=o>+=</span> <span class=n>batch_correct</span>
            <span class=n>n_incorrect</span> <span class=o>+=</span> <span class=n>batch_incorrect</span>

    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>losses</span><span class=p>),</span> <span class=n>n_correct</span><span class=o>/</span><span class=p>(</span><span class=n>n_correct</span><span class=o>+</span><span class=n>n_incorrect</span><span class=p>)</span>


<span class=c1># randomly initialize the model&#39;s weights</span>
<span class=k>for</span> <span class=n>module</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
        <span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

<span class=c1># send weights to optimizer </span>
<span class=n>lr</span> <span class=o>=</span> <span class=mf>2.5e-2</span>
<span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>)</span>

<span class=n>epochs</span> <span class=o>=</span> <span class=mi>500</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>epochs</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
    <span class=n>train_loss</span> <span class=o>=</span> <span class=n>train</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>epoch</span><span class=p>)</span>
    <span class=n>test_loss</span><span class=p>,</span> <span class=n>test_acc</span> <span class=o>=</span> <span class=n>test</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>epoch</span><span class=o>%</span><span class=mi>25</span><span class=o>==</span><span class=mi>0</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;epoch=</span><span class=si>{}</span><span class=s1>: train_loss=</span><span class=si>{:.3f}</span><span class=s1>, test_loss=</span><span class=si>{:.3f}</span><span class=s1>, test_acc=</span><span class=si>{:.3f}</span><span class=s1>&#39;</span>
              <span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>epoch</span><span class=p>,</span> <span class=n>train_loss</span><span class=p>,</span> <span class=n>test_loss</span><span class=p>,</span> <span class=n>test_acc</span><span class=p>))</span>

<span class=o>&gt;&gt;&gt;</span> <span class=n>epoch</span><span class=o>=</span><span class=mi>25</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.683</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.681</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.500</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>50</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.665</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.664</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>75</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.640</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.635</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>100</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.598</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.595</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>125</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.554</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.550</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>150</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.502</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.498</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>175</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.435</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.432</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>200</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.360</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.358</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>0.750</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>225</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.290</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.287</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>250</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.230</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.228</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>275</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.184</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.183</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>300</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.149</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.148</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>325</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.122</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.122</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>350</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.102</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.101</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>375</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.086</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.086</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>400</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.074</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.073</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>425</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.064</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.063</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>450</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.056</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.055</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>475</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.049</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.049</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
    <span class=n>epoch</span><span class=o>=</span><span class=mi>500</span><span class=p>:</span> <span class=n>train_loss</span><span class=o>=</span><span class=mf>0.043</span><span class=p>,</span> <span class=n>test_loss</span><span class=o>=</span><span class=mf>0.043</span><span class=p>,</span> <span class=n>test_acc</span><span class=o>=</span><span class=mf>1.000</span>
</code></pre></div> Here, the model has converged to 100% test accuracy, indicating that it has learned to reproduce the XOR outputs perfectly. Note that even though the test accuracy is 100%, the test loss (BCE) decreases steadily; this is because the BCE loss is nonzero when <span class=arithmatex>\(y_{output}\)</span> is not exactly 0 or 1, while accuracy is determined by thresholding the model outputs such that each prediction is the boolean <span class=arithmatex>\((y_{output} &gt; 0.5)\)</span>. This highlights that it is important to choose the correct performance metric for an ML problem. In the case of XOR, perfect test accuracy is sufficient. Let's check that we've recovered the XOR output by extracting the model's weights and using them to build a custom XOR function:</p> <div class=highlight><pre><span></span><code><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
    <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>param</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>

<span class=o>&gt;&gt;&gt;</span> <span class=n>l1</span><span class=o>.</span><span class=n>weight</span> <span class=n>tensor</span><span class=p>([[</span> <span class=mf>7.2888</span><span class=p>,</span> <span class=o>-</span><span class=mf>6.4168</span><span class=p>],</span>
                      <span class=p>[</span> <span class=mf>7.2824</span><span class=p>,</span> <span class=o>-</span><span class=mf>8.1637</span><span class=p>]])</span>
    <span class=n>l1</span><span class=o>.</span><span class=n>bias</span> <span class=n>tensor</span><span class=p>([</span> <span class=mf>2.6895</span><span class=p>,</span> <span class=o>-</span><span class=mf>3.9633</span><span class=p>])</span>
    <span class=n>l2</span><span class=o>.</span><span class=n>weight</span> <span class=n>tensor</span><span class=p>([[</span><span class=o>-</span><span class=mf>6.3500</span><span class=p>,</span>  <span class=mf>8.0990</span><span class=p>]])</span>
    <span class=n>l2</span><span class=o>.</span><span class=n>bias</span> <span class=n>tensor</span><span class=p>([</span><span class=mf>2.5058</span><span class=p>])</span>
</code></pre></div> <p>Because our model was built with <code>nn.Linear</code> modules, we have weight matrices and bias terms. Next, we'll hard-code the matrix operations into a custom XOR function based on the architecture of the NN: </p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>XOR</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=n>w1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span> <span class=mf>7.2888</span><span class=p>,</span> <span class=o>-</span><span class=mf>6.4168</span><span class=p>],</span>
                       <span class=p>[</span> <span class=mf>7.2824</span><span class=p>,</span> <span class=o>-</span><span class=mf>8.1637</span><span class=p>]])</span><span class=o>.</span><span class=n>t</span><span class=p>()</span>
    <span class=n>b1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span> <span class=mf>2.6895</span><span class=p>,</span> <span class=o>-</span><span class=mf>3.9633</span><span class=p>])</span>
    <span class=n>layer1_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>b1</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
                               <span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=n>w1</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>b1</span><span class=p>[</span><span class=mi>1</span><span class=p>]])</span>
    <span class=n>layer1_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>layer1_out</span><span class=p>)</span>

    <span class=n>w2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>6.3500</span><span class=p>,</span>  <span class=mf>8.0990</span><span class=p>])</span>
    <span class=n>b2</span> <span class=o>=</span> <span class=mf>2.5058</span>
    <span class=n>layer2_out</span> <span class=o>=</span> <span class=n>layer1_out</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=n>w2</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>layer1_out</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=n>w2</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>b2</span>
    <span class=n>layer2_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>layer2_out</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>layer2_out</span><span class=p>,</span> <span class=p>(</span><span class=n>layer2_out</span> <span class=o>&gt;</span> <span class=mf>0.5</span><span class=p>)</span>

<span class=n>XOR</span><span class=p>([</span><span class=mf>0.</span><span class=p>,</span><span class=mf>0.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.0359</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>False</span><span class=p>))</span>
<span class=n>XOR</span><span class=p>([</span><span class=mf>0.</span><span class=p>,</span><span class=mf>1.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.9135</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>True</span><span class=p>))</span>
<span class=n>XOR</span><span class=p>([</span><span class=mf>1.</span><span class=p>,</span><span class=mf>0.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.9815</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>True</span><span class=p>))</span>
<span class=n>XOR</span><span class=p>([</span><span class=mf>1.</span><span class=p>,</span><span class=mf>1.</span><span class=p>])</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>tensor</span><span class=p>(</span><span class=mf>0.0265</span><span class=p>),</span> <span class=n>tensor</span><span class=p>(</span><span class=kc>False</span><span class=p>))</span>
</code></pre></div> <p>There we have it - the NN learned XOR! </p> <h2 id=pytorch-in-cmssw>PyTorch in CMSSW<a class=headerlink href=#pytorch-in-cmssw title="Permanent link">&para;</a></h2> <h3 id=via-onnx>Via ONNX<a class=headerlink href=#via-onnx title="Permanent link">&para;</a></h3> <p>One way to incorporate your PyTorch models into CMSSW is through the <a href=https://www.onnxruntime.ai/about.html>Open Neural Network Exchange</a> (ONNX) Runtime tool. In brief, ONNX supports training and inference for a variety of ML frameworks, and is currently integrated into CMSSW (see the CMS ML tutorial). PyTorch hosts an excellent tutorial on <a href=https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html>exporting a model from PyTorch to ONNX</a>. ONNX is available in CMSSW (see a relevant <a href=https://github.com/cms-sw/cmssw/issues/27458>discussion</a> in the CMSSW git repo). </p> <h4 id=example-use-cases>Example Use Cases<a class=headerlink href=#example-use-cases title="Permanent link">&para;</a></h4> <p>The <span class=arithmatex>\(ZZ\rightarrow 4b\)</span> analysis utilizes trained PyTorch models via ONNX in CMSSW (see the corresponding <a href=https://github.com/patrickbryant/ZZ4b/blob/master/README.md>repo</a>). Briefly, they run ONNX in CMSSW_11_X via the CMSSW package <code>PhysicsTools/ONNXRuntime</code>, using it to define a <a href=https://github.com/patrickbryant/ZZ4b/blob/5931a21d8005683e23166c0b44b9594b52ad1126/nTupleAnalysis/interface/multiClassifierONNX.h>multiClassifierONNX</a> class. This multiclassifier is capable of loading pre-trained PyTorch models specified by a <code>modelFile</code> string as follows:</p> <div class=highlight><pre><span></span><code><span class=cp>#include</span> <span class=cpf>&quot;PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h&quot;</span><span class=cp></span>

<span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>cms</span><span class=o>::</span><span class=n>Ort</span><span class=o>::</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span> <span class=n>model</span><span class=p>;</span>
<span class=n>Ort</span><span class=o>::</span><span class=n>SessionOptions</span><span class=o>*</span> <span class=n>session_options</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Ort</span><span class=o>::</span><span class=n>SessionOptions</span><span class=p>();</span>
<span class=n>session_options</span><span class=o>-&gt;</span><span class=n>SetIntraOpNumThreads</span><span class=p>(</span><span class=mi>1</span><span class=p>);</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>std</span><span class=o>::</span><span class=n>make_unique</span><span class=o>&lt;</span><span class=n>cms</span><span class=o>::</span><span class=n>Ort</span><span class=o>::</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=p>(</span><span class=n>modelFile</span><span class=p>,</span> <span class=n>session_options</span><span class=p>);</span>
</code></pre></div> <h3 id=via-triton>Via Triton<a class=headerlink href=#via-triton title="Permanent link">&para;</a></h3> <p>Coprocessors (GPUs, FPGAs, etc.) are frequently used to accelerate ML operations such as inference and training. In the 'as-a-service' paradigm, users can access cloud-based applications through lightweight client inferfaces. The Services for Optimized Network Inference on Coprocessors (<a href=https://github.com/cms-sw/cmssw/tree/master/HeterogeneousCore/SonicCore>SONIC</a>) framework implements this paradigm in CMSSW, allowing the optimal integration of GPUs into event processing workflows. One powerful implementation of SONIC is the the NVIDIA Triton Inference Server, which is flexible with respect to ML framework, storage source, and hardware infrastructure. For more details, see the corresponding <a href=https://developer.nvidia.com/blog/scaling-inference-in-high-energy-particle-physics-at-fermilab-using-nvidia-triton-inference-server/ >NVIDIA developer blog entry</a>. </p> <p>A Graph Attention Network (GAN) is available via Triton in CMSSW, and can be accessed here: <a href=https://github.com/cms-sw/cmssw/tree/master/HeterogeneousCore/SonicTriton/test>https://github.com/cms-sw/cmssw/tree/master/HeterogeneousCore/SonicTriton/test</a></p> <h2 id=training-tips>Training Tips<a class=headerlink href=#training-tips title="Permanent link">&para;</a></h2> <ul> <li>When instantiating a <code>DataLoader</code>, <code>shuffle=True</code> should be enabled for training data but not for validation and testing data. At each training epoch, this will vary the order of data objects in each batch; accordingly, it is not efficient to load the full dataset (in its original ordering) into GPU memory before training. Instead, enable <code>num_workers&gt;1</code>; this allows the <code>DataLoader</code> to load batches to the GPU as they're prepared. Note that this launches muliple threads on the CPU. For more information, see a corresponding <a href=https://discuss.pytorch.org/t/keras-trains-significantly-faster-than-pytorch-for-simple-network/124303/5>discussion</a> in the PyTorch forum. </li> </ul> <hr> <div class=md-source-date> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">July 18, 2022</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=tensorflow2.html title="TensorFlow 2" class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> TensorFlow 2 </div> </div> </a> <a href=pyg.html title="PyTorch Geometric" class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> PyTorch Geometric </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 CMS Machine Learning Group </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/cms-ml target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </a> <a href=https://hub.docker.com/orgs/cmsml/repositories target=_blank rel=noopener title=hub.docker.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M349.9 236.3h-66.1v-59.4h66.1v59.4zm0-204.3h-66.1v60.7h66.1V32zm78.2 144.8H362v59.4h66.1v-59.4zm-156.3-72.1h-66.1v60.1h66.1v-60.1zm78.1 0h-66.1v60.1h66.1v-60.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1l-13.3-8.9zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm-78.1-72.1h-66.1v60.1h66.1v-60.1z"/></svg> </a> <a href=https://hypernews.cern.ch/HyperNews/CMS/get/machine-learning.html target=_blank rel=noopener title=hypernews.cern.ch class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M256 32C114.6 32 0 125.1 0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3 0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4 0 256-93.1 256-208S397.4 32 256 32zM128 272c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm128 0c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm128 0c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32z"/></svg> </a> <a href=mailto:hn-cms-machine-learning@cern.ch target=_blank rel=noopener title class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../assets/javascripts/vendor.c3dc8c49.min.js></script> <script src=../assets/javascripts/bundle.f9edbbd5.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script> <script>
        app = initialize({
          base: "..",
          features: ["instant"],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.8e2cddea.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src=https://unpkg.com/mermaid@8.6/dist/mermaid.min.js></script> <script src=../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>