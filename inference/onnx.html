<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Documentation of the CMS Machine Learning Group"><meta name=author content="CMS Machine Learning Group"><link rel=canonical href=https://cms-ml.github.io/documentation/inference/onnx.html><link rel=prev href=pyg.html><link rel=next href=xgboost.html><link rel=icon href=../images/favicon.png><meta name=generator content="mkdocs-1.4.2, mkdocs-material-9.0.3"><title>ONNX - CMS Machine Learning Documentation</title><link rel=stylesheet href=../assets/stylesheets/main.6b71719e.min.css><link rel=stylesheet href=../assets/stylesheets/palette.2505c338.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=orange> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#direct-inference-with-onnx-runtime class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../index.html title="CMS Machine Learning Documentation" class="md-header__button md-logo" aria-label="CMS Machine Learning Documentation" data-md-component=logo> <img src=../images/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> CMS Machine Learning Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> ONNX </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=orange aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=orange aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/cms-ml/documentation title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../index.html title="CMS Machine Learning Documentation" class="md-nav__button md-logo" aria-label="CMS Machine Learning Documentation" data-md-component=logo> <img src=../images/logo.png alt=logo> </a> CMS Machine Learning Documentation </label> <div class=md-nav__source> <a href=https://github.com/cms-ml/documentation title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../index.html class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2 type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 tabindex=0 aria-expanded=false> Innovation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Innovation data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Innovation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../innovation/journal_club.html class=md-nav__link> ML Journal Club </a> </li> <li class=md-nav__item> <a href=../innovation/hackathons.html class=md-nav__link> ML Hackathons </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 tabindex=0 aria-expanded=false> Resources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Resources data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../resources/cloud_resources/index.html class=md-nav__link> Cloud Resources </a> </li> <li class=md-nav__item> <a href=../resources/dataset_resources/index.html class=md-nav__link> Dataset Resources </a> </li> <li class=md-nav__item> <a href=../resources/fpga_resources/index.html class=md-nav__link> FPGA Resource </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_3_4 type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4 tabindex=0 aria-expanded=false> GPU Resources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="GPU Resources" data-md-level=2> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> GPU Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/lxplus_gpu.html class=md-nav__link> lxplus-gpu </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/lxplus_htcondor.html class=md-nav__link> CERN HTCondor </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/swan.html class=md-nav__link> SWAN </a> </li> <li class=md-nav__item> <a href=../resources/gpu_resources/cms_resources/ml_cern_ch.html class=md-nav__link> ml.cern.ch </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4 type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 tabindex=0 aria-expanded=true> Guides <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Guides data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_1 type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 tabindex=0 aria-expanded=false> Software environments <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Software environments" data-md-level=2> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Software environments </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../software_envs/lcg_environments.html class=md-nav__link> LCG environments </a> </li> <li class=md-nav__item> <a href=../software_envs/containers.html class=md-nav__link> Using containers </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_2 type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 tabindex=0 aria-expanded=false> Optimization <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Optimization data-md-level=2> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../optimization/model_optimization.html class=md-nav__link> Model optimization </a> </li> <li class=md-nav__item> <a href=../optimization/importance.html class=md-nav__link> Feature importance </a> </li> <li class=md-nav__item> <a href=../optimization/data_augmentation.html class=md-nav__link> Data augmentation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_3 type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 tabindex=0 aria-expanded=false> General Advice <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="General Advice" data-md-level=2> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> General Advice </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/intro.html class=md-nav__link> Introduction </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_3_2 type=checkbox id=__nav_4_3_2> <label class=md-nav__link for=__nav_4_3_2 tabindex=0 aria-expanded=false> Before training <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Before training" data-md-level=3> <label class=md-nav__title for=__nav_4_3_2> <span class="md-nav__icon md-icon"></span> Before training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/before/domains.html class=md-nav__link> Domains </a> </li> <li class=md-nav__item> <a href=../general_advice/before/features.html class=md-nav__link> Features </a> </li> <li class=md-nav__item> <a href=../general_advice/before/inputs.html class=md-nav__link> Inputs </a> </li> <li class=md-nav__item> <a href=../general_advice/before/model.html class=md-nav__link> Model </a> </li> <li class=md-nav__item> <a href=../general_advice/before/metrics.html class=md-nav__link> Metrics & Losses </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_3_3 type=checkbox id=__nav_4_3_3> <label class=md-nav__link for=__nav_4_3_3 tabindex=0 aria-expanded=false> During training <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="During training" data-md-level=3> <label class=md-nav__title for=__nav_4_3_3> <span class="md-nav__icon md-icon"></span> During training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../general_advice/during/overfitting.html class=md-nav__link> Overfitting </a> </li> <li class=md-nav__item> <a href=../general_advice/during/xvalidation.html class=md-nav__link> Cross-validation </a> </li> <li class=md-nav__item> <a href=../general_advice/during/opt.html class=md-nav__link> Optimisation problems </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../general_advice/after/after.html class=md-nav__link> After training </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4 type=checkbox id=__nav_4_4 checked> <label class=md-nav__link for=__nav_4_4 tabindex=0 aria-expanded=true> Inference <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Inference data-md-level=2> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> Inference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_1 type=checkbox id=__nav_4_4_1 checked> <label class=md-nav__link for=__nav_4_4_1 tabindex=0 aria-expanded=true> Direct inference <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Direct inference" data-md-level=3> <label class=md-nav__title for=__nav_4_4_1> <span class="md-nav__icon md-icon"></span> Direct inference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=tensorflow2.html class=md-nav__link> TensorFlow 2 </a> </li> <li class=md-nav__item> <a href=pytorch.html class=md-nav__link> PyTorch </a> </li> <li class=md-nav__item> <a href=pyg.html class=md-nav__link> PyTorch Geometric </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> ONNX <span class="md-nav__icon md-icon"></span> </label> <a href=onnx.html class="md-nav__link md-nav__link--active"> ONNX </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#software-setup class=md-nav__link> Software Setup </a> </li> <li class=md-nav__item> <a href=#converting-model-to-onnx class=md-nav__link> Converting model to ONNX </a> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-c class=md-nav__link> Inference in CMSSW (C++) </a> <nav class=md-nav aria-label="Inference in CMSSW (C++)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-includes class=md-nav__link> 1. includes </a> </li> <li class=md-nav__item> <a href=#2-global-cache-object class=md-nav__link> 2. Global cache object </a> </li> <li class=md-nav__item> <a href=#3-initiate-objects class=md-nav__link> 3. Initiate objects </a> </li> <li class=md-nav__item> <a href=#4-inference class=md-nav__link> 4. Inference </a> </li> <li class=md-nav__item> <a href=#full-example class=md-nav__link> Full example </a> </li> <li class=md-nav__item> <a href=#test-our-module class=md-nav__link> Test our module </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-python class=md-nav__link> Inference in CMSSW (Python) </a> </li> <li class=md-nav__item> <a href=#links-and-further-reading class=md-nav__link> Links and further reading </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=xgboost.html class=md-nav__link> XGBoost </a> </li> <li class=md-nav__item> <a href=hls4ml.html class=md-nav__link> hls4ml </a> </li> <li class=md-nav__item> <a href=conifer.html class=md-nav__link> conifer </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_2 type=checkbox id=__nav_4_4_2> <label class=md-nav__link for=__nav_4_4_2 tabindex=0 aria-expanded=false> Inference as a service <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Inference as a service" data-md-level=3> <label class=md-nav__title for=__nav_4_4_2> <span class="md-nav__icon md-icon"></span> Inference as a service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=sonic_triton.html class=md-nav__link> Sonic/Triton </a> </li> <li class=md-nav__item> <a href=tfaas.html class=md-nav__link> TFaaS </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_3 type=checkbox id=__nav_4_4_3> <label class=md-nav__link for=__nav_4_4_3 tabindex=0 aria-expanded=false> Non-standard workflows <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Non-standard workflows" data-md-level=3> <label class=md-nav__title for=__nav_4_4_3> <span class="md-nav__icon md-icon"></span> Non-standard workflows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=standalone.html class=md-nav__link> Standalone framework </a> </li> <li class=md-nav__item> <a href=swan_aws.html class=md-nav__link> SWAN + AWS </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=checklist.html class=md-nav__link> Integration checklist </a> </li> <li class=md-nav__item> <a href=performance.html class=md-nav__link> Performance </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_4_6 type=checkbox id=__nav_4_4_6> <label class=md-nav__link for=__nav_4_4_6 tabindex=0 aria-expanded=false> Successful integrations <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Successful integrations" data-md-level=3> <label class=md-nav__title for=__nav_4_4_6> <span class="md-nav__icon md-icon"></span> Successful integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=particlenet.html class=md-nav__link> ParticleNet </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_5 type=checkbox id=__nav_4_5> <label class=md-nav__link for=__nav_4_5 tabindex=0 aria-expanded=false> Training <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Training data-md-level=2> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Training </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/Decorrelation.html class=md-nav__link> Decorrelation </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_5_2 type=checkbox id=__nav_4_5_2> <label class=md-nav__link for=__nav_4_5_2 tabindex=0 aria-expanded=false> Training as a Service <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Training as a Service" data-md-level=3> <label class=md-nav__title for=__nav_4_5_2> <span class="md-nav__icon md-icon"></span> Training as a Service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/MLaaS4HEP.html class=md-nav__link> MLaaS4HEP </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../training/autoencoders.html class=md-nav__link> Autoencoders </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#software-setup class=md-nav__link> Software Setup </a> </li> <li class=md-nav__item> <a href=#converting-model-to-onnx class=md-nav__link> Converting model to ONNX </a> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-c class=md-nav__link> Inference in CMSSW (C++) </a> <nav class=md-nav aria-label="Inference in CMSSW (C++)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-includes class=md-nav__link> 1. includes </a> </li> <li class=md-nav__item> <a href=#2-global-cache-object class=md-nav__link> 2. Global cache object </a> </li> <li class=md-nav__item> <a href=#3-initiate-objects class=md-nav__link> 3. Initiate objects </a> </li> <li class=md-nav__item> <a href=#4-inference class=md-nav__link> 4. Inference </a> </li> <li class=md-nav__item> <a href=#full-example class=md-nav__link> Full example </a> </li> <li class=md-nav__item> <a href=#test-our-module class=md-nav__link> Test our module </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-python class=md-nav__link> Inference in CMSSW (Python) </a> </li> <li class=md-nav__item> <a href=#links-and-further-reading class=md-nav__link> Links and further reading </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=direct-inference-with-onnx-runtime>Direct inference with ONNX Runtime<a class=headerlink href=#direct-inference-with-onnx-runtime title="Permanent link">&para;</a></h1> <p><a href=https://onnx.ai>ONNX</a> is an open format built to represent machine learning models. It is designed to improve <mark>interoperability</mark> across a variety of frameworks and platforms in the AI tools community—most deep learning frameworks (e.g. XGBoost, TensorFlow, PyTorch which are frequently used in CMS) support converting their model into the ONNX format or loading a model from an ONNX format.</p> <figure> <img src=../images/inference/onnx/onnx-interoperability.jpeg width=70%> <figcaption>The figure showing the ONNX interoperability. (Source from <a href=https://towardsdatascience.com/onnx-preventing-framework-lock-in-9a798fb34c92>website</a>.)</figcaption> </figure> <p><a href=https://onnxruntime.ai/ >ONNX Runtime</a> is a tool aiming for the <mark>acceleration of machine learning inferencing</mark> across a variety of deployment platforms. It allows to "run any ONNX model using a single set of inference APIs that provide access to the best hardware acceleration available". It includes "built-in optimization features that trim and consolidate nodes without impacting model accuracy."</p> <p>The CMSSW interface to ONNX Runtime is avaiable since CMSSW_11_1_X (<a href=https://github.com/cms-sw/cmssw/pull/28112>cmssw#28112</a>, <a href=https://github.com/cms-sw/cmsdist/pull/5020>cmsdist#5020</a>). Its functionality is improved in CMSSW_11_2_X. The final implementation is also backported to CMSSW_10_6_X to facilitate Run 2 UL data reprocessing. The inference of a number of deep learning tagger models (e.g. DeepJet, DeepTauID, ParticleNet, DeepDoubleX, etc.) has been made with ONNX Runtime in the routine of UL processing and has gained substantial speedup.</p> <p>On this page, we will <mark>use a simple example to show how to use ONNX Runtime for deep learning model inference in the CMSSW framework</mark>, both in C++ (e.g. to process the MiniAOD file) and in Python (e.g. using NanoAOD-tools to process the NanoAODs). This may help readers who will deploy an ONNX model into their analyses or in the CMSSW framework.</p> <h2 id=software-setup>Software Setup<a class=headerlink href=#software-setup title="Permanent link">&para;</a></h2> <p>We use CMSSW_11_2_5_patch2 to show the simple example for ONNX Runtime inference. The example can also work under the new 12 releases (note that inference with C++ can also run on CMSSW_10_6_X)</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span></pre></div></td><td class=code><div><pre><span></span><code><span class=nb>export</span><span class=w> </span><span class=nv>SCRAM_ARCH</span><span class=o>=</span><span class=s2>&quot;slc7_amd64_gcc900&quot;</span>
<span class=nb>export</span><span class=w> </span><span class=nv>CMSSW_VERSION</span><span class=o>=</span><span class=s2>&quot;CMSSW_11_2_5_patch2&quot;</span>

<span class=nb>source</span><span class=w> </span>/cvmfs/cms.cern.ch/cmsset_default.sh

cmsrel<span class=w> </span><span class=s2>&quot;</span><span class=nv>$CMSSW_VERSION</span><span class=s2>&quot;</span>
<span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=nv>$CMSSW_VERSION</span><span class=s2>/src&quot;</span>

cmsenv
scram<span class=w> </span>b
</code></pre></div></td></tr></table></div> <h2 id=converting-model-to-onnx>Converting model to ONNX<a class=headerlink href=#converting-model-to-onnx title="Permanent link">&para;</a></h2> <p>The model deployed into CMSSW or our analysis needs to be converted to ONNX from the original framework format where it is trained. Please see <a href=https://github.com/onnx/tutorials#converting-to-onnx-format>here</a> for a nice deck of tutorials on converting models from different mainstream frameworks into ONNX.</p> <p>Here we take PyTorch as an example. A PyTorch model can be converted by <code>torch.onnx.export(...)</code>. As a simple illustration, we convert a randomly initialized feed-forward network implemented in PyTorch, with 10 input nodes and 2 output nodes, and two hidden layers with 64 nodes each. The conversion code is presented below. The output model <code>model.onnx</code> will be deployed under the CMSSW framework in our following tutorial.</p> <details class=hint> <summary>Click to expand</summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span></pre></div></td><td class=code><div><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=k>class</span> <span class=nc>SimpleMLP</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>SimpleMLP</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> 
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> 
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> 
            <span class=p>)</span>
    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># input x: (batch_size, feature_dim=10)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleMLP</span><span class=p>()</span>

<span class=c1># create dummy input for the model</span>
<span class=n>dummy_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=c1># batch size = 1</span>

<span class=c1># export model to ONNX</span>
<span class=n>torch</span><span class=o>.</span><span class=n>onnx</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>dummy_input</span><span class=p>,</span> <span class=s2>&quot;model.onnx&quot;</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>input_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;my_input&#39;</span><span class=p>],</span> <span class=n>output_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;my_output&#39;</span><span class=p>])</span>
</code></pre></div></td></tr></table></div> </details> <h2 id=inference-in-cmssw-c>Inference in CMSSW (C++)<a class=headerlink href=#inference-in-cmssw-c title="Permanent link">&para;</a></h2> <p>We will introduce how to write a module to run inference on the ONNX model under the CMSSW framework. CMSSW is known for its multi-threaded ability. In a threaded framework, multiple threads are served for processing events in the event loop. The logic is straightforward: a new event is assigned to idled threads following the first-come-first-serve princlple.</p> <p>In most cases, each thread is able to process events individually as the majority of event processing workflow can be accomplished only by seeing the information of that event. Thus, the <code>stream</code> modules (<code>stream</code> <code>EDAnalyzer</code> and <code>stream</code> <code>EDFilter</code>) are used frequently as each thread holds an individual copy of the module instance—they do not need to communicate with each other. It is however also possible to share a global cache object between all threads in case sharing information across threads is necessary. In all, such CMSSW EDAnalyzer modules are declared by <code class=highlight><span class=k>class</span><span class=w> </span><span class=nc>MyPlugin</span><span class=w> </span><span class=o>:</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>stream</span><span class=o>::</span><span class=n>EDAnalyzer</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span><span class=o>&lt;</span><span class=n>CacheData</span><span class=o>&gt;&gt;</span></code> (similar for <code>EDFilter</code>). Details can be found in documentation on the <a href=https://twiki.cern.ch/twiki/bin/view/CMSPublic/FWMultithreadedFrameworkStreamModuleInterface>C++ interface of <code>stream</code> modules</a>.</p> <p>Let's then think about what would happen when interfacing CMSSW with ONNX for model inference. When ONNX Runtime accepts a model, it converts the model into an in-memory representation, and performance a variety of optimizations depending on the operators in the model. The procedure is done when an ONNX Runtime <code>Session</code> is created with an inputting model. The economic method will then be to hold only one <code>Session</code> for all threads—this may save memory to a large extent, as the model has only one copy in memory. Upon request from multiple threads to do inference with their input data, the <code>Session</code> accepts those requests and serializes them, then produces the output data. ONNX Runtime has by design accepted that multithread threads invoke the <code>Run()</code> method on the same inference <code>Session</code> object. Therefore, what has left us to do is to</p> <ol> <li>create a <code>Session</code> as a global object in our CMSSW module and share it among all threads;</li> <li>in each thread, we process the input data and then call the <code>Run()</code> method from that global <code>Session</code>.</li> </ol> <p>That's the main logic for implementing ONNX inference in CMSSW. For details of high-level designs of ONNX Runtime, please see <a href=https://onnxruntime.ai/docs/reference/high-level-design.html>documentation here</a>.</p> <p>With this concept, let's build the module.</p> <h5 id=1-includes>1. includes<a class=headerlink href=#1-includes title="Permanent link">&para;</a></h5> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span></pre></div></td><td class=code><div><pre><span></span><code><span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;FWCore/Framework/interface/stream/EDAnalyzer.h&quot;</span>
<span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h&quot;</span>
<span class=c1>// further framework includes</span>
<span class=p>...</span>
</code></pre></div></td></tr></table></div> <p>We include <code>stream/EDAnalyzer.h</code> to build the <code>stream</code> CMSSW module.</p> <h5 id=2-global-cache-object>2. Global cache object<a class=headerlink href=#2-global-cache-object title="Permanent link">&para;</a></h5> <p>In CMSSW there exists a class <a href=https://github.com/cms-sw/cmssw/blob/master/PhysicsTools/ONNXRuntime/src/ONNXRuntime.cc><code>ONNXRuntime</code></a> which can be used directly as the global cache object. Upon initialization from a given model, it holds the ONNX Runtime <code>Session</code> object and provides the handle to invoke the <code>Run()</code> for model inference.</p> <p>We put the <code>ONNXRuntime</code> class in the <code class=highlight><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span></code> template argument:</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span></pre></div></td><td class=code><div><pre><span></span><code><span class=hll><span class=k>class</span><span class=w> </span><span class=nc>MyPlugin</span><span class=w> </span><span class=o>:</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>stream</span><span class=o>::</span><span class=n>EDAnalyzer</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;&gt;</span><span class=w> </span><span class=p>{</span>
</span><span class=w>  </span><span class=p>...</span>
<span class=p>};</span>
</code></pre></div></td></tr></table></div> <h5 id=3-initiate-objects>3. Initiate objects<a class=headerlink href=#3-initiate-objects title="Permanent link">&para;</a></h5> <p>In the <code>stream</code> <code>EDAnlyzer</code> module, it provides a hook <code>initializeGlobalCache()</code> to initiate the global object. We simply do</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span></pre></div></td><td class=code><div><pre><span></span><code><span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=w> </span><span class=n>MyPlugin</span><span class=o>::</span><span class=n>initializeGlobalCache</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span><span class=w> </span><span class=o>&amp;</span><span class=n>iConfig</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=k>return</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>make_unique</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=p>(</span><span class=n>iConfig</span><span class=p>.</span><span class=n>getParameter</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&quot;model_path&quot;</span><span class=p>).</span><span class=n>fullPath</span><span class=p>());</span>
<span class=p>}</span>
</code></pre></div></td></tr></table></div> <p>to initiate the <code>ONNXRuntime</code> object upon a given model path.</p> <h5 id=4-inference>4. Inference<a class=headerlink href=#4-inference title="Permanent link">&para;</a></h5> <p>We know the event processing step is implemented in the <code>void EDAnalyzer::analyze</code> method. When an event is assigned to a valid thread, the content will be processed in that thread. This can go in parallel with other threads processing other events.</p> <p>We need to first construct the input data dedicated to the event. Here we create a dummy input: a sequence of consecutive integers of length 10. The input is set by replacing the values of our pre-booked vector, <code>data_</code>. This member variable has <code class=highlight><span class=n>vector</span><span class=o>&lt;</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;&gt;</span></code> format and is initialised as <code class=highlight><span class=p>{</span><span class=w> </span><span class=p>{</span><span class=mi>0</span><span class=p>,</span><span class=w> </span><span class=mi>0</span><span class=p>,</span><span class=w> </span><span class=p>...,</span><span class=w> </span><span class=mi>0</span><span class=p>}</span><span class=w> </span><span class=p>}</span></code> (contains only one element, which is a vector of 10 zeros). In processing of each event, the input <code>data_</code> is modified:</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span></pre></div></td><td class=code><div><pre><span></span><code><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=w> </span><span class=o>&amp;</span><span class=n>group_data</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>data_</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
<span class=k>for</span><span class=w> </span><span class=p>(</span><span class=kt>size_t</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>0</span><span class=p>;</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=mi>10</span><span class=p>;</span><span class=w> </span><span class=n>i</span><span class=o>++</span><span class=p>){</span>
<span class=w>  </span><span class=n>group_data</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=kt>float</span><span class=p>(</span><span class=n>iEvent</span><span class=p>.</span><span class=n>id</span><span class=p>().</span><span class=n>event</span><span class=p>()</span><span class=w> </span><span class=o>%</span><span class=w> </span><span class=mi>100</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>i</span><span class=p>);</span>
<span class=p>}</span>
</code></pre></div></td></tr></table></div> <p>Then, we send <code>data_</code> to the inference engine and get the model output:</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=w> </span><span class=n>outputs</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>globalCache</span><span class=p>()</span><span class=o>-&gt;</span><span class=n>run</span><span class=p>(</span><span class=n>input_names_</span><span class=p>,</span><span class=w> </span><span class=n>data_</span><span class=p>,</span><span class=w> </span><span class=n>input_shapes_</span><span class=p>)[</span><span class=mi>0</span><span class=p>];</span>
</code></pre></div></td></tr></table></div> <p>We clarify a few details here.</p> <p>First, we use <code class=highlight><span class=n>globalCache</span><span class=p>()</span></code> which is a class method in our <code>stream</code> CMSSW module to access the global object shared across all threads. In our case it is the <code>ONNXRuntime</code> instance.</p> <p>The <code>run()</code> method is a wrapper to call <code>Run()</code> on the ONNX <code>Session</code>. Definations on the method arguments are (code from <a href=https://github.com/cms-sw/cmssw/blob/CMSSW_11_2_5_patch2/PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h#L32-L44>link</a>): <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span></pre></div></td><td class=code><div><pre><span></span><code><span class=c1>// Run inference and get outputs</span>
<span class=c1>// input_names: list of the names of the input nodes.</span>
<span class=c1>// input_values: list of input arrays for each input node. The order of `input_values` must match `input_names`.</span>
<span class=c1>// input_shapes: list of `int64_t` arrays specifying the shape of each input node. Can leave empty if the model does not have dynamic axes.</span>
<span class=c1>// output_names: names of the output nodes to get outputs from. Empty list means all output nodes.</span>
<span class=c1>// batch_size: number of samples in the batch. Each array in `input_values` must have a shape layout of (batch_size, ...).</span>
<span class=c1>// Returns: a std::vector&lt;std::vector&lt;float&gt;&gt;, with the order matched to `output_names`.</span>
<span class=c1>// When `output_names` is empty, will return all outputs ordered as in `getOutputNames()`.</span>
<span class=n>FloatArrays</span><span class=w> </span><span class=nf>run</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&amp;</span><span class=w> </span><span class=n>input_names</span><span class=p>,</span>
<span class=w>                </span><span class=n>FloatArrays</span><span class=o>&amp;</span><span class=w> </span><span class=n>input_values</span><span class=p>,</span>
<span class=w>                </span><span class=k>const</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int64_t</span><span class=o>&gt;&gt;&amp;</span><span class=w> </span><span class=n>input_shapes</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>{},</span>
<span class=w>                </span><span class=k>const</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&amp;</span><span class=w> </span><span class=n>output_names</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>{},</span>
<span class=w>                </span><span class=kt>int64_t</span><span class=w> </span><span class=n>batch_size</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>1</span><span class=p>)</span><span class=w> </span><span class=k>const</span><span class=p>;</span>
</code></pre></div></td></tr></table></div> where we have <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>typedef</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;&gt;</span><span class=w> </span><span class=n>FloatArrays</span><span class=p>;</span>
</code></pre></div></td></tr></table></div></p> <p>In our case, <code class=highlight><span class=n>input_names</span></code> is set to <code class=highlight><span class=p>{</span><span class=s>&quot;my_input&quot;</span><span class=p>}</span></code> which corresponds to the names upon model creation. <code class=highlight><span class=n>input_values</span></code> is a length-1 vector, and <code class=highlight><span class=n>input_values</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span></code> is a vector of float of length 10, which are inputs to the 10 nodes. <code class=highlight><span class=n>input_shapes</span></code> can be set empty here and will be necessary for advanced usage, when our input has dynamic lengths (e.g., in boosed jet tagging, we use different numbers of particle-flow candidates and secondary vertices as input).</p> <p>For the usual model design, we have only one vector of output. In such a case, the output is simply a length-1 vector, and we use <code class=highlight><span class=p>[</span><span class=mi>0</span><span class=p>]</span></code> to get the vector of two float numbers—the output of the model.</p> <h5 id=full-example>Full example<a class=headerlink href=#full-example title="Permanent link">&para;</a></h5> <p>Let's construct the full example.</p> <details class=hint> <summary>Click to expand</summary> <p>The example assumes the following directory structure:</p> <div class=highlight><pre><span></span><code>MySubsystem/MyModule/
│
├── plugins/
│   ├── MyPlugin.cpp
│   └── BuildFile.xml
│
├── test/
│   └── my_plugin_cfg.py
│
└── data/
    └── model.onnx
</code></pre></div> <div class="tabbed-set tabbed-alternate" data-tabs=1:4><input checked=checked id=__tabbed_1_1 name=__tabbed_1 type=radio><input id=__tabbed_1_2 name=__tabbed_1 type=radio><input id=__tabbed_1_3 name=__tabbed_1 type=radio><input id=__tabbed_1_4 name=__tabbed_1 type=radio><div class=tabbed-labels><label for=__tabbed_1_1>plugins/MyPlugin.cpp</label><label for=__tabbed_1_2>plugins/BuildFile.xml</label><label for=__tabbed_1_3>test/my_plugin_cfg.py</label><label for=__tabbed_1_4>data/model.onnx</label></div> <div class=tabbed-content> <div class=tabbed-block> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span>
<span class=normal>44</span>
<span class=normal>45</span>
<span class=normal>46</span>
<span class=normal>47</span>
<span class=normal>48</span>
<span class=normal>49</span>
<span class=normal>50</span>
<span class=normal>51</span>
<span class=normal>52</span>
<span class=normal>53</span>
<span class=normal>54</span>
<span class=normal>55</span>
<span class=normal>56</span>
<span class=normal>57</span>
<span class=normal>58</span>
<span class=normal>59</span>
<span class=normal>60</span>
<span class=normal>61</span>
<span class=normal>62</span>
<span class=normal>63</span>
<span class=normal>64</span>
<span class=normal>65</span>
<span class=normal>66</span>
<span class=normal>67</span>
<span class=normal>68</span>
<span class=normal>69</span>
<span class=normal>70</span>
<span class=normal>71</span>
<span class=normal>72</span>
<span class=normal>73</span>
<span class=normal>74</span>
<span class=normal>75</span>
<span class=normal>76</span>
<span class=normal>77</span>
<span class=normal>78</span>
<span class=normal>79</span>
<span class=normal>80</span></pre></div></td><td class=code><div><pre><span></span><code><span class=cm>/*</span>
<span class=hll><span class=cm> * Example plugin to demonstrate the direct multi-threaded inference with ONNX Runtime.</span>
</span><span class=cm> */</span>

<span class=cp>#include</span><span class=w> </span><span class=cpf>&lt;memory&gt;</span>
<span class=cp>#include</span><span class=w> </span><span class=cpf>&lt;iostream&gt;</span>

<span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;FWCore/Framework/interface/Event.h&quot;</span>
<span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;FWCore/Framework/interface/Frameworkfwd.h&quot;</span>
<span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;FWCore/Framework/interface/MakerMacros.h&quot;</span>
<span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;FWCore/Framework/interface/stream/EDAnalyzer.h&quot;</span>
<span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;FWCore/ParameterSet/interface/ParameterSet.h&quot;</span>

<span class=cp>#include</span><span class=w> </span><span class=cpf>&quot;PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h&quot;</span>

<span class=k>using</span><span class=w> </span><span class=k>namespace</span><span class=w> </span><span class=nn>cms</span><span class=o>::</span><span class=nn>Ort</span><span class=p>;</span>

<span class=k>class</span><span class=w> </span><span class=nc>MyPlugin</span><span class=w> </span><span class=o>:</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>stream</span><span class=o>::</span><span class=n>EDAnalyzer</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;&gt;</span><span class=w> </span><span class=p>{</span>
<span class=k>public</span><span class=o>:</span>
<span class=w>  </span><span class=k>explicit</span><span class=w> </span><span class=n>MyPlugin</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span><span class=w> </span><span class=o>&amp;</span><span class=p>,</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=n>ONNXRuntime</span><span class=w> </span><span class=o>*</span><span class=p>);</span>
<span class=w>  </span><span class=k>static</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=nf>fillDescriptions</span><span class=p>(</span><span class=n>edm</span><span class=o>::</span><span class=n>ConfigurationDescriptions</span><span class=o>&amp;</span><span class=p>);</span>

<span class=w>  </span><span class=k>static</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=w> </span><span class=n>initializeGlobalCache</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span><span class=w> </span><span class=o>&amp;</span><span class=p>);</span>
<span class=w>  </span><span class=k>static</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=nf>globalEndJob</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>ONNXRuntime</span><span class=w> </span><span class=o>*</span><span class=p>);</span>

<span class=k>private</span><span class=o>:</span>
<span class=w>  </span><span class=kt>void</span><span class=w> </span><span class=n>beginJob</span><span class=p>();</span>
<span class=w>  </span><span class=kt>void</span><span class=w> </span><span class=nf>analyze</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>Event</span><span class=o>&amp;</span><span class=p>,</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>EventSetup</span><span class=o>&amp;</span><span class=p>);</span>
<span class=w>  </span><span class=kt>void</span><span class=w> </span><span class=nf>endJob</span><span class=p>();</span>

<span class=w>  </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;</span><span class=w> </span><span class=n>input_names_</span><span class=p>;</span>
<span class=w>  </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int64_t</span><span class=o>&gt;&gt;</span><span class=w> </span><span class=n>input_shapes_</span><span class=p>;</span>
<span class=w>  </span><span class=n>FloatArrays</span><span class=w> </span><span class=n>data_</span><span class=p>;</span><span class=w> </span><span class=c1>// each stream hosts its own data</span>
<span class=p>};</span>


<span class=kt>void</span><span class=w> </span><span class=nf>MyPlugin::fillDescriptions</span><span class=p>(</span><span class=n>edm</span><span class=o>::</span><span class=n>ConfigurationDescriptions</span><span class=o>&amp;</span><span class=w> </span><span class=n>descriptions</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=c1>// defining this function will lead to a *_cfi file being generated when compiling</span>
<span class=w>  </span><span class=n>edm</span><span class=o>::</span><span class=n>ParameterSetDescription</span><span class=w> </span><span class=n>desc</span><span class=p>;</span>
<span class=w>  </span><span class=n>desc</span><span class=p>.</span><span class=n>add</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&quot;model_path&quot;</span><span class=p>,</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=p>(</span><span class=s>&quot;MySubsystem/MyModule/data/model.onnx&quot;</span><span class=p>));</span>
<span class=w>  </span><span class=n>desc</span><span class=p>.</span><span class=n>add</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&gt;</span><span class=p>(</span><span class=s>&quot;input_names&quot;</span><span class=p>,</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;</span><span class=p>({</span><span class=s>&quot;my_input&quot;</span><span class=p>}));</span>
<span class=w>  </span><span class=n>descriptions</span><span class=p>.</span><span class=n>addWithDefaultLabel</span><span class=p>(</span><span class=n>desc</span><span class=p>);</span>
<span class=p>}</span>


<span class=n>MyPlugin</span><span class=o>::</span><span class=n>MyPlugin</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span><span class=w> </span><span class=o>&amp;</span><span class=n>iConfig</span><span class=p>,</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=n>ONNXRuntime</span><span class=w> </span><span class=o>*</span><span class=n>cache</span><span class=p>)</span>
<span class=w>    </span><span class=o>:</span><span class=w> </span><span class=n>input_names_</span><span class=p>(</span><span class=n>iConfig</span><span class=p>.</span><span class=n>getParameter</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&gt;</span><span class=p>(</span><span class=s>&quot;input_names&quot;</span><span class=p>)),</span>
<span class=w>      </span><span class=n>input_shapes_</span><span class=p>()</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=c1>// initialize the input data arrays</span>
<span class=w>    </span><span class=c1>// note there is only one element in the FloatArrays type (i.e. vector&lt;vector&lt;float&gt;&gt;) variable</span>
<span class=w>    </span><span class=n>data_</span><span class=p>.</span><span class=n>emplace_back</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=w> </span><span class=mi>0</span><span class=p>);</span>
<span class=p>}</span>


<span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=w> </span><span class=n>MyPlugin</span><span class=o>::</span><span class=n>initializeGlobalCache</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span><span class=w> </span><span class=o>&amp;</span><span class=n>iConfig</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=k>return</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>make_unique</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=p>(</span><span class=n>iConfig</span><span class=p>.</span><span class=n>getParameter</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&quot;model_path&quot;</span><span class=p>).</span><span class=n>fullPath</span><span class=p>());</span>
<span class=p>}</span>

<span class=kt>void</span><span class=w> </span><span class=n>MyPlugin</span><span class=o>::</span><span class=n>globalEndJob</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>ONNXRuntime</span><span class=w> </span><span class=o>*</span><span class=n>cache</span><span class=p>)</span><span class=w> </span><span class=p>{}</span>

<span class=kt>void</span><span class=w> </span><span class=n>MyPlugin</span><span class=o>::</span><span class=n>analyze</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>Event</span><span class=w> </span><span class=o>&amp;</span><span class=n>iEvent</span><span class=p>,</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=n>edm</span><span class=o>::</span><span class=n>EventSetup</span><span class=w> </span><span class=o>&amp;</span><span class=n>iSetup</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=c1>// prepare dummy inputs for every event</span>
<span class=w>  </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=w> </span><span class=o>&amp;</span><span class=n>group_data</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>data_</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
<span class=w>  </span><span class=k>for</span><span class=w> </span><span class=p>(</span><span class=kt>size_t</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>0</span><span class=p>;</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=mi>10</span><span class=p>;</span><span class=w> </span><span class=n>i</span><span class=o>++</span><span class=p>){</span>
<span class=w>      </span><span class=n>group_data</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=kt>float</span><span class=p>(</span><span class=n>iEvent</span><span class=p>.</span><span class=n>id</span><span class=p>().</span><span class=n>event</span><span class=p>()</span><span class=w> </span><span class=o>%</span><span class=w> </span><span class=mi>100</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>i</span><span class=p>);</span>
<span class=w>  </span><span class=p>}</span>

<span class=w>  </span><span class=c1>// run prediction and get outputs</span>
<span class=w>  </span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=w> </span><span class=n>outputs</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>globalCache</span><span class=p>()</span><span class=o>-&gt;</span><span class=n>run</span><span class=p>(</span><span class=n>input_names_</span><span class=p>,</span><span class=w> </span><span class=n>data_</span><span class=p>,</span><span class=w> </span><span class=n>input_shapes_</span><span class=p>)[</span><span class=mi>0</span><span class=p>];</span>

<span class=w>  </span><span class=c1>// print the input and output data</span>
<span class=w>  </span><span class=n>std</span><span class=o>::</span><span class=n>cout</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=s>&quot;input data -&gt; &quot;</span><span class=p>;</span>
<span class=w>  </span><span class=k>for</span><span class=w> </span><span class=p>(</span><span class=k>auto</span><span class=w> </span><span class=o>&amp;</span><span class=n>i</span><span class=o>:</span><span class=w> </span><span class=n>group_data</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>cout</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=s>&quot; &quot;</span><span class=p>;</span><span class=w> </span><span class=p>}</span>
<span class=w>  </span><span class=n>std</span><span class=o>::</span><span class=n>cout</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=s>&quot;output data -&gt; &quot;</span><span class=p>;</span>
<span class=w>  </span><span class=k>for</span><span class=w> </span><span class=p>(</span><span class=k>auto</span><span class=w> </span><span class=o>&amp;</span><span class=n>i</span><span class=o>:</span><span class=w> </span><span class=n>outputs</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>cout</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=s>&quot; &quot;</span><span class=p>;</span><span class=w> </span><span class=p>}</span>
<span class=w>  </span><span class=n>std</span><span class=o>::</span><span class=n>cout</span><span class=w> </span><span class=o>&lt;&lt;</span><span class=w> </span><span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>

<span class=p>}</span>

<span class=n>DEFINE_FWK_MODULE</span><span class=p>(</span><span class=n>MyPlugin</span><span class=p>);</span>
</code></pre></div></td></tr></table></div> </div> <div class=tabbed-block> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span></pre></div></td><td class=code><div><pre><span></span><code><span class=nt>&lt;use</span><span class=w> </span><span class=na>name=</span><span class=s>&quot;FWCore/Framework&quot;</span><span class=w> </span><span class=nt>/&gt;</span>
<span class=nt>&lt;use</span><span class=w> </span><span class=na>name=</span><span class=s>&quot;FWCore/PluginManager&quot;</span><span class=w> </span><span class=nt>/&gt;</span>
<span class=nt>&lt;use</span><span class=w> </span><span class=na>name=</span><span class=s>&quot;FWCore/ParameterSet&quot;</span><span class=w> </span><span class=nt>/&gt;</span>
<span class=nt>&lt;use</span><span class=w> </span><span class=na>name=</span><span class=s>&quot;PhysicsTools/ONNXRuntime&quot;</span><span class=w> </span><span class=nt>/&gt;</span>

<span class=nt>&lt;flags</span><span class=w> </span><span class=na>EDM_PLUGIN=</span><span class=s>&quot;1&quot;</span><span class=w> </span><span class=nt>/&gt;</span>
</code></pre></div></td></tr></table></div> </div> <div class=tabbed-block> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span>
<span class=normal>44</span>
<span class=normal>45</span></pre></div></td><td class=code><div><pre><span></span><code><span class=c1># coding: utf-8</span>

<span class=kn>import</span> <span class=nn>os</span>

<span class=kn>import</span> <span class=nn>FWCore.ParameterSet.Config</span> <span class=k>as</span> <span class=nn>cms</span>
<span class=kn>from</span> <span class=nn>FWCore.ParameterSet.VarParsing</span> <span class=kn>import</span> <span class=n>VarParsing</span>


<span class=c1># setup minimal options</span>
<span class=n>options</span> <span class=o>=</span> <span class=n>VarParsing</span><span class=p>(</span><span class=s2>&quot;python&quot;</span><span class=p>)</span>
<span class=n>options</span><span class=o>.</span><span class=n>setDefault</span><span class=p>(</span><span class=s2>&quot;inputFiles&quot;</span><span class=p>,</span> <span class=s2>&quot;/store/mc/RunIISummer20UL18MiniAODv2/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/MINIAODSIM/106X_upgrade2018_realistic_v16_L1v1-v2/230000/4C8619B2-D0C0-4647-B946-B33754F4ED16.root&quot;</span><span class=p>)</span>  <span class=c1># noqa</span>
<span class=n>options</span><span class=o>.</span><span class=n>parseArguments</span><span class=p>()</span>

<span class=c1># define the process to run</span>
<span class=n>process</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>Process</span><span class=p>(</span><span class=s2>&quot;TEST&quot;</span><span class=p>)</span>

<span class=c1># minimal configuration</span>
<span class=n>process</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;FWCore.MessageService.MessageLogger_cfi&quot;</span><span class=p>)</span>
<span class=n>process</span><span class=o>.</span><span class=n>MessageLogger</span><span class=o>.</span><span class=n>cerr</span><span class=o>.</span><span class=n>FwkReport</span><span class=o>.</span><span class=n>reportEvery</span> <span class=o>=</span> <span class=mi>1</span>
<span class=n>process</span><span class=o>.</span><span class=n>maxEvents</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>PSet</span><span class=p>(</span><span class=nb>input</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>int32</span><span class=p>(</span><span class=mi>10</span><span class=p>))</span>
<span class=n>process</span><span class=o>.</span><span class=n>source</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>Source</span><span class=p>(</span><span class=s2>&quot;PoolSource&quot;</span><span class=p>,</span>
    <span class=n>fileNames</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>vstring</span><span class=p>(</span><span class=n>options</span><span class=o>.</span><span class=n>inputFiles</span><span class=p>))</span>

<span class=c1># process options</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>PSet</span><span class=p>(</span>
    <span class=n>allowUnscheduled</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>bool</span><span class=p>(</span><span class=kc>True</span><span class=p>),</span>
    <span class=n>wantSummary</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>bool</span><span class=p>(</span><span class=kc>True</span><span class=p>),</span>
<span class=p>)</span>

<span class=c1># setup options for multithreaded</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfThreads</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfStreams</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfConcurrentLuminosityBlocks</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>


<span class=c1># setup MyPlugin by loading the auto-generated cfi (see MyPlugin.fillDescriptions)</span>
<span class=n>process</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;MySubsystem.MyModule.myPlugin_cfi&quot;</span><span class=p>)</span>
<span class=c1># specify the path of the ONNX model</span>
<span class=n>process</span><span class=o>.</span><span class=n>myPlugin</span><span class=o>.</span><span class=n>model_path</span> <span class=o>=</span> <span class=s2>&quot;MySubsystem/MyModule/data/model.onnx&quot;</span>
<span class=c1># input names as defined in the model</span>
<span class=c1># the order of name strings should also corresponds to the order of input data array feed to the model</span>
<span class=n>process</span><span class=o>.</span><span class=n>myPlugin</span><span class=o>.</span><span class=n>input_names</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;my_input&quot;</span><span class=p>]</span>

<span class=c1># define what to run in the path</span>
<span class=n>process</span><span class=o>.</span><span class=n>p</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>Path</span><span class=p>(</span><span class=n>process</span><span class=o>.</span><span class=n>myPlugin</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </div> <div class=tabbed-block> <p>The model is produced by code in the section <a href=#converting-model-to-onnx>"Converting model to ONNX"</a> and can be downloaded <a href=https://github.com/cms-ml/documentation/raw/master/content/inference/code/onnx/model.onnx>here</a>.</p> </div> </div> </div> </details> <h5 id=test-our-module>Test our module<a class=headerlink href=#test-our-module title="Permanent link">&para;</a></h5> <p>Under <code>MySubsystem/MyModule/test</code>, run <code class=highlight>cmsRun<span class=w> </span>my_plugin_cfg.py</code> to launch our module. You may see the following from the output, which include the input and output vectors in the inference process.</p> <details class=hint> <summary>Click to see the output</summary> <div class=highlight><pre><span></span><code>...
19-Jul-2022 10:50:41 CEST  Successfully opened file root://xrootd-cms.infn.it//store/mc/RunIISummer20UL18MiniAODv2/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/MINIAODSIM/106X_upgrade2018_realistic_v16_L1v1-v2/230000/4C8619B2-D0C0-4647-B946-B33754F4ED16.root
Begin processing the 1st record. Run 1, Event 27074045, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.494 CEST
input data -&gt; 45 46 47 48 49 50 51 52 53 54
output data -&gt; 0.995657 0.00434343
Begin processing the 2nd record. Run 1, Event 27074048, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.495 CEST
input data -&gt; 48 49 50 51 52 53 54 55 56 57
output data -&gt; 0.996884 0.00311563
Begin processing the 3rd record. Run 1, Event 27074059, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.495 CEST
input data -&gt; 59 60 61 62 63 64 65 66 67 68
output data -&gt; 0.999081 0.000919373
Begin processing the 4th record. Run 1, Event 27074061, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.495 CEST
input data -&gt; 61 62 63 64 65 66 67 68 69 70
output data -&gt; 0.999264 0.000736247
Begin processing the 5th record. Run 1, Event 27074046, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 46 47 48 49 50 51 52 53 54 55
output data -&gt; 0.996112 0.00388828
Begin processing the 6th record. Run 1, Event 27074047, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 47 48 49 50 51 52 53 54 55 56
output data -&gt; 0.996519 0.00348065
Begin processing the 7th record. Run 1, Event 27074064, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 64 65 66 67 68 69 70 71 72 73
output data -&gt; 0.999472 0.000527586
Begin processing the 8th record. Run 1, Event 27074074, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 74 75 76 77 78 79 80 81 82 83
output data -&gt; 0.999826 0.000173664
Begin processing the 9th record. Run 1, Event 27074050, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 50 51 52 53 54 55 56 57 58 59
output data -&gt; 0.997504 0.00249614
Begin processing the 10th record. Run 1, Event 27074060, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 60 61 62 63 64 65 66 67 68 69
output data -&gt; 0.999177 0.000822734
19-Jul-2022 10:50:43 CEST  Closed file root://xrootd-cms.infn.it//store/mc/RunIISummer20UL18MiniAODv2/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/MINIAODSIM/106X_upgrade2018_realistic_v16_L1v1-v2/230000/4C8619B2-D0C0-4647-B946-B33754F4ED16.root
</code></pre></div> </details> <p>Also we could try launching the script with more threads. Change the corresponding line in <code>my_plugin_cfg.py</code> as follows to activate the multi-threaded mode with 4 threads.</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>31</span></pre></div></td><td class=code><div><pre><span></span><code><span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfThreads</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>4</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> <p>Launch the script again, and one could see the same results, but with the inference processed concurrently on 4 threads.</p> <h2 id=inference-in-cmssw-python>Inference in CMSSW (Python)<a class=headerlink href=#inference-in-cmssw-python title="Permanent link">&para;</a></h2> <p>Doing ONNX Runtime inference with python is possible as well. For those releases that have the ONNX Runtime C++ package installed, the <code>onnxruntime</code> python package is also installed in <mark><code>python3</code></mark> (except for CMSSW_10_6_X). We still use CMSSW_11_2_5_patch2 to run our examples. We could quickly check if <code>onnxruntime</code> is available by:</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code><span class=n>python3</span> <span class=o>-</span><span class=n>c</span> <span class=s2>&quot;import onnxruntime; print(&#39;onnxruntime available&#39;)&quot;</span>
</code></pre></div></td></tr></table></div> <p>The python code is simple to construct: following the quick examples <a href=https://onnxruntime.ai/docs/get-started/with-python.html>"Get started with ORT for Python"</a>, we create the file <code>MySubsystem/MyModule/test/my_standalone_test.py</code> as follows:</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span></pre></div></td><td class=code><div><pre><span></span><code><span class=kn>import</span> <span class=nn>onnxruntime</span> <span class=k>as</span> <span class=nn>ort</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>

<span class=c1># create input data in the float format (32 bit)</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>45</span><span class=p>,</span> <span class=mi>55</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>

<span class=c1># create inference session using ort.InferenceSession from a given model</span>
<span class=n>ort_sess</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span><span class=s1>&#39;../data/model.onnx&#39;</span><span class=p>)</span>

<span class=c1># run inference</span>
<span class=n>outputs</span> <span class=o>=</span> <span class=n>ort_sess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=p>{</span><span class=s1>&#39;my_input&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>data</span><span class=p>])})[</span><span class=mi>0</span><span class=p>]</span>

<span class=c1># print input and output</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;input -&gt;&#39;</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;output -&gt;&#39;</span><span class=p>,</span> <span class=n>outputs</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> <p>Under the directory <code>MySubsystem/MyModule/test</code>, run the example with <code>python3 my_standalone_test.py</code>. Then we see the output:</p> <div class=highlight><pre><span></span><code>input -&gt; [45. 46. 47. 48. 49. 50. 51. 52. 53. 54.]
output -&gt; [[0.9956566  0.00434343]]
</code></pre></div> <p>Using ONNX Runtime on NanoAOD-tools follows the same logic. Here we create the ONNX <code>Session</code> in the beginning stage and run inference in the event loop. Note that NanoAOD-tools runs the event loop in the single-thread mode.</p> <p>Please find details in the following block.</p> <details class=hint> <summary>Click to see the NanoAOD-tools example</summary> <p>We run the NanoAOD-tools example following the above CMSSW_11_2_5_patch2 environment. According to the setup instruction in <a href=https://github.com/cms-nanoAOD/nanoAOD-tools>NanoAOD-tools</a>, do</p> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=nv>$CMSSW_BASE</span>/src
git<span class=w> </span>clone<span class=w> </span>https://github.com/cms-nanoAOD/nanoAOD-tools.git<span class=w> </span>PhysicsTools/NanoAODTools
<span class=nb>cd</span><span class=w> </span>PhysicsTools/NanoAODTools
cmsenv
scram<span class=w> </span>b
</code></pre></div> <p>Now we add our custom module to run ONNX Runtime inference. Create a file <code>PhysicsTools/NanoAODTools/python/postprocessing/examples/exampleOrtModule.py</code> with the content:</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span>
<span class=normal>44</span>
<span class=normal>45</span></pre></div></td><td class=code><div><pre><span></span><code><span class=kn>from</span> <span class=nn>PhysicsTools.NanoAODTools.postprocessing.framework.datamodel</span> <span class=kn>import</span> <span class=n>Collection</span>
<span class=kn>from</span> <span class=nn>PhysicsTools.NanoAODTools.postprocessing.framework.eventloop</span> <span class=kn>import</span> <span class=n>Module</span>
<span class=kn>import</span> <span class=nn>ROOT</span>
<span class=n>ROOT</span><span class=o>.</span><span class=n>PyConfig</span><span class=o>.</span><span class=n>IgnoreCommandLineOptions</span> <span class=o>=</span> <span class=kc>True</span>

<span class=kn>import</span> <span class=nn>onnxruntime</span> <span class=k>as</span> <span class=nn>ort</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>os</span> 

<span class=k>class</span> <span class=nc>exampleOrtProducer</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>beginJob</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>model_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&quot;CMSSW_BASE&quot;</span><span class=p>),</span> <span class=s1>&#39;src&#39;</span><span class=p>,</span> <span class=s1>&#39;MySubsystem/MyModule/data/model.onnx&#39;</span><span class=p>)</span>
<span class=hll>        <span class=bp>self</span><span class=o>.</span><span class=n>ort_sess</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
</span>
    <span class=k>def</span> <span class=nf>endJob</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>beginFile</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputFile</span><span class=p>,</span> <span class=n>outputFile</span><span class=p>,</span> <span class=n>inputTree</span><span class=p>,</span> <span class=n>wrappedOutputTree</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>out</span> <span class=o>=</span> <span class=n>wrappedOutputTree</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>branch</span><span class=p>(</span><span class=s2>&quot;OrtScore&quot;</span><span class=p>,</span> <span class=s2>&quot;F&quot;</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>endFile</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputFile</span><span class=p>,</span> <span class=n>outputFile</span><span class=p>,</span> <span class=n>inputTree</span><span class=p>,</span> <span class=n>wrappedOutputTree</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>analyze</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>event</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;process event, return True (go to next module) or False (fail, go to next event)&quot;&quot;&quot;</span>

        <span class=c1># create input data</span>
        <span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>event</span><span class=o>.</span><span class=n>event</span> <span class=o>%</span> <span class=mi>100</span><span class=p>,</span> <span class=n>event</span><span class=o>.</span><span class=n>event</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>+</span> <span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
        <span class=c1># run inference</span>
<span class=hll>        <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ort_sess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=p>{</span><span class=s1>&#39;my_input&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>data</span><span class=p>])})[</span><span class=mi>0</span><span class=p>]</span>
</span>        <span class=c1># print input and output</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;input -&gt;&#39;</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;output -&gt;&#39;</span><span class=p>,</span> <span class=n>outputs</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>fillBranch</span><span class=p>(</span><span class=s2>&quot;OrtScore&quot;</span><span class=p>,</span> <span class=n>outputs</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
        <span class=k>return</span> <span class=kc>True</span>


<span class=c1># define modules using the syntax &#39;name = lambda : constructor&#39; to avoid having them loaded when not needed</span>

<span class=n>exampleOrtModuleConstr</span> <span class=o>=</span> <span class=k>lambda</span><span class=p>:</span> <span class=n>exampleOrtProducer</span><span class=p>()</span>
</code></pre></div></td></tr></table></div> <p>Please notice the highlighted lines for the creation of ONNX Runtime <code>Session</code> and launching the inference.</p> <p>Finally, following the test command from NanoAOD-tools, we run our custom module in <code>python3</code> by <div class=highlight><pre><span></span><code>python3<span class=w> </span>scripts/nano_postproc.py<span class=w> </span>outDir<span class=w> </span>/eos/cms/store/user/andrey/f.root<span class=w> </span>-I<span class=w> </span>PhysicsTools.NanoAODTools.postprocessing.examples.exampleOrtModule<span class=w> </span>exampleOrtModuleConstr<span class=w> </span>-N<span class=w> </span><span class=m>10</span>
</code></pre></div></p> <p>We should see the output as follows <div class=highlight><pre><span></span><code>processing.examples.exampleOrtModule exampleOrtModuleConstr -N 10
Loading exampleOrtModuleConstr from PhysicsTools.NanoAODTools.postprocessing.examples.exampleOrtModule
Will write selected trees to outDir
Pre-select 10 entries out of 10 (100.00%)
input -&gt; [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]
output -&gt; [[0.83919346 0.16080655]]
input -&gt; [ 7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]
output -&gt; [[0.76994413 0.2300559 ]]
input -&gt; [ 4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]
output -&gt; [[0.7116992 0.2883008]]
input -&gt; [ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]
output -&gt; [[0.66414535 0.33585465]]
input -&gt; [ 9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]
output -&gt; [[0.80617136 0.19382869]]
input -&gt; [ 6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]
output -&gt; [[0.75187963 0.2481204 ]]
input -&gt; [16. 17. 18. 19. 20. 21. 22. 23. 24. 25.]
output -&gt; [[0.9014619  0.09853811]]
input -&gt; [18. 19. 20. 21. 22. 23. 24. 25. 26. 27.]
output -&gt; [[0.9202239  0.07977609]]
input -&gt; [ 5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]
output -&gt; [[0.7330253  0.26697478]]
input -&gt; [10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]
output -&gt; [[0.82333535 0.17666471]]
Processed 10 preselected entries from /eos/cms/store/user/andrey/f.root (10 entries). Finally selected 10 entries
Done outDir/f_Skim.root
Total time 1.1 sec. to process 10 events. Rate = 9.3 Hz.
</code></pre></div></p> </details> <h2 id=links-and-further-reading>Links and further reading<a class=headerlink href=#links-and-further-reading title="Permanent link">&para;</a></h2> <ul> <li>ONNX/ONNX Runtime<ul> <li><a href=https://github.com/onnx/tutorials#converting-to-onnx-format>Tutorials on converting models to ONNX format</a></li> <li><a href=https://github.com/microsoft/onnxruntime-inference-examples/tree/main/c_cxx>ONNX Runtime C++ example</a></li> <li><a href=https://onnxruntime.ai/docs/api/c/index.html>ONNX Runtime C++ API</a></li> <li><a href=https://onnxruntime.ai/docs/get-started/with-python.html>ONNX Runtime python example</a></li> <li><a href=https://onnxruntime.ai/docs/api/python/api_summary.html>ONNX Runtime python API</a></li> <li><a href=https://indico.cern.ch/event/1127774/contributions/4733524/attachments/2394910/4094695/ONNXRuntime_20220221.pdf>ONNX Runtime in CMSSW (talk)</a></li> </ul> </li> </ul> <hr> <p>Developers: <a href=mailto:huilin.qu@cern.ch>Huilin Qu</a></p> <p>Authors: <a href=mailto:congqiao.li@cern.ch>Congqiao Li</a></p> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">January 8, 2024</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2020-2023 CMS Machine Learning Group </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/cms-ml target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </a> <a href=https://hub.docker.com/orgs/cmsml/repositories target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1v59.4zm0-204.3h-66.1v60.7h66.1V32zm78.2 144.8H362v59.4h66.1v-59.4zm-156.3-72.1h-66.1v60.1h66.1v-60.1zm78.1 0h-66.1v60.1h66.1v-60.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1l-13.3-8.9zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm-78.1-72.1h-66.1v60.1h66.1v-60.1z"/></svg> </a> <a href=https://cms-talk.web.cern.ch/c/physics/ml/104 target=_blank rel=noopener title=cms-talk.web.cern.ch class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M256 448c141.4 0 256-93.1 256-208S397.4 32 256 32 0 125.1 0 240c0 45.1 17.7 86.8 47.7 120.9-1.9 24.5-11.4 46.3-21.4 62.9-5.5 9.2-11.1 16.6-15.2 21.6-2.1 2.5-3.7 4.4-4.9 5.7-.6.6-1 1.1-1.3 1.4l-.3.3c-4.6 4.6-5.9 11.4-3.4 17.4 2.5 6 8.3 9.9 14.8 9.9 28.7 0 57.6-8.9 81.6-19.3 22.9-10 42.4-21.9 54.3-30.6 31.8 11.5 67 17.9 104.1 17.9zM128 272c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm128 0c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm160-32c0 17.7-14.3 32-32 32s-32-14.3-32-32 14.3-32 32-32 32 14.3 32 32z"/></svg> </a> <a href=mailto:cms-conveners-ml-knowledge@cern.ch target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l217.6 163.2c11.4 8.5 27 8.5 38.4 0l217.6-163.2c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48H48zM0 176v208c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V176L294.4 339.2a63.9 63.9 0 0 1-76.8 0L0 176z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["instant", "navigation.sections"], "search": "../assets/javascripts/workers/search.e5c33ebb.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../assets/javascripts/bundle.ba449ae6.min.js></script> <script src=https://unpkg.com/mermaid@9.3/dist/mermaid.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>