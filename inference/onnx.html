<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Documentation of the CMS Machine Learning Group"><link rel=canonical href=https://cms-ml.github.io/documentation/inference/onnx.html><meta name=author content="CMS Machine Learning Group"><link rel="shortcut icon" href=../images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.5.3"><title>ONNX - CMS Machine Learning Documentation</title><link rel=stylesheet href=../assets/stylesheets/main.947af8d5.min.css><link rel=stylesheet href=../assets/stylesheets/palette.7f672a1f.min.css><meta name=theme-color content=#3f51b5><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style></head> <body dir=ltr data-md-color-scheme=preference data-md-color-primary=indigo data-md-color-accent=orange> <script>matchMedia("(prefers-color-scheme: dark)").matches&&document.body.setAttribute("data-md-color-scheme","slate")</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#direct-inference-with-onnx-runtime class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://cms-ml.github.io/documentation title="CMS Machine Learning Documentation" class="md-header-nav__button md-logo" aria-label="CMS Machine Learning Documentation"> <img src=../images/logo.png alt=logo> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> CMS Machine Learning Documentation </span> <span class="md-header-nav__topic md-ellipsis"> ONNX </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/cms-ml/documentation/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://cms-ml.github.io/documentation title="CMS Machine Learning Documentation" class="md-nav__button md-logo" aria-label="CMS Machine Learning Documentation"> <img src=../images/logo.png alt=logo> </a> CMS Machine Learning Documentation </label> <div class=md-nav__source> <a href=https://github.com/cms-ml/documentation/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> cms-ml/documentation </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../index.html title=Home class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Innovation <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Innovation data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Innovation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../innovation/journal_club.html title="ML Journal Club" class=md-nav__link> ML Journal Club </a> </li> <li class=md-nav__item> <a href=../innovation/hackathons.html title="ML Hackathons" class=md-nav__link> ML Hackathons </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Resources <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Resources data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Resources/Cloud_Resources/index.html title="Cloud Resources" class=md-nav__link> Cloud Resources </a> </li> <li class=md-nav__item> <a href=../Resources/FPGA_Resources/index.html title="FPGA Resource" class=md-nav__link> FPGA Resource </a> </li> <li class=md-nav__item> <a href=../Resources/GPU_Resources/index.html title="GPU Resources" class=md-nav__link> GPU Resources </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4 checked> <label class=md-nav__link for=nav-4> Tutorials <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Tutorials data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-1 type=checkbox id=nav-4-1> <label class=md-nav__link for=nav-4-1> Optimization <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Optimization data-md-level=2> <label class=md-nav__title for=nav-4-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../optimization/model_optimization.html title="Model optimization" class=md-nav__link> Model optimization </a> </li> <li class=md-nav__item> <a href=../optimization/importance.html title="Feature importance" class=md-nav__link> Feature importance </a> </li> <li class=md-nav__item> <a href=../optimization/data_augmentation.html title="Data augmentation" class=md-nav__link> Data augmentation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-2 type=checkbox id=nav-4-2> <label class=md-nav__link for=nav-4-2> Validation <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Validation data-md-level=2> <label class=md-nav__title for=nav-4-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Validation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../validation/overtraining.html title=Overtraining class=md-nav__link> Overtraining </a> </li> <li class=md-nav__item> <a href=../validation/cross_validation.html title="Cross validation" class=md-nav__link> Cross validation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3 type=checkbox id=nav-4-3 checked> <label class=md-nav__link for=nav-4-3> Inference <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Inference data-md-level=2> <label class=md-nav__title for=nav-4-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Inference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-1 type=checkbox id=nav-4-3-1 checked> <label class=md-nav__link for=nav-4-3-1> Direct inference <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Direct inference" data-md-level=3> <label class=md-nav__title for=nav-4-3-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Direct inference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=tensorflow1.html title="TensorFlow 1" class=md-nav__link> TensorFlow 1 </a> </li> <li class=md-nav__item> <a href=tensorflow2.html title="TensorFlow 2" class=md-nav__link> TensorFlow 2 </a> </li> <li class=md-nav__item> <a href=pytorch.html title=PyTorch class=md-nav__link> PyTorch </a> </li> <li class=md-nav__item> <a href=pyg.html title="PyTorch Geometric" class=md-nav__link> PyTorch Geometric </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> ONNX <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg> </span> </label> <a href=onnx.html title=ONNX class="md-nav__link md-nav__link--active"> ONNX </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#software-setup class=md-nav__link> Software Setup </a> </li> <li class=md-nav__item> <a href=#converting-model-to-onnx class=md-nav__link> Converting model to ONNX </a> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-c class=md-nav__link> Inference in CMSSW (C++) </a> <nav class=md-nav aria-label="Inference in CMSSW (C++)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-includes class=md-nav__link> 1. includes </a> </li> <li class=md-nav__item> <a href=#2-global-cache-object class=md-nav__link> 2. Global cache object </a> </li> <li class=md-nav__item> <a href=#3-initiate-objects class=md-nav__link> 3. Initiate objects </a> </li> <li class=md-nav__item> <a href=#4-inference class=md-nav__link> 4. Inference </a> </li> <li class=md-nav__item> <a href=#full-example class=md-nav__link> Full example </a> </li> <li class=md-nav__item> <a href=#test-our-module class=md-nav__link> Test our module </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-python class=md-nav__link> Inference in CMSSW (Python) </a> </li> <li class=md-nav__item> <a href=#links-and-further-reading class=md-nav__link> Links and further reading </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=xgboost.html title=XGBoost class=md-nav__link> XGBoost </a> </li> <li class=md-nav__item> <a href=hls4ml.html title=hls4ml class=md-nav__link> hls4ml </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-2 type=checkbox id=nav-4-3-2> <label class=md-nav__link for=nav-4-3-2> Inference as a service <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Inference as a service" data-md-level=3> <label class=md-nav__title for=nav-4-3-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Inference as a service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=sonic_triton.html title=Sonic/Triton class=md-nav__link> Sonic/Triton </a> </li> <li class=md-nav__item> <a href=tfaas.html title=TFaaS class=md-nav__link> TFaaS </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-3 type=checkbox id=nav-4-3-3> <label class=md-nav__link for=nav-4-3-3> Non-standard workflows <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Non-standard workflows" data-md-level=3> <label class=md-nav__title for=nav-4-3-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Non-standard workflows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=standalone.html title="Standalone framework" class=md-nav__link> Standalone framework </a> </li> <li class=md-nav__item> <a href=swan_aws.html title="SWAN + AWS" class=md-nav__link> SWAN + AWS </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=checklist.html title="Integration checklist" class=md-nav__link> Integration checklist </a> </li> <li class=md-nav__item> <a href=performance.html title=Performance class=md-nav__link> Performance </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3-6 type=checkbox id=nav-4-3-6> <label class=md-nav__link for=nav-4-3-6> Successful integrations <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Successful integrations" data-md-level=3> <label class=md-nav__title for=nav-4-3-6> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Successful integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=particlenet.html title=ParticleNet class=md-nav__link> ParticleNet </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4 type=checkbox id=nav-4-4> <label class=md-nav__link for=nav-4-4> Training <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Training data-md-level=2> <label class=md-nav__title for=nav-4-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Training </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4-1 type=checkbox id=nav-4-4-1> <label class=md-nav__link for=nav-4-4-1> Training as a Service <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Training as a Service" data-md-level=3> <label class=md-nav__title for=nav-4-4-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Training as a Service </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../training/MLaaS4HEP.html title=MLaaS4HEP class=md-nav__link> MLaaS4HEP </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#software-setup class=md-nav__link> Software Setup </a> </li> <li class=md-nav__item> <a href=#converting-model-to-onnx class=md-nav__link> Converting model to ONNX </a> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-c class=md-nav__link> Inference in CMSSW (C++) </a> <nav class=md-nav aria-label="Inference in CMSSW (C++)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-includes class=md-nav__link> 1. includes </a> </li> <li class=md-nav__item> <a href=#2-global-cache-object class=md-nav__link> 2. Global cache object </a> </li> <li class=md-nav__item> <a href=#3-initiate-objects class=md-nav__link> 3. Initiate objects </a> </li> <li class=md-nav__item> <a href=#4-inference class=md-nav__link> 4. Inference </a> </li> <li class=md-nav__item> <a href=#full-example class=md-nav__link> Full example </a> </li> <li class=md-nav__item> <a href=#test-our-module class=md-nav__link> Test our module </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#inference-in-cmssw-python class=md-nav__link> Inference in CMSSW (Python) </a> </li> <li class=md-nav__item> <a href=#links-and-further-reading class=md-nav__link> Links and further reading </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/cms-ml/documentation/blob/master/content/inference/onnx.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=direct-inference-with-onnx-runtime>Direct inference with ONNX Runtime<a class=headerlink href=#direct-inference-with-onnx-runtime title="Permanent link">&para;</a></h1> <p><a href=https://onnx.ai>ONNX</a> is an open format built to represent machine learning models. It is designed to improve <mark>interoperability</mark> across a variety of frameworks and platforms in the AI tools community—most deep learning frameworks (e.g. XGBoost, TensorFlow, PyTorch which are frequently used in CMS) support converting their model into the ONNX format or loading a model from an ONNX format.</p> <figure> <img src=../images/inference/onnx/onnx-interoperability.jpeg width=70%> <figcaption>The figure showing the ONNX interoperability. (Source from <a href=https://towardsdatascience.com/onnx-preventing-framework-lock-in-9a798fb34c92>website</a>.)</figcaption> </figure> <p><a href=https://onnxruntime.ai/ >ONNX Runtime</a> is a tool aiming for the <mark>acceleration of machine learning inferencing</mark> across a variety of deployment platforms. It allows to "run any ONNX model using a single set of inference APIs that provide access to the best hardware acceleration available". It includes "built-in optimization features that trim and consolidate nodes without impacting model accuracy."</p> <p>The CMSSW interface to ONNX Runtime is avaiable since CMSSW_11_1_X (<a href=https://github.com/cms-sw/cmssw/pull/28112>cmssw#28112</a>, <a href=https://github.com/cms-sw/cmsdist/pull/5020>cmsdist#5020</a>). Its functionality is improved in CMSSW_11_2_X. The final implementation is also backported to CMSSW_10_6_X to facilitate Run 2 UL data reprocessing. The inference of a number of deep learning tagger models (e.g. DeepJet, DeepTauID, ParticleNet, DeepDoubleX, etc.) has been made with ONNX Runtime in the routine of UL processing and has gained substantial speedup.</p> <p>On this page, we will <mark>use a simple example to show how to use ONNX Runtime for deep learning model inference in the CMSSW framework</mark>, both in C++ (e.g. to process the MiniAOD file) and in Python (e.g. using NanoAOD-tools to process the NanoAODs). This may help readers who will deploy an ONNX model into their analyses or in the CMSSW framework.</p> <h2 id=software-setup>Software Setup<a class=headerlink href=#software-setup title="Permanent link">&para;</a></h2> <p>We use CMSSW_11_2_5_patch2 to show the simple example for ONNX Runtime inference. The example can also work under the new 12 releases (note that inference with C++ can also run on CMSSW_10_6_X)</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=nb>export</span> <span class=nv>SCRAM_ARCH</span><span class=o>=</span><span class=s2>&quot;slc7_amd64_gcc900&quot;</span>
<span class=nb>export</span> <span class=nv>CMSSW_VERSION</span><span class=o>=</span><span class=s2>&quot;CMSSW_11_2_5_patch2&quot;</span>

<span class=nb>source</span> /cvmfs/cms.cern.ch/cmsset_default.sh

cmsrel <span class=s2>&quot;</span><span class=nv>$CMSSW_VERSION</span><span class=s2>&quot;</span>
<span class=nb>cd</span> <span class=s2>&quot;</span><span class=nv>$CMSSW_VERSION</span><span class=s2>/src&quot;</span>

cmsenv
scram b
</code></pre></div> </td></tr></table> <h2 id=converting-model-to-onnx>Converting model to ONNX<a class=headerlink href=#converting-model-to-onnx title="Permanent link">&para;</a></h2> <p>The model deployed into CMSSW or our analysis needs to be converted to ONNX from the original framework format where it is trained. Please see <a href=https://github.com/onnx/tutorials#converting-to-onnx-format>here</a> for a nice deck of tutorials on converting models from different mainstream frameworks into ONNX.</p> <p>Here we take PyTorch as an example. A PyTorch model can be converted by <code>torch.onnx.export(...)</code>. As a simple illustration, we convert a randomly initialized feed-forward network implemented in PyTorch, with 10 input nodes and 2 output nodes, and two hidden layers with 64 nodes each. The conversion code is presented below. The output model <code>model.onnx</code> will be deployed under the CMSSW framework in our following tutorial.</p> <details class=hint><summary>Click to expand</summary><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=k>class</span> <span class=nc>SimpleMLP</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>SimpleMLP</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> 
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>64</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> 
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span> 
            <span class=p>)</span>
    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># input x: (batch_size, feature_dim=10)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleMLP</span><span class=p>()</span>

<span class=c1># create dummy input for the model</span>
<span class=n>dummy_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=c1># batch size = 1</span>

<span class=c1># export model to ONNX</span>
<span class=n>torch</span><span class=o>.</span><span class=n>onnx</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>dummy_input</span><span class=p>,</span> <span class=s2>&quot;model.onnx&quot;</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>input_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;my_input&#39;</span><span class=p>],</span> <span class=n>output_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;my_output&#39;</span><span class=p>])</span>
</code></pre></div> </td></tr></table> </details> <h2 id=inference-in-cmssw-c>Inference in CMSSW (C++)<a class=headerlink href=#inference-in-cmssw-c title="Permanent link">&para;</a></h2> <p>We will introduce how to write a module to run inference on the ONNX model under the CMSSW framework. CMSSW is known for its multi-threaded ability. In a threaded framework, multiple threads are served for processing events in the event loop. The logic is straightforward: a new event is assigned to idled threads following the first-come-first-serve princlple.</p> <p>In most cases, each thread is able to process events individually as the majority of event processing workflow can be accomplished only by seeing the information of that event. Thus, the <code>stream</code> modules (<code>stream</code> <code>EDAnalyzer</code> and <code>stream</code> <code>EDFilter</code>) are used frequently as each thread holds an individual copy of the module instance—they do not need to communicate with each other. It is however also possible to share a global cache object between all threads in case sharing information across threads is necessary. In all, such CMSSW EDAnalyzer modules are declared by <code class=highlight><span class=k>class</span> <span class=nc>MyPlugin</span> <span class=o>:</span> <span class=k>public</span> <span class=n>edm</span><span class=o>::</span><span class=n>stream</span><span class=o>::</span><span class=n>EDAnalyzer</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span><span class=o>&lt;</span><span class=n>CacheData</span><span class=o>&gt;&gt;</span></code> (similar for <code>EDFilter</code>). Details can be found in documentation on the <a href=https://twiki.cern.ch/twiki/bin/view/CMSPublic/FWMultithreadedFrameworkStreamModuleInterface>C++ interface of <code>stream</code> modules</a>.</p> <p>Let's then think about what would happen when interfacing CMSSW with ONNX for model inference. When ONNX Runtime accepts a model, it converts the model into an in-memory representation, and performance a variety of optimizations depending on the operators in the model. The procedure is done when an ONNX Runtime <code>Session</code> is created with an inputting model. The economic method will then be to hold only one <code>Session</code> for all threads—this may save memory to a large extent, as the model has only one copy in memory. Upon request from multiple threads to do inference with their input data, the <code>Session</code> accepts those requests and serializes them, then produces the output data. ONNX Runtime has by design accepted that multithread threads invoke the <code>Run()</code> method on the same inference <code>Session</code> object. Therefore, what has left us to do is to</p> <ol> <li>create a <code>Session</code> as a global object in our CMSSW module and share it among all threads;</li> <li>in each thread, we process the input data and then call the <code>Run()</code> method from that global <code>Session</code>.</li> </ol> <p>That's the main logic for implementing ONNX inference in CMSSW. For details of high-level designs of ONNX Runtime, please see <a href=https://onnxruntime.ai/docs/reference/high-level-design.html>documentation here</a>.</p> <p>With this concept, let's build the module.</p> <h5 id=1-includes>1. includes<a class=headerlink href=#1-includes title="Permanent link">&para;</a></h5> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3
4</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=cp>#include</span> <span class=cpf>&quot;FWCore/Framework/interface/stream/EDAnalyzer.h&quot;</span><span class=cp></span>
<span class=cp>#include</span> <span class=cpf>&quot;PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h&quot;</span><span class=cp></span>
<span class=c1>// further framework includes</span>
<span class=p>...</span>
</code></pre></div> </td></tr></table> <p>We include <code>stream/EDAnalyzer.h</code> to build the <code>stream</code> CMSSW module.</p> <h5 id=2-global-cache-object>2. Global cache object<a class=headerlink href=#2-global-cache-object title="Permanent link">&para;</a></h5> <p>In CMSSW there exists a class <a href=https://github.com/cms-sw/cmssw/blob/master/PhysicsTools/ONNXRuntime/src/ONNXRuntime.cc><code>ONNXRuntime</code></a> which can be used directly as the global cache object. Upon initialization from a given model, it holds the ONNX Runtime <code>Session</code> object and provides the handle to invoke the <code>Run()</code> for model inference.</p> <p>We put the <code>ONNXRuntime</code> class in the <code class=highlight><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span></code> template argument:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=hll><span class=k>class</span> <span class=nc>MyPlugin</span> <span class=o>:</span> <span class=k>public</span> <span class=n>edm</span><span class=o>::</span><span class=n>stream</span><span class=o>::</span><span class=n>EDAnalyzer</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;&gt;</span> <span class=p>{</span>
</span>  <span class=p>...</span>
<span class=p>};</span>
</code></pre></div> </td></tr></table> <h5 id=3-initiate-objects>3. Initiate objects<a class=headerlink href=#3-initiate-objects title="Permanent link">&para;</a></h5> <p>In the <code>stream</code> <code>EDAnlyzer</code> module, it provides a hook <code>initializeGlobalCache()</code> to initiate the global object. We simply do</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span> <span class=n>MyPlugin</span><span class=o>::</span><span class=n>initializeGlobalCache</span><span class=p>(</span><span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span> <span class=o>&amp;</span><span class=n>iConfig</span><span class=p>)</span> <span class=p>{</span>
  <span class=k>return</span> <span class=n>std</span><span class=o>::</span><span class=n>make_unique</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=p>(</span><span class=n>iConfig</span><span class=p>.</span><span class=n>getParameter</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&quot;model_path&quot;</span><span class=p>).</span><span class=n>fullPath</span><span class=p>());</span>
<span class=p>}</span>
</code></pre></div> </td></tr></table> <p>to initiate the <code>ONNXRuntime</code> object upon a given model path.</p> <h5 id=4-inference>4. Inference<a class=headerlink href=#4-inference title="Permanent link">&para;</a></h5> <p>We know the event processing step is implemented in the <code>void EDAnalyzer::analyze</code> method. When an event is assigned to a valid thread, the content will be processed in that thread. This can go in parallel with other threads processing other events.</p> <p>We need to first construct the input data dedicated to the event. Here we create a dummy input: a sequence of consecutive integers of length 10. The input is set by replacing the values of our pre-booked vector, <code>data_</code>. This member variable has <code class=highlight><span class=n>vector</span><span class=o>&lt;</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;&gt;</span></code> format and is initialised as <code class=highlight><span class=p>{</span> <span class=p>{</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=p>...,</span> <span class=mi>0</span><span class=p>}</span> <span class=p>}</span></code> (contains only one element, which is a vector of 10 zeros). In processing of each event, the input <code>data_</code> is modified:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3
4</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>group_data</span> <span class=o>=</span> <span class=n>data_</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
<span class=k>for</span> <span class=p>(</span><span class=kt>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
  <span class=n>group_data</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=kt>float</span><span class=p>(</span><span class=n>iEvent</span><span class=p>.</span><span class=n>id</span><span class=p>().</span><span class=n>event</span><span class=p>()</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>+</span> <span class=n>i</span><span class=p>);</span>
<span class=p>}</span>
</code></pre></div> </td></tr></table> <p>Then, we send <code>data_</code> to the inference engine and get the model output:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>outputs</span> <span class=o>=</span> <span class=n>globalCache</span><span class=p>()</span><span class=o>-&gt;</span><span class=n>run</span><span class=p>(</span><span class=n>input_names_</span><span class=p>,</span> <span class=n>data_</span><span class=p>,</span> <span class=n>input_shapes_</span><span class=p>)[</span><span class=mi>0</span><span class=p>];</span>
</code></pre></div> </td></tr></table> <p>We clarify a few details here.</p> <p>First, we use <code class=highlight><span class=n>globalCache</span><span class=p>()</span></code> which is a class method in our <code>stream</code> CMSSW module to access the global object shared across all threads. In our case it is the <code>ONNXRuntime</code> instance.</p> <p>The <code>run()</code> method is a wrapper to call <code>Run()</code> on the ONNX <code>Session</code>. Definations on the method arguments are (code from <a href=https://github.com/cms-sw/cmssw/blob/CMSSW_11_2_5_patch2/PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h#L32-L44>link</a>): <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=c1>// Run inference and get outputs</span>
<span class=c1>// input_names: list of the names of the input nodes.</span>
<span class=c1>// input_values: list of input arrays for each input node. The order of `input_values` must match `input_names`.</span>
<span class=c1>// input_shapes: list of `int64_t` arrays specifying the shape of each input node. Can leave empty if the model does not have dynamic axes.</span>
<span class=c1>// output_names: names of the output nodes to get outputs from. Empty list means all output nodes.</span>
<span class=c1>// batch_size: number of samples in the batch. Each array in `input_values` must have a shape layout of (batch_size, ...).</span>
<span class=c1>// Returns: a std::vector&lt;std::vector&lt;float&gt;&gt;, with the order matched to `output_names`.</span>
<span class=c1>// When `output_names` is empty, will return all outputs ordered as in `getOutputNames()`.</span>
<span class=n>FloatArrays</span> <span class=nf>run</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&amp;</span> <span class=n>input_names</span><span class=p>,</span>
                <span class=n>FloatArrays</span><span class=o>&amp;</span> <span class=n>input_values</span><span class=p>,</span>
                <span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int64_t</span><span class=o>&gt;&gt;&amp;</span> <span class=n>input_shapes</span> <span class=o>=</span> <span class=p>{},</span>
                <span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&amp;</span> <span class=n>output_names</span> <span class=o>=</span> <span class=p>{},</span>
                <span class=kt>int64_t</span> <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>1</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
</code></pre></div> </td></tr></table> where we have <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>typedef</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;&gt;</span> <span class=n>FloatArrays</span><span class=p>;</span>
</code></pre></div> </td></tr></table></p> <p>In our case, <code class=highlight><span class=n>input_names</span></code> is set to <code class=highlight><span class=p>{</span><span class=s>&quot;my_input&quot;</span><span class=p>}</span></code> which corresponds to the names upon model creation. <code class=highlight><span class=n>input_values</span></code> is a length-1 vector, and <code class=highlight><span class=n>input_values</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span></code> is a vector of float of length 10, which are inputs to the 10 nodes. <code class=highlight><span class=n>input_shapes</span></code> can be set empty here and will be necessary for advanced usage, when our input has dynamic lengths (e.g., in boosed jet tagging, we use different numbers of particle-flow candidates and secondary vertices as input).</p> <p>For the usual model design, we have only one vector of output. In such a case, the output is simply a length-1 vector, and we use <code class=highlight><span class=p>[</span><span class=mi>0</span><span class=p>]</span></code> to get the vector of two float numbers—the output of the model.</p> <h5 id=full-example>Full example<a class=headerlink href=#full-example title="Permanent link">&para;</a></h5> <p>Let's construct the full example.</p> <details class=hint><summary>Click to expand</summary><p>The example assumes the following directory structure:</p> <div class=highlight><pre><span></span><code>MySubsystem/MyModule/
│
├── plugins/
│   ├── MyPlugin.cpp
│   └── BuildFile.xml
│
├── test/
│   └── my_plugin_cfg.py
│
└── data/
    └── model.onnx
</code></pre></div> <div class=tabbed-set data-tabs=1:4><input checked=checked id=__tabbed_1_1 name=__tabbed_1 type=radio><label for=__tabbed_1_1>plugins/MyPlugin.cpp</label><div class=tabbed-content> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=cm>/*</span>
<span class=hll><span class=cm> * Example plugin to demonstrate the direct multi-threaded inference with ONNX Runtime.</span>
</span><span class=cm> */</span>

<span class=cp>#include</span> <span class=cpf>&lt;memory&gt;</span><span class=cp></span>
<span class=cp>#include</span> <span class=cpf>&lt;iostream&gt;</span><span class=cp></span>

<span class=cp>#include</span> <span class=cpf>&quot;FWCore/Framework/interface/Event.h&quot;</span><span class=cp></span>
<span class=cp>#include</span> <span class=cpf>&quot;FWCore/Framework/interface/Frameworkfwd.h&quot;</span><span class=cp></span>
<span class=cp>#include</span> <span class=cpf>&quot;FWCore/Framework/interface/MakerMacros.h&quot;</span><span class=cp></span>
<span class=cp>#include</span> <span class=cpf>&quot;FWCore/Framework/interface/stream/EDAnalyzer.h&quot;</span><span class=cp></span>
<span class=cp>#include</span> <span class=cpf>&quot;FWCore/ParameterSet/interface/ParameterSet.h&quot;</span><span class=cp></span>

<span class=cp>#include</span> <span class=cpf>&quot;PhysicsTools/ONNXRuntime/interface/ONNXRuntime.h&quot;</span><span class=cp></span>

<span class=k>using</span> <span class=k>namespace</span> <span class=n>cms</span><span class=o>::</span><span class=n>Ort</span><span class=p>;</span>

<span class=k>class</span> <span class=nc>MyPlugin</span> <span class=o>:</span> <span class=k>public</span> <span class=n>edm</span><span class=o>::</span><span class=n>stream</span><span class=o>::</span><span class=n>EDAnalyzer</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>GlobalCache</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;&gt;</span> <span class=p>{</span>
<span class=k>public</span><span class=o>:</span>
  <span class=k>explicit</span> <span class=n>MyPlugin</span><span class=p>(</span><span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span> <span class=o>&amp;</span><span class=p>,</span> <span class=k>const</span> <span class=n>ONNXRuntime</span> <span class=o>*</span><span class=p>);</span>
  <span class=k>static</span> <span class=kt>void</span> <span class=nf>fillDescriptions</span><span class=p>(</span><span class=n>edm</span><span class=o>::</span><span class=n>ConfigurationDescriptions</span><span class=o>&amp;</span><span class=p>);</span>

  <span class=k>static</span> <span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span> <span class=n>initializeGlobalCache</span><span class=p>(</span><span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span> <span class=o>&amp;</span><span class=p>);</span>
  <span class=k>static</span> <span class=kt>void</span> <span class=nf>globalEndJob</span><span class=p>(</span><span class=k>const</span> <span class=n>ONNXRuntime</span> <span class=o>*</span><span class=p>);</span>

<span class=k>private</span><span class=o>:</span>
  <span class=kt>void</span> <span class=n>beginJob</span><span class=p>();</span>
  <span class=kt>void</span> <span class=nf>analyze</span><span class=p>(</span><span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>Event</span><span class=o>&amp;</span><span class=p>,</span> <span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>EventSetup</span><span class=o>&amp;</span><span class=p>);</span>
  <span class=kt>void</span> <span class=nf>endJob</span><span class=p>();</span>

  <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;</span> <span class=n>input_names_</span><span class=p>;</span>
  <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int64_t</span><span class=o>&gt;&gt;</span> <span class=n>input_shapes_</span><span class=p>;</span>
  <span class=n>FloatArrays</span> <span class=n>data_</span><span class=p>;</span> <span class=c1>// each stream hosts its own data</span>
<span class=p>};</span>


<span class=kt>void</span> <span class=n>MyPlugin</span><span class=o>::</span><span class=n>fillDescriptions</span><span class=p>(</span><span class=n>edm</span><span class=o>::</span><span class=n>ConfigurationDescriptions</span><span class=o>&amp;</span> <span class=n>descriptions</span><span class=p>)</span> <span class=p>{</span>
  <span class=c1>// defining this function will lead to a *_cfi file being generated when compiling</span>
  <span class=n>edm</span><span class=o>::</span><span class=n>ParameterSetDescription</span> <span class=n>desc</span><span class=p>;</span>
  <span class=n>desc</span><span class=p>.</span><span class=n>add</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&quot;model_path&quot;</span><span class=p>,</span> <span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=p>(</span><span class=s>&quot;MySubsystem/MyModule/data/model.onnx&quot;</span><span class=p>));</span>
  <span class=n>desc</span><span class=p>.</span><span class=n>add</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&gt;</span><span class=p>(</span><span class=s>&quot;input_names&quot;</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;</span><span class=p>({</span><span class=s>&quot;my_input&quot;</span><span class=p>}));</span>
  <span class=n>descriptions</span><span class=p>.</span><span class=n>addWithDefaultLabel</span><span class=p>(</span><span class=n>desc</span><span class=p>);</span>
<span class=p>}</span>


<span class=n>MyPlugin</span><span class=o>::</span><span class=n>MyPlugin</span><span class=p>(</span><span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span> <span class=o>&amp;</span><span class=n>iConfig</span><span class=p>,</span> <span class=k>const</span> <span class=n>ONNXRuntime</span> <span class=o>*</span><span class=n>cache</span><span class=p>)</span>
    <span class=o>:</span> <span class=n>input_names_</span><span class=p>(</span><span class=n>iConfig</span><span class=p>.</span><span class=n>getParameter</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>string</span><span class=o>&gt;&gt;</span><span class=p>(</span><span class=s>&quot;input_names&quot;</span><span class=p>)),</span>
      <span class=n>input_shapes_</span><span class=p>()</span> <span class=p>{</span>
    <span class=c1>// initialize the input data arrays</span>
    <span class=c1>// note there is only one element in the FloatArrays type (i.e. vector&lt;vector&lt;float&gt;&gt;) variable</span>
    <span class=n>data_</span><span class=p>.</span><span class=n>emplace_back</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
<span class=p>}</span>


<span class=n>std</span><span class=o>::</span><span class=n>unique_ptr</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span> <span class=n>MyPlugin</span><span class=o>::</span><span class=n>initializeGlobalCache</span><span class=p>(</span><span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>ParameterSet</span> <span class=o>&amp;</span><span class=n>iConfig</span><span class=p>)</span> <span class=p>{</span>
  <span class=k>return</span> <span class=n>std</span><span class=o>::</span><span class=n>make_unique</span><span class=o>&lt;</span><span class=n>ONNXRuntime</span><span class=o>&gt;</span><span class=p>(</span><span class=n>iConfig</span><span class=p>.</span><span class=n>getParameter</span><span class=o>&lt;</span><span class=n>edm</span><span class=o>::</span><span class=n>FileInPath</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&quot;model_path&quot;</span><span class=p>).</span><span class=n>fullPath</span><span class=p>());</span>
<span class=p>}</span>

<span class=kt>void</span> <span class=n>MyPlugin</span><span class=o>::</span><span class=n>globalEndJob</span><span class=p>(</span><span class=k>const</span> <span class=n>ONNXRuntime</span> <span class=o>*</span><span class=n>cache</span><span class=p>)</span> <span class=p>{}</span>

<span class=kt>void</span> <span class=n>MyPlugin</span><span class=o>::</span><span class=n>analyze</span><span class=p>(</span><span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>Event</span> <span class=o>&amp;</span><span class=n>iEvent</span><span class=p>,</span> <span class=k>const</span> <span class=n>edm</span><span class=o>::</span><span class=n>EventSetup</span> <span class=o>&amp;</span><span class=n>iSetup</span><span class=p>)</span> <span class=p>{</span>
  <span class=c1>// prepare dummy inputs for every event</span>
  <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>group_data</span> <span class=o>=</span> <span class=n>data_</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
  <span class=k>for</span> <span class=p>(</span><span class=kt>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
      <span class=n>group_data</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=kt>float</span><span class=p>(</span><span class=n>iEvent</span><span class=p>.</span><span class=n>id</span><span class=p>().</span><span class=n>event</span><span class=p>()</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>+</span> <span class=n>i</span><span class=p>);</span>
  <span class=p>}</span>

  <span class=c1>// run prediction and get outputs</span>
  <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>outputs</span> <span class=o>=</span> <span class=n>globalCache</span><span class=p>()</span><span class=o>-&gt;</span><span class=n>run</span><span class=p>(</span><span class=n>input_names_</span><span class=p>,</span> <span class=n>data_</span><span class=p>,</span> <span class=n>input_shapes_</span><span class=p>)[</span><span class=mi>0</span><span class=p>];</span>

  <span class=c1>// print the input and output data</span>
  <span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=s>&quot;input data -&gt; &quot;</span><span class=p>;</span>
  <span class=k>for</span> <span class=p>(</span><span class=k>auto</span> <span class=o>&amp;</span><span class=nl>i</span><span class=p>:</span> <span class=n>group_data</span><span class=p>)</span> <span class=p>{</span> <span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>i</span> <span class=o>&lt;&lt;</span> <span class=s>&quot; &quot;</span><span class=p>;</span> <span class=p>}</span>
  <span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span> <span class=o>&lt;&lt;</span> <span class=s>&quot;output data -&gt; &quot;</span><span class=p>;</span>
  <span class=k>for</span> <span class=p>(</span><span class=k>auto</span> <span class=o>&amp;</span><span class=nl>i</span><span class=p>:</span> <span class=n>outputs</span><span class=p>)</span> <span class=p>{</span> <span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>i</span> <span class=o>&lt;&lt;</span> <span class=s>&quot; &quot;</span><span class=p>;</span> <span class=p>}</span>
  <span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>

<span class=p>}</span>

<span class=n>DEFINE_FWK_MODULE</span><span class=p>(</span><span class=n>MyPlugin</span><span class=p>);</span>
</code></pre></div> </td></tr></table> </div> <input id=__tabbed_1_2 name=__tabbed_1 type=radio><label for=__tabbed_1_2>plugins/BuildFile.xml</label><div class=tabbed-content> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3
4
5
6</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=nt>&lt;use</span> <span class=na>name=</span><span class=s>&quot;FWCore/Framework&quot;</span> <span class=nt>/&gt;</span>
<span class=nt>&lt;use</span> <span class=na>name=</span><span class=s>&quot;FWCore/PluginManager&quot;</span> <span class=nt>/&gt;</span>
<span class=nt>&lt;use</span> <span class=na>name=</span><span class=s>&quot;FWCore/ParameterSet&quot;</span> <span class=nt>/&gt;</span>
<span class=nt>&lt;use</span> <span class=na>name=</span><span class=s>&quot;PhysicsTools/ONNXRuntime&quot;</span> <span class=nt>/&gt;</span>

<span class=nt>&lt;flags</span> <span class=na>EDM_PLUGIN=</span><span class=s>&quot;1&quot;</span> <span class=nt>/&gt;</span>
</code></pre></div> </td></tr></table> </div> <input id=__tabbed_1_3 name=__tabbed_1 type=radio><label for=__tabbed_1_3>test/my_plugin_cfg.py</label><div class=tabbed-content> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=c1># coding: utf-8</span>

<span class=kn>import</span> <span class=nn>os</span>

<span class=kn>import</span> <span class=nn>FWCore.ParameterSet.Config</span> <span class=k>as</span> <span class=nn>cms</span>
<span class=kn>from</span> <span class=nn>FWCore.ParameterSet.VarParsing</span> <span class=kn>import</span> <span class=n>VarParsing</span>


<span class=c1># setup minimal options</span>
<span class=n>options</span> <span class=o>=</span> <span class=n>VarParsing</span><span class=p>(</span><span class=s2>&quot;python&quot;</span><span class=p>)</span>
<span class=n>options</span><span class=o>.</span><span class=n>setDefault</span><span class=p>(</span><span class=s2>&quot;inputFiles&quot;</span><span class=p>,</span> <span class=s2>&quot;/store/mc/RunIISummer20UL18MiniAODv2/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/MINIAODSIM/106X_upgrade2018_realistic_v16_L1v1-v2/230000/4C8619B2-D0C0-4647-B946-B33754F4ED16.root&quot;</span><span class=p>)</span>  <span class=c1># noqa</span>
<span class=n>options</span><span class=o>.</span><span class=n>parseArguments</span><span class=p>()</span>

<span class=c1># define the process to run</span>
<span class=n>process</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>Process</span><span class=p>(</span><span class=s2>&quot;TEST&quot;</span><span class=p>)</span>

<span class=c1># minimal configuration</span>
<span class=n>process</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;FWCore.MessageService.MessageLogger_cfi&quot;</span><span class=p>)</span>
<span class=n>process</span><span class=o>.</span><span class=n>MessageLogger</span><span class=o>.</span><span class=n>cerr</span><span class=o>.</span><span class=n>FwkReport</span><span class=o>.</span><span class=n>reportEvery</span> <span class=o>=</span> <span class=mi>1</span>
<span class=n>process</span><span class=o>.</span><span class=n>maxEvents</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>PSet</span><span class=p>(</span><span class=nb>input</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>int32</span><span class=p>(</span><span class=mi>10</span><span class=p>))</span>
<span class=n>process</span><span class=o>.</span><span class=n>source</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>Source</span><span class=p>(</span><span class=s2>&quot;PoolSource&quot;</span><span class=p>,</span>
    <span class=n>fileNames</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>vstring</span><span class=p>(</span><span class=n>options</span><span class=o>.</span><span class=n>inputFiles</span><span class=p>))</span>

<span class=c1># process options</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>PSet</span><span class=p>(</span>
    <span class=n>allowUnscheduled</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>bool</span><span class=p>(</span><span class=kc>True</span><span class=p>),</span>
    <span class=n>wantSummary</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>bool</span><span class=p>(</span><span class=kc>True</span><span class=p>),</span>
<span class=p>)</span>

<span class=c1># setup options for multithreaded</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfThreads</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfStreams</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
<span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfConcurrentLuminosityBlocks</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>


<span class=c1># setup MyPlugin by loading the auto-generated cfi (see MyPlugin.fillDescriptions)</span>
<span class=n>process</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;MySubsystem.MyModule.myPlugin_cfi&quot;</span><span class=p>)</span>
<span class=c1># specify the path of the ONNX model</span>
<span class=n>process</span><span class=o>.</span><span class=n>myPlugin</span><span class=o>.</span><span class=n>model_path</span> <span class=o>=</span> <span class=s2>&quot;MySubsystem/MyModule/data/model.onnx&quot;</span>
<span class=c1># input names as defined in the model</span>
<span class=c1># the order of name strings should also corresponds to the order of input data array feed to the model</span>
<span class=n>process</span><span class=o>.</span><span class=n>myPlugin</span><span class=o>.</span><span class=n>input_names</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;my_input&quot;</span><span class=p>]</span>

<span class=c1># define what to run in the path</span>
<span class=n>process</span><span class=o>.</span><span class=n>p</span> <span class=o>=</span> <span class=n>cms</span><span class=o>.</span><span class=n>Path</span><span class=p>(</span><span class=n>process</span><span class=o>.</span><span class=n>myPlugin</span><span class=p>)</span>
</code></pre></div> </td></tr></table> </div> <input id=__tabbed_1_4 name=__tabbed_1 type=radio><label for=__tabbed_1_4>data/model.onnx</label><div class=tabbed-content> <p>The model is produced by code in the section <a href=#converting-model-to-onnx>"Converting model to ONNX"</a> and can be downloaded <a href=https://github.com/cms-ml/documentation/raw/master/content/inference/code/onnx/model.onnx>here</a>.</p> </div> </div> </details> <h5 id=test-our-module>Test our module<a class=headerlink href=#test-our-module title="Permanent link">&para;</a></h5> <p>Under <code>MySubsystem/MyModule/test</code>, run <code class=highlight>cmsRun my_plugin_cfg.py</code> to launch our module. You may see the following from the output, which include the input and output vectors in the inference process.</p> <details class=hint><summary>Click to see the output</summary><div class=highlight><pre><span></span><code>...
19-Jul-2022 10:50:41 CEST  Successfully opened file root://xrootd-cms.infn.it//store/mc/RunIISummer20UL18MiniAODv2/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/MINIAODSIM/106X_upgrade2018_realistic_v16_L1v1-v2/230000/4C8619B2-D0C0-4647-B946-B33754F4ED16.root
Begin processing the 1st record. Run 1, Event 27074045, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.494 CEST
input data -&gt; 45 46 47 48 49 50 51 52 53 54
output data -&gt; 0.995657 0.00434343
Begin processing the 2nd record. Run 1, Event 27074048, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.495 CEST
input data -&gt; 48 49 50 51 52 53 54 55 56 57
output data -&gt; 0.996884 0.00311563
Begin processing the 3rd record. Run 1, Event 27074059, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.495 CEST
input data -&gt; 59 60 61 62 63 64 65 66 67 68
output data -&gt; 0.999081 0.000919373
Begin processing the 4th record. Run 1, Event 27074061, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.495 CEST
input data -&gt; 61 62 63 64 65 66 67 68 69 70
output data -&gt; 0.999264 0.000736247
Begin processing the 5th record. Run 1, Event 27074046, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 46 47 48 49 50 51 52 53 54 55
output data -&gt; 0.996112 0.00388828
Begin processing the 6th record. Run 1, Event 27074047, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 47 48 49 50 51 52 53 54 55 56
output data -&gt; 0.996519 0.00348065
Begin processing the 7th record. Run 1, Event 27074064, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 64 65 66 67 68 69 70 71 72 73
output data -&gt; 0.999472 0.000527586
Begin processing the 8th record. Run 1, Event 27074074, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 74 75 76 77 78 79 80 81 82 83
output data -&gt; 0.999826 0.000173664
Begin processing the 9th record. Run 1, Event 27074050, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 50 51 52 53 54 55 56 57 58 59
output data -&gt; 0.997504 0.00249614
Begin processing the 10th record. Run 1, Event 27074060, LumiSection 10021 on stream 0 at 19-Jul-2022 10:50:43.496 CEST
input data -&gt; 60 61 62 63 64 65 66 67 68 69
output data -&gt; 0.999177 0.000822734
19-Jul-2022 10:50:43 CEST  Closed file root://xrootd-cms.infn.it//store/mc/RunIISummer20UL18MiniAODv2/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/MINIAODSIM/106X_upgrade2018_realistic_v16_L1v1-v2/230000/4C8619B2-D0C0-4647-B946-B33754F4ED16.root
</code></pre></div> </details> <p>Also we could try launching the script with more threads. Change the corresponding line in <code>my_plugin_cfg.py</code> as follows to activate the multi-threaded mode with 4 threads.</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>31</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>process</span><span class=o>.</span><span class=n>options</span><span class=o>.</span><span class=n>numberOfThreads</span><span class=o>=</span><span class=n>cms</span><span class=o>.</span><span class=n>untracked</span><span class=o>.</span><span class=n>uint32</span><span class=p>(</span><span class=mi>4</span><span class=p>)</span>
</code></pre></div> </td></tr></table> <p>Launch the script again, and one could see the same results, but with the inference processed concurrently on 4 threads.</p> <h2 id=inference-in-cmssw-python>Inference in CMSSW (Python)<a class=headerlink href=#inference-in-cmssw-python title="Permanent link">&para;</a></h2> <p>Doing ONNX Runtime inference with python is possible as well. For those releases that have the ONNX Runtime C++ package installed, the <code>onnxruntime</code> python package is also installed in <mark><code>python3</code></mark> (except for CMSSW_10_6_X). We still use CMSSW_11_2_5_patch2 to run our examples. We could quickly check if <code>onnxruntime</code> is available by:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>python3</span> <span class=o>-</span><span class=n>c</span> <span class=s2>&quot;import onnxruntime; print(&#39;onnxruntime available&#39;)&quot;</span>
</code></pre></div> </td></tr></table> <p>The python code is simple to construct: following the quick examples <a href=https://onnxruntime.ai/docs/get-started/with-python.html>"Get started with ORT for Python"</a>, we create the file <code>MySubsystem/MyModule/test/my_standalone_test.py</code> as follows:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>onnxruntime</span> <span class=k>as</span> <span class=nn>ort</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>

<span class=c1># create input data in the float format (32 bit)</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>45</span><span class=p>,</span> <span class=mi>55</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>

<span class=c1># create inference session using ort.InferenceSession from a given model</span>
<span class=n>ort_sess</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span><span class=s1>&#39;../data/model.onnx&#39;</span><span class=p>)</span>

<span class=c1># run inference</span>
<span class=n>outputs</span> <span class=o>=</span> <span class=n>ort_sess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=p>{</span><span class=s1>&#39;my_input&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>data</span><span class=p>])})[</span><span class=mi>0</span><span class=p>]</span>

<span class=c1># print input and output</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;input -&gt;&#39;</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;output -&gt;&#39;</span><span class=p>,</span> <span class=n>outputs</span><span class=p>)</span>
</code></pre></div> </td></tr></table> <p>Under the directory <code>MySubsystem/MyModule/test</code>, run the example with <code>python3 my_standalone_test.py</code>. Then we see the output:</p> <div class=highlight><pre><span></span><code>input -&gt; [45. 46. 47. 48. 49. 50. 51. 52. 53. 54.]
output -&gt; [[0.9956566  0.00434343]]
</code></pre></div> <p>Using ONNX Runtime on NanoAOD-tools follows the same logic. Here we create the ONNX <code>Session</code> in the beginning stage and run inference in the event loop. Note that NanoAOD-tools runs the event loop in the single-thread mode.</p> <p>Please find details in the following block.</p> <details class=hint><summary>Click to see the NanoAOD-tools example</summary><p>We run the NanoAOD-tools example following the above CMSSW_11_2_5_patch2 environment. According to the setup instruction in <a href=https://github.com/cms-nanoAOD/nanoAOD-tools>NanoAOD-tools</a>, do</p> <div class=highlight><pre><span></span><code><span class=nb>cd</span> <span class=nv>$CMSSW_BASE</span>/src
git clone https://github.com/cms-nanoAOD/nanoAOD-tools.git PhysicsTools/NanoAODTools
<span class=nb>cd</span> PhysicsTools/NanoAODTools
cmsenv
scram b
</code></pre></div> <p>Now we add our custom module to run ONNX Runtime inference. Create a file <code>PhysicsTools/NanoAODTools/python/postprocessing/examples/exampleOrtModule.py</code> with the content:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>PhysicsTools.NanoAODTools.postprocessing.framework.datamodel</span> <span class=kn>import</span> <span class=n>Collection</span>
<span class=kn>from</span> <span class=nn>PhysicsTools.NanoAODTools.postprocessing.framework.eventloop</span> <span class=kn>import</span> <span class=n>Module</span>
<span class=kn>import</span> <span class=nn>ROOT</span>
<span class=n>ROOT</span><span class=o>.</span><span class=n>PyConfig</span><span class=o>.</span><span class=n>IgnoreCommandLineOptions</span> <span class=o>=</span> <span class=kc>True</span>

<span class=kn>import</span> <span class=nn>onnxruntime</span> <span class=k>as</span> <span class=nn>ort</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>os</span> 

<span class=k>class</span> <span class=nc>exampleOrtProducer</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>beginJob</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>model_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&quot;CMSSW_BASE&quot;</span><span class=p>),</span> <span class=s1>&#39;src&#39;</span><span class=p>,</span> <span class=s1>&#39;MySubsystem/MyModule/data/model.onnx&#39;</span><span class=p>)</span>
<span class=hll>        <span class=bp>self</span><span class=o>.</span><span class=n>ort_sess</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
</span>
    <span class=k>def</span> <span class=nf>endJob</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>beginFile</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputFile</span><span class=p>,</span> <span class=n>outputFile</span><span class=p>,</span> <span class=n>inputTree</span><span class=p>,</span> <span class=n>wrappedOutputTree</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>out</span> <span class=o>=</span> <span class=n>wrappedOutputTree</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>branch</span><span class=p>(</span><span class=s2>&quot;OrtScore&quot;</span><span class=p>,</span> <span class=s2>&quot;F&quot;</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>endFile</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputFile</span><span class=p>,</span> <span class=n>outputFile</span><span class=p>,</span> <span class=n>inputTree</span><span class=p>,</span> <span class=n>wrappedOutputTree</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>analyze</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>event</span><span class=p>):</span>
        <span class=sd>&quot;&quot;&quot;process event, return True (go to next module) or False (fail, go to next event)&quot;&quot;&quot;</span>

        <span class=c1># create input data</span>
        <span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>event</span><span class=o>.</span><span class=n>event</span> <span class=o>%</span> <span class=mi>100</span><span class=p>,</span> <span class=n>event</span><span class=o>.</span><span class=n>event</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>+</span> <span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
        <span class=c1># run inference</span>
<span class=hll>        <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ort_sess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=p>{</span><span class=s1>&#39;my_input&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>data</span><span class=p>])})[</span><span class=mi>0</span><span class=p>]</span>
</span>        <span class=c1># print input and output</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;input -&gt;&#39;</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;output -&gt;&#39;</span><span class=p>,</span> <span class=n>outputs</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>fillBranch</span><span class=p>(</span><span class=s2>&quot;OrtScore&quot;</span><span class=p>,</span> <span class=n>outputs</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
        <span class=k>return</span> <span class=kc>True</span>


<span class=c1># define modules using the syntax &#39;name = lambda : constructor&#39; to avoid having them loaded when not needed</span>

<span class=n>exampleOrtModuleConstr</span> <span class=o>=</span> <span class=k>lambda</span><span class=p>:</span> <span class=n>exampleOrtProducer</span><span class=p>()</span>
</code></pre></div> </td></tr></table> <p>Please notice the highlighted lines for the creation of ONNX Runtime <code>Session</code> and launching the inference.</p> <p>Finally, following the test command from NanoAOD-tools, we run our custom module in <code>python3</code> by <div class=highlight><pre><span></span><code>python3 scripts/nano_postproc.py outDir /eos/cms/store/user/andrey/f.root -I PhysicsTools.NanoAODTools.postprocessing.examples.exampleOrtModule exampleOrtModuleConstr -N <span class=m>10</span>
</code></pre></div></p> <p>We should see the output as follows <div class=highlight><pre><span></span><code>processing.examples.exampleOrtModule exampleOrtModuleConstr -N 10
Loading exampleOrtModuleConstr from PhysicsTools.NanoAODTools.postprocessing.examples.exampleOrtModule
Will write selected trees to outDir
Pre-select 10 entries out of 10 (100.00%)
input -&gt; [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]
output -&gt; [[0.83919346 0.16080655]]
input -&gt; [ 7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]
output -&gt; [[0.76994413 0.2300559 ]]
input -&gt; [ 4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]
output -&gt; [[0.7116992 0.2883008]]
input -&gt; [ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]
output -&gt; [[0.66414535 0.33585465]]
input -&gt; [ 9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]
output -&gt; [[0.80617136 0.19382869]]
input -&gt; [ 6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]
output -&gt; [[0.75187963 0.2481204 ]]
input -&gt; [16. 17. 18. 19. 20. 21. 22. 23. 24. 25.]
output -&gt; [[0.9014619  0.09853811]]
input -&gt; [18. 19. 20. 21. 22. 23. 24. 25. 26. 27.]
output -&gt; [[0.9202239  0.07977609]]
input -&gt; [ 5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]
output -&gt; [[0.7330253  0.26697478]]
input -&gt; [10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]
output -&gt; [[0.82333535 0.17666471]]
Processed 10 preselected entries from /eos/cms/store/user/andrey/f.root (10 entries). Finally selected 10 entries
Done outDir/f_Skim.root
Total time 1.1 sec. to process 10 events. Rate = 9.3 Hz.
</code></pre></div></p> </details> <h2 id=links-and-further-reading>Links and further reading<a class=headerlink href=#links-and-further-reading title="Permanent link">&para;</a></h2> <ul> <li>ONNX/ONNX Runtime<ul> <li><a href=https://github.com/onnx/tutorials#converting-to-onnx-format>Tutorials on converting models to ONNX format</a></li> <li><a href=https://github.com/microsoft/onnxruntime-inference-examples/tree/main/c_cxx>ONNX Runtime C++ example</a></li> <li><a href=https://onnxruntime.ai/docs/api/c/index.html>ONNX Runtime C++ API</a></li> <li><a href=https://onnxruntime.ai/docs/get-started/with-python.html>ONNX Runtime python example</a></li> <li><a href=https://onnxruntime.ai/docs/api/python/api_summary.html>ONNX Runtime python API</a></li> <li><a href=https://indico.cern.ch/event/1127774/contributions/4733524/attachments/2394910/4094695/ONNXRuntime_20220221.pdf>ONNX Runtime in CMSSW (talk)</a></li> </ul> </li> </ul> <hr> <p>Developers: <a href=mailto:huilin.qu@cern.ch>Huilin Qu</a></p> <p>Authors: <a href=mailto:congqiao.li@cern.ch>Congqiao Li</a></p> <hr> <div class=md-source-date> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">July 19, 2022</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=pyg.html title="PyTorch Geometric" class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> PyTorch Geometric </div> </div> </a> <a href=xgboost.html title=XGBoost class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> XGBoost </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 CMS Machine Learning Group </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/cms-ml target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </a> <a href=https://hub.docker.com/orgs/cmsml/repositories target=_blank rel=noopener title=hub.docker.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M349.9 236.3h-66.1v-59.4h66.1v59.4zm0-204.3h-66.1v60.7h66.1V32zm78.2 144.8H362v59.4h66.1v-59.4zm-156.3-72.1h-66.1v60.1h66.1v-60.1zm78.1 0h-66.1v60.1h66.1v-60.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1l-13.3-8.9zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm-78.1-72.1h-66.1v60.1h66.1v-60.1z"/></svg> </a> <a href=https://hypernews.cern.ch/HyperNews/CMS/get/machine-learning.html target=_blank rel=noopener title=hypernews.cern.ch class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M256 32C114.6 32 0 125.1 0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3 0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4 0 256-93.1 256-208S397.4 32 256 32zM128 272c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm128 0c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32zm128 0c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32z"/></svg> </a> <a href=mailto:hn-cms-machine-learning@cern.ch target=_blank rel=noopener title class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../assets/javascripts/vendor.c3dc8c49.min.js></script> <script src=../assets/javascripts/bundle.f9edbbd5.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script> <script>
        app = initialize({
          base: "..",
          features: ["instant"],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.8e2cddea.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src=https://unpkg.com/mermaid@8.6/dist/mermaid.min.js></script> <script src=../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>